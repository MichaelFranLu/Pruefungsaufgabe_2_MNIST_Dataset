{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Ho3CzLsO3YS"
      },
      "source": [
        "<a href=\"https://akademie.datamics.com/kursliste/\">![title](bg_datamics_top.png)</a>\n",
        "\n",
        "<center><em>© Datamics</em></center><br><center><em>Besuche uns für mehr Informationen auf <a href='https://akademie.datamics.com/kursliste/'>www.akademie.datamics.com</a></em></center>\n",
        "\n",
        "# MNIST mit Multi-Layer Perceptron\n",
        "\n",
        "In dieser Lektion werden wir ein Multi Layer Perceptron Modell erstellen und versuchen damit handgeschriebenen Zahlen zu klassifizieren. Das ist ein sehr verbreitetes Einsteigerproblem für Tensorflow.\n",
        "\n",
        "Denkt daran, dass eine einzige Lektion niemals ausreichen wird, um Deep Learning und/oder Tensorflow in seiner Komlexität abzudecken!\n",
        "\n",
        "## Die Daten laden\n",
        "\n",
        "Wir werden die berühmten MNIST Daten über [handgeschriebenen Zahlen](http://yann.lecun.com/exdb/mnist/) verwenden.\n",
        "\n",
        "Die Bilder die wir verwenden werden sind schwarz-weiß Bilder der größe 28 x 28, d.h. 784 Pixel insgesamt. Unsere Features werden die Pixelwerte für jeden Pixel sein. Entweder ist der Pixel \"weiß\" (also eine 0 in den Daten) oder er hat einen Pixelwert.\n",
        "\n",
        "Wir werden versuchen korrekt vorherzusagen, welche Nummer geschrieben steht. Dazu verwenden wir lediglich die Bilddaten in Form unseres Arrays. Diese Art von Problem (Image Recognition oder auf Deutsch: Bilderkennung) ist ein tolle Use Case für Deep Learning Methoden!\n",
        "\n",
        "Die Daten sind für Deep Learning das, was der Iris Datensatz für typische Machine Learning Algorithmen ist."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kv2Qq0kOO3YY"
      },
      "source": [
        "# Import Bibliotheken\n",
        "\n",
        "Dieser Code importiert mehrere Python-Bibliotheken, die für maschinelles Lernen, Datenmanipulation, Protokollierung, Zeitmessung, Datenvisualisierung, Arbeit mit binären Daten & Unit-Tests nützlich sind.\n",
        "\n",
        "Insbesondere werden folgende Bibliotheken importiert: TensorFlow, NumPy, Logging, Time, Matplotlib und Unittest importiert."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "sWPRYdWbPB29",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3d25b19-d7eb-4b8e-cdf9-6e045efda922"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.6.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow_dataset (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for tensorflow_dataset\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow==2.15.0 keras==2.15.0\n",
        "!pip install tensorflow_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hKZnyc3DO3YY"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import logging\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import unittest\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fynJb56ZO3YY"
      },
      "source": [
        "# Import des MNIST Datensatzes\n",
        "\n",
        "Wir werden die berühmten MNIST Daten über handgeschriebenen Zahlen verwenden.\n",
        "Die Bilder die wir verwenden werden sind schwarz-weiß Bilder der größe 28 x 28, d.h. 784 Pixel insgesamt. Unsere Features werden die Pixelwerte für jeden Pixel sein. Entweder ist der Pixel \"weiß\" (also eine 0 in den Daten) oder er hat einen Pixelwert.\n",
        "Wir werden versuchen korrekt vorherzusagen, welche Nummer geschrieben steht. Dazu verwenden wir lediglich die Bilddaten in Form unseres Arrays. Diese Art von Problem (Image Recognition oder auf Deutsch: Bilderkennung) ist ein tolle Use Case für Deep Learning Methoden!\n",
        "Die Daten sind für Deep Learning das, was der Iris Datensatz für typische Machine Learning Algorithmen ist.\n",
        "Laden wir die Daten:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XBF0XFywPW0o"
      },
      "outputs": [],
      "source": [
        "# Importieren der MNIST-Trainings- und Testdaten\n",
        "from tensorflow.keras.datasets import mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7w9-TV6O3Yb"
      },
      "source": [
        "# Daten Format\n",
        "\n",
        "Die Daten sind im Vektor Format gespeichert, obwohl die Originaldaten eine 2-dimensionale Matrix waren, die angab, wie viele Pigmente sich an welcher Position befinden. Untersuchen wir das genauer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U7fCxLgrO3Yb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "397d41d0-598c-49ce-a324-66126ee30d9b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "module"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "type(mnist)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pVvQ9V06O3Yb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1addd47-e13b-41a5-a1b9-70f191787ed6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "type(train_images)\n",
        "type(test_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NvgsEIzYO3Yc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67244f41-c1ab-4d6a-e90d-953e91c98f0f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "train_images[2].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i5QXnVuFO3Yc"
      },
      "outputs": [],
      "source": [
        "sample = train_images[2].reshape(28, 28)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3AkMs90WO3Yc"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QbSx9sGXO3Yc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "outputId": "fa28f8fb-3410-42b1-dfb0-c31d4c17b8f2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7d640446e110>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.imshow(sample)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVDLx3aLO3YZ"
      },
      "source": [
        "# Verarbeitung des MNIST Datensatzes\n",
        "\n",
        "Dieser Code normalisiert und formt die Trainings- und Testbilder um, sodass sie als eindimensionale Arrays dargestellt werden. Anschließend teilt er die Daten in Trainings- und Testsets auf, wobei 80% der Daten für das Training und 20% für das Testen verwendet werden. Zuletzt überprüft er, ob die Form der Daten korrekt ist."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Normalisierung\n",
        "class Normalize(object):\n",
        "    def normalize(self, X_train, X_test):\n",
        "        self.scaler = MinMaxScaler()\n",
        "        X_train = X_train.reshape(X_train.shape[0], -1)\n",
        "        X_test = X_test.reshape(X_test.shape[0], -1)\n",
        "        X_train = self.scaler.fit_transform(X_train)\n",
        "        X_test = self.scaler.transform(X_test)\n",
        "        return (X_train, X_test)\n",
        "\n",
        "    def inverse(self, X_train, X_test):\n",
        "        X_train = self.scaler.inverse_transform(X_train)\n",
        "        X_test = self.scaler.inverse_transform(X_test)\n",
        "        return (X_train, X_test)\n",
        "\n",
        "# Aufteilung der Daten\n",
        "def split(X, y, splitRatio):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1 - splitRatio, random_state=42)\n",
        "    return (X_train, y_train, X_test, y_test)\n",
        "\n",
        "splitRatio = 0.8  # 80% Trainingsdaten, 20% Testdaten\n",
        "x_train, y_train, x_test, y_test = split(train_images, train_labels, splitRatio)\n",
        "\n",
        "# Normalisierung\n",
        "normalizer = Normalize()\n",
        "x_train, x_test = normalizer.normalize(x_train, x_test)\n",
        "\n",
        "# Berechnen Sie die erwarteten Formen\n",
        "expected_train_size = int(0.8 * len(train_images))\n",
        "expected_test_size = int(0.2 * len(train_images))\n",
        "expected_feature_size = train_images.shape[1] * train_images.shape[2]\n",
        "\n",
        "# Überprüfen Sie die Form der Trainingsdaten\n",
        "assert x_train.shape == (expected_train_size, expected_feature_size), \\\n",
        "    f\"Erwartete Form: ({expected_train_size}, {expected_feature_size}), aber erhalten: {x_train.shape}\"\n",
        "\n",
        "# Überprüfen Sie die Form der Testdaten\n",
        "assert x_test.shape == (expected_test_size, expected_feature_size), \\\n",
        "    f\"Erwartete Form: ({expected_test_size}, {expected_feature_size}), aber erhalten: {x_test.shape}\"\n",
        "\n",
        "# Überprüfen Sie die Form der Trainingslabels\n",
        "assert y_train.shape == (expected_train_size,), \\\n",
        "    f\"Erwartete Form: ({expected_train_size},), aber erhalten: {y_train.shape}\"\n",
        "\n",
        "# Überprüfen Sie die Form der Testlabels\n",
        "assert y_test.shape == (expected_test_size,), \\\n",
        "    f\"Erwartete Form: ({expected_test_size},), aber erhalten: {y_test.shape}\"\n"
      ],
      "metadata": {
        "id": "xpkcout6zleA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KnSL75VxO3Ya"
      },
      "source": [
        "## Einbindung der my_logger Funktion\n",
        "\n",
        "Auf Basis des Code-Snippet der [Website]( https://towardsdatascience.com/unit-testing-and-logging-for-data-science-d7fb8fd5d217) aus der Aufgabenstellung."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DS4pbKjBO3Ya"
      },
      "outputs": [],
      "source": [
        "def my_logger(orig_func):\n",
        "    logging.basicConfig(filename='{}.log'.format(orig_func.__name__), level=logging.INFO)\n",
        "\n",
        "    @wraps(orig_func)\n",
        "    def wrapper(*args, **kwargs):\n",
        "        logging.info(\n",
        "            'Ran with args: {}, and kwargs: {}'.format(args, kwargs))\n",
        "        return orig_func(*args, **kwargs)\n",
        "\n",
        "    return wrapper"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgRROcl94W-g"
      },
      "source": [
        "# Einbindung der my_timer Funktion\n",
        "\n",
        "Auf Basis des Code-Snippet der [Website]( https://towardsdatascience.com/unit-testing-and-logging-for-data-science-d7fb8fd5d217) aus der Aufgabenstellung."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5i4UNSwwO3Ya"
      },
      "outputs": [],
      "source": [
        "def my_timer(orig_func):\n",
        "    import time\n",
        "\n",
        "    @wraps(orig_func)\n",
        "    def wrapper(*args, **kwargs):\n",
        "        t1 = time.time()\n",
        "        result = orig_func(*args, **kwargs)\n",
        "        t2 = time.time() - t1\n",
        "        print('{} ran in: {} sec'.format(orig_func.__name__, t2))\n",
        "        return result\n",
        "\n",
        "    return wrapper"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Mq7_gvaO3Ya"
      },
      "source": [
        "# Eimbindung der Klasse \"TheAlgorithm\"\n",
        "\n",
        "Auf Basis des Code-Snippet der [Website]( https://towardsdatascience.com/unit-testing-and-logging-for-data-science-d7fb8fd5d217) aus der Aufgabenstellung."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RjUKLvzcO3Ya"
      },
      "outputs": [],
      "source": [
        "from functools import wraps\n",
        "from sklearn.preprocessing import Normalizer\n",
        "\n",
        "\n",
        "class TheAlgorithm(object):\n",
        "    @my_logger\n",
        "    @my_timer\n",
        "    def __init__(self, X_train, y_train, X_test, y_test):\n",
        "        self.X_train, self.y_train, self.X_test, self.y_test = X_train, y_train, X_test, y_test\n",
        "\n",
        "    @my_logger\n",
        "    @my_timer\n",
        "    def fit(self):\n",
        "        x_train, y_train, x_test, y_test = self.X_train, self.y_train, self.X_test, self.y_test\n",
        "\n",
        "        normalizer = Normalize()  # Use the correct class name here\n",
        "        x_train, x_test = normalizer.normalize(x_train, x_test)\n",
        "\n",
        "        train_samples = x_train.shape[0]\n",
        "\n",
        "        self.classifier = LogisticRegression(\n",
        "            C=50. / train_samples,\n",
        "            multi_class='multinomial',\n",
        "            penalty='l1',\n",
        "            solver='saga',\n",
        "            tol=0.1,\n",
        "            class_weight='balanced',\n",
        "        )\n",
        "\n",
        "        self.classifier.fit(x_train, y_train)\n",
        "        self.train_predictions = self.classifier.predict(x_train)\n",
        "        self.train_accuracy = np.mean(self.train_predictions.ravel() == y_train.ravel()) * 100\n",
        "        self.train_confusion_matrix = confusion_matrix(y_train, self.train_predictions)\n",
        "        return self.train_accuracy\n",
        "\n",
        "    @my_logger\n",
        "    @my_timer\n",
        "    def predict(self):\n",
        "        x_test = self.X_test  # Test data doesn't need to be normalized again\n",
        "\n",
        "        self.test_predictions = self.classifier.predict(x_test)\n",
        "        self.test_accuracy = np.mean(self.test_predictions.ravel() == self.y_test.ravel()) * 100\n",
        "        self.test_confusion_matrix = confusion_matrix(self.y_test, self.test_predictions)\n",
        "        self.report = classification_report(self.y_test, self.test_predictions)\n",
        "        print(\"Classification Report for the classifier:\\n%s\\n\" % (self.report))\n",
        "\n",
        "        return self.test_accuracy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HD00O7xVO3Yd"
      },
      "source": [
        "## Parameter & Netzwerk Parameter\n",
        "\n",
        " - **Lernrate** - Sie bestimmt die Geschwindigkeit, mit der die Kostenfunktion optimiert wird.\n",
        " - **Trainingsepochen** - Sie legt die Anzahl der Durchläufe fest, die das\n",
        " Modell durch die Trainingsdaten machen soll.\n",
        " - **Batch-Größe** - Sie definiert die Menge an Trainingsdaten, die in einem Durchlauf verarbeitet werden."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tyJJsRTRO3Yd"
      },
      "outputs": [],
      "source": [
        "# Parameter\n",
        "learning_rate = 0.001     # Lernrate - Geschwindigkeit\n",
        "training_epochs = 15      # Anzahl der Durchläufe\n",
        "batch_size = 100          # Menge der Trainingsdaten\n",
        "\n",
        "# Netzwerk Parameter\n",
        "n_hidden_1 = 256          # Anzahl an Features\n",
        "n_hidden_2 = 256          # Anzahl an Features\n",
        "n_input = 784             # MNIST Daten Input\n",
        "n_classes = 10            # MNIST Klassen\n",
        "n_samples = len(x_train)  # Anzahl der Trainingsbeispiele"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbWBKaXaO3Yd"
      },
      "source": [
        "### Tensorflow Graph Input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WrsQRtvqO3Yd"
      },
      "outputs": [],
      "source": [
        "x = tf.keras.Input(shape=(n_input,), dtype=tf.float32)\n",
        "y = tf.keras.Input(shape=(n_classes,), dtype=tf.float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ggelg9hCO3Yd"
      },
      "source": [
        "## MultiLayer Modell\n",
        "\n",
        "Es ist Zeit unser Modell zu erstellen. Wiederholen wir deshalb kurz, was wir erstellen wollen:\n",
        "\n",
        "Zuerst erhalten wir einen *Input* in Form eines Datenarrays und schicken diesen an die erste *Hidden Layer*. Dann wird den Daten ein  *Weight* zwischen den Schichten zugewiesen (welches zuerst ein zufälliger Wert ist). Anschließend wird es an einen *Node* geschicht und unterläuft eine *Activation Function* (zusammen mit einem Bias, wie in der Neural Network Lektion erwähnt). Dann geht es weiter zur nächsten *Layer* und immer so weiter, bis zur finalen *Output Layer*. In unserem Fall werden wir nur 2 *Hidden Layers* verwenden. Je mehr wir davon verwenden, desto länger braucht das Modell (aber er hat mehr Möglichkeiten um die Genauigkeit zu erhöhen).\n",
        "\n",
        "Sobald die transformierte Daten die *Output Layer* erreicht haben müssen wir sie auswerten. Hier verwenden wir eine *Loss Function* (auch Cost Function genannt). Diese berechnet, wie sehr wir vom gewünschten Ergebnis entfernt sind. In diesem Fall: Wie viele der Klassen wir richtig zugeteilt haben.\n",
        "\n",
        "Dann wenden wir eine Optimierungsfunktion an, um die *Costs* (bzw. den Error) zu minimieren. Dies geschiet durch die Anpassung der *Weights* entlang des Netzes. Wir verwenden in unserem Beispiel den [Adam Optimizer](https://arxiv.org/pdf/1412.6980v8.pdf), welcher eine (im Vergleich zu anderen) sehr neue Entwicklung ist.\n",
        "\n",
        "Wir können anpassen, wie schnell diese Optimierung angewendet wird, indem wir unseren *Learning Rate* Parameter anpassen. Je geringer die Rate, desto höher die Möglichkeiten für Anpassungen. Dies erzeugt allerdings die Kosten einer erhöhten Wartezeit. Ab einem bestimmten Punkt lohnt es sich nicht mehr, die Learning Rate weiter zu senken.\n",
        "\n",
        "Jetzt können wir unser Modell erstellen. Wir beginnen mit 2 Hidden Layers, welche die []() Activation Function verwenden. Dies ist eine einfache Umformungsfunktion, die entweder x oder 0 zurückgibt. Für unsere finale Output Layer verwenden wir eine lineare Activation mit Matrixmultiplikation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lsgfhNrqO3Ye"
      },
      "outputs": [],
      "source": [
        "@my_logger  # Protokolieren der Funktion\n",
        "@my_timer   # Zeitmessung der Funktion\n",
        "def multilayer_perceptron(x, weights, biases):\n",
        "\n",
        "    # Erste Hidden layer mit RELU Activation\n",
        "    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
        "    layer_1 = tf.nn.relu(layer_1)\n",
        "\n",
        "    # Zweite Hidden layer mit RELU Activation\n",
        "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
        "    layer_2 = tf.nn.relu(layer_2)\n",
        "\n",
        "    # Letzte Output layer mit linearer Activation\n",
        "    out_layer = tf.matmul(layer_2, weights['out']) + biases['out']\n",
        "    return out_layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmgexfwJO3Ye"
      },
      "source": [
        "## Weights und Bias\n",
        "\n",
        "Damit unser Tensorflow Modell funktioniert müssen wir zwei Dictionaries anlegen, die unsere Weights und Biases enthalten. Wir können das `tf.variable` Objekt verwenden. Dies ist anders als eine Konstante, da Tensorflow's Graph Objekt alle Zustände der Variablen wahrnimmt. Eine Variable ist ein anpassbares Tensor, der zwischen Tensorflow's Graph von interagierenden Operationen lebt. Er kann durch die Berechnung verwendet und verändert werden. Wir werden die Modell Parameter generell als Variablen verwenden. Aus der Dokumentation können wir entnehmen:\n",
        "\n",
        "    A variable maintains state in the graph across calls to `run()`. You add a variable to the graph by constructing an instance of the class `Variable`.\n",
        "\n",
        "    The `Variable()` constructor requires an initial value for the variable, which can be a `Tensor` of any type and shape. The initial value defines the type and shape of the variable. After construction, the type and shape of the variable are fixed. The value can be changed using one of the assign methods.\n",
        "    \n",
        "Wir werden Tensorflow's eingebaute `random_normal` Methode verwenden, um zufällige Werte für unsere Weights und Biases zu erstellen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wlJnfQhdO3Ye"
      },
      "outputs": [],
      "source": [
        "# Gewichtsinitialisierung\n",
        "weights = {\n",
        "    'h1': tf.Variable(tf.initializers.RandomNormal()(shape=[n_input, n_hidden_1])),\n",
        "    'h2': tf.Variable(tf.initializers.RandomNormal()(shape=[n_hidden_1, n_hidden_2])),\n",
        "    'out': tf.Variable(tf.initializers.RandomNormal()(shape=[n_hidden_2, n_classes]))\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u1q6oYNkO3Ye"
      },
      "outputs": [],
      "source": [
        "# Bias-Initialisierung\n",
        "biases = {\n",
        "    'b1': tf.Variable(tf.random.normal([n_hidden_1])),\n",
        "    'b2': tf.Variable(tf.random.normal([n_hidden_2])),\n",
        "    'out': tf.Variable(tf.random.normal([n_classes]))\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IsHEYI0-O3Yf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fefe085f-785f-45bd-84ef-078467bbafcf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.linalg.matmul_3), but are not present in its tracked objects:   <tf.Variable 'Variable:0' shape=(784, 256) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
            "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.math.add_2), but are not present in its tracked objects:   <tf.Variable 'Variable:0' shape=(256,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
            "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.linalg.matmul_4), but are not present in its tracked objects:   <tf.Variable 'Variable:0' shape=(256, 256) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
            "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.math.add_3), but are not present in its tracked objects:   <tf.Variable 'Variable:0' shape=(256,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
            "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.linalg.matmul_5), but are not present in its tracked objects:   <tf.Variable 'Variable:0' shape=(256, 10) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
            "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.__operators__.add_1), but are not present in its tracked objects:   <tf.Variable 'Variable:0' shape=(10,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "multilayer_perceptron ran in: 0.09383225440979004 sec\n"
          ]
        }
      ],
      "source": [
        "# Model erstellen\n",
        "pred = multilayer_perceptron(x, weights, biases)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OaaaiHVbO3Yf"
      },
      "source": [
        "## Cost und Optimierungs-Funktion\n",
        "\n",
        "Wir verwenden Tensorflow's eingebaute Funktionen für diesesn Teil. Weitere Details bietet die Dokumentation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uRyP7iLoO3Yf"
      },
      "outputs": [],
      "source": [
        "# Cost und Optimierungsfunktion definieren\n",
        "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels = y, logits=pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lQToSTfuO3Yg"
      },
      "outputs": [],
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8Lqd_5aO3Yg"
      },
      "source": [
        "## Das Modell trainieren\n",
        "\n",
        "### next_batch()\n",
        "\n",
        "Bevor wir beginnen möchte ich eine weitere nützliche Funktion in unserem MNIST Datenobjekt abdecken, die `next_batch` heißt. Diese gibt ein Tupel in der Form (X,y) mit einem X Array der Daten und einem y Array der Klasse. Zum Beispiel:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Erstellen des Datasets\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "\n",
        "# Erhöhen der Batch-Größe für effizienteres Training\n",
        "batch_size = 1\n",
        "train_dataset = train_dataset.shuffle(buffer_size=len(x_train)).batch(batch_size)\n",
        "\n",
        "# Funktion zur Visualisierung eines Beispieldatensatzes\n",
        "def visualize_sample(Xsamp):\n",
        "    Xsamp_numpy = Xsamp.numpy()\n",
        "    plt.imshow(Xsamp_numpy.reshape(28, 28))\n",
        "\n",
        "# Anwenden der Visualisierungsfunktion auf ein Beispieldatensatz\n",
        "Xsamp, ysamp = next(iter(train_dataset))\n",
        "visualize_sample(Xsamp[0])\n"
      ],
      "metadata": {
        "id": "g4oX9cYFe4vk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "outputId": "9796c27d-9179-415a-863a-2fb52ab82a8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(ysamp)"
      ],
      "metadata": {
        "id": "S9lkW_EOXGcy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6626b60a-18ef-4bc1-d649-de91a6a53ee6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([2], shape=(1,), dtype=uint8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def my_logger(orig_func):\n",
        "    # Ein Dekorierer, der die Argumente einer Funktion protokolliert.\n",
        "    logging.basicConfig(filename=f'{orig_func.__name__}.log', level=logging.INFO)\n",
        "\n",
        "    @wraps(orig_func)\n",
        "    def wrapper(*args, **kwargs):\n",
        "        logging.info(f'Ran with args: {args}, and kwargs: {kwargs}')\n",
        "        return orig_func(*args, **kwargs)\n",
        "\n",
        "    return wrapper\n",
        "\n",
        "def my_timer(orig_func):\n",
        "    # Ein Dekorierer, der die Ausführungszeit einer Funktion misst.\n",
        "    @wraps(orig_func)\n",
        "    def wrapper(*args, **kwargs):\n",
        "        start_time = time.time()\n",
        "        result = orig_func(*args, **kwargs)\n",
        "        elapsed_time = time.time() - start_time\n",
        "        print(f'{orig_func.__name__} ran in: {elapsed_time} sec')\n",
        "        return result\n",
        "\n",
        "    return wrapper\n"
      ],
      "metadata": {
        "id": "7r9ZuR1CfgE_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HItXWrTO3Yi"
      },
      "source": [
        "## Die Session ausführen\n",
        "\n",
        "In diesm Abschnitt wird ein neuronales Netzwerk trainiert. Es werden nur **0,5%** der gesamten Daten für das Training verwendet. Während des Trainings werden die Gewichte und Bias des Netzwerks aktualisiert, um den durchschnittlichen Verlust (Kosten) über alle Batches in jeder Epoche zu minimieren. Nach Abschluss des Trainings werden die Kosten für jede Epoche und eine abschließende Nachricht ausgegeben."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1P3717SvO3Yi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afd8942b-0a84-4497-9d8a-e69ff5c7fdb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "multilayer_perceptron ran in: 0.003935337066650391 sec\n",
            "multilayer_perceptron ran in: 0.0027883052825927734 sec\n",
            "multilayer_perceptron ran in: 0.0017819404602050781 sec\n",
            "multilayer_perceptron ran in: 0.002532958984375 sec\n",
            "multilayer_perceptron ran in: 0.0027017593383789062 sec\n",
            "multilayer_perceptron ran in: 0.0022029876708984375 sec\n",
            "multilayer_perceptron ran in: 0.0021719932556152344 sec\n",
            "multilayer_perceptron ran in: 0.002153158187866211 sec\n",
            "multilayer_perceptron ran in: 0.002050161361694336 sec\n",
            "multilayer_perceptron ran in: 0.0025458335876464844 sec\n",
            "multilayer_perceptron ran in: 0.002514362335205078 sec\n",
            "multilayer_perceptron ran in: 0.002680540084838867 sec\n",
            "multilayer_perceptron ran in: 0.0023660659790039062 sec\n",
            "multilayer_perceptron ran in: 0.0031824111938476562 sec\n",
            "multilayer_perceptron ran in: 0.002172708511352539 sec\n",
            "multilayer_perceptron ran in: 0.0022084712982177734 sec\n",
            "multilayer_perceptron ran in: 0.002229928970336914 sec\n",
            "multilayer_perceptron ran in: 0.0022177696228027344 sec\n",
            "multilayer_perceptron ran in: 0.0022101402282714844 sec\n",
            "multilayer_perceptron ran in: 0.002195119857788086 sec\n",
            "multilayer_perceptron ran in: 0.0032846927642822266 sec\n",
            "multilayer_perceptron ran in: 0.0027387142181396484 sec\n",
            "multilayer_perceptron ran in: 0.0026869773864746094 sec\n",
            "multilayer_perceptron ran in: 0.001928091049194336 sec\n",
            "multilayer_perceptron ran in: 0.004037380218505859 sec\n",
            "multilayer_perceptron ran in: 0.005063056945800781 sec\n",
            "multilayer_perceptron ran in: 0.002145528793334961 sec\n",
            "multilayer_perceptron ran in: 0.0030319690704345703 sec\n",
            "multilayer_perceptron ran in: 0.002622365951538086 sec\n",
            "multilayer_perceptron ran in: 0.002670764923095703 sec\n",
            "multilayer_perceptron ran in: 0.0031747817993164062 sec\n",
            "multilayer_perceptron ran in: 0.002396821975708008 sec\n",
            "multilayer_perceptron ran in: 0.005631685256958008 sec\n",
            "multilayer_perceptron ran in: 0.0026128292083740234 sec\n",
            "multilayer_perceptron ran in: 0.002357006072998047 sec\n",
            "multilayer_perceptron ran in: 0.00408935546875 sec\n",
            "multilayer_perceptron ran in: 0.0023958683013916016 sec\n",
            "multilayer_perceptron ran in: 0.002306699752807617 sec\n",
            "multilayer_perceptron ran in: 0.002325296401977539 sec\n",
            "multilayer_perceptron ran in: 0.004927396774291992 sec\n",
            "multilayer_perceptron ran in: 0.0030612945556640625 sec\n",
            "multilayer_perceptron ran in: 0.0043332576751708984 sec\n",
            "multilayer_perceptron ran in: 0.004033565521240234 sec\n",
            "multilayer_perceptron ran in: 0.0026273727416992188 sec\n",
            "multilayer_perceptron ran in: 0.002758026123046875 sec\n",
            "multilayer_perceptron ran in: 0.003290414810180664 sec\n",
            "multilayer_perceptron ran in: 0.0020215511322021484 sec\n",
            "multilayer_perceptron ran in: 0.003435850143432617 sec\n",
            "multilayer_perceptron ran in: 0.003079652786254883 sec\n",
            "multilayer_perceptron ran in: 0.0019638538360595703 sec\n",
            "multilayer_perceptron ran in: 0.0018954277038574219 sec\n",
            "multilayer_perceptron ran in: 0.0019481182098388672 sec\n",
            "multilayer_perceptron ran in: 0.001851797103881836 sec\n",
            "multilayer_perceptron ran in: 0.0020036697387695312 sec\n",
            "multilayer_perceptron ran in: 0.001735687255859375 sec\n",
            "multilayer_perceptron ran in: 0.00200653076171875 sec\n",
            "multilayer_perceptron ran in: 0.0019979476928710938 sec\n",
            "multilayer_perceptron ran in: 0.0018401145935058594 sec\n",
            "multilayer_perceptron ran in: 0.0018093585968017578 sec\n",
            "multilayer_perceptron ran in: 0.0016753673553466797 sec\n",
            "multilayer_perceptron ran in: 0.0017240047454833984 sec\n",
            "multilayer_perceptron ran in: 0.0018875598907470703 sec\n",
            "multilayer_perceptron ran in: 0.0017714500427246094 sec\n",
            "multilayer_perceptron ran in: 0.0017969608306884766 sec\n",
            "multilayer_perceptron ran in: 0.002179384231567383 sec\n",
            "multilayer_perceptron ran in: 0.002104520797729492 sec\n",
            "multilayer_perceptron ran in: 0.0018622875213623047 sec\n",
            "multilayer_perceptron ran in: 0.0023183822631835938 sec\n",
            "multilayer_perceptron ran in: 0.0017969608306884766 sec\n",
            "multilayer_perceptron ran in: 0.002028942108154297 sec\n",
            "multilayer_perceptron ran in: 0.0018084049224853516 sec\n",
            "multilayer_perceptron ran in: 0.0019106864929199219 sec\n",
            "multilayer_perceptron ran in: 0.0019402503967285156 sec\n",
            "multilayer_perceptron ran in: 0.0021054744720458984 sec\n",
            "multilayer_perceptron ran in: 0.0034942626953125 sec\n",
            "multilayer_perceptron ran in: 0.003393411636352539 sec\n",
            "multilayer_perceptron ran in: 0.0018434524536132812 sec\n",
            "multilayer_perceptron ran in: 0.0018055438995361328 sec\n",
            "multilayer_perceptron ran in: 0.0018372535705566406 sec\n",
            "multilayer_perceptron ran in: 0.0022399425506591797 sec\n",
            "multilayer_perceptron ran in: 0.0018644332885742188 sec\n",
            "multilayer_perceptron ran in: 0.0017209053039550781 sec\n",
            "multilayer_perceptron ran in: 0.0017495155334472656 sec\n",
            "multilayer_perceptron ran in: 0.0038526058197021484 sec\n",
            "multilayer_perceptron ran in: 0.002074003219604492 sec\n",
            "multilayer_perceptron ran in: 0.002002239227294922 sec\n",
            "multilayer_perceptron ran in: 0.002299785614013672 sec\n",
            "multilayer_perceptron ran in: 0.0017936229705810547 sec\n",
            "multilayer_perceptron ran in: 0.0018961429595947266 sec\n",
            "multilayer_perceptron ran in: 0.0019464492797851562 sec\n",
            "multilayer_perceptron ran in: 0.002421855926513672 sec\n",
            "multilayer_perceptron ran in: 0.0018613338470458984 sec\n",
            "multilayer_perceptron ran in: 0.0018742084503173828 sec\n",
            "multilayer_perceptron ran in: 0.001986980438232422 sec\n",
            "multilayer_perceptron ran in: 0.0019135475158691406 sec\n",
            "multilayer_perceptron ran in: 0.0017032623291015625 sec\n",
            "multilayer_perceptron ran in: 0.0018029212951660156 sec\n",
            "multilayer_perceptron ran in: 0.0018970966339111328 sec\n",
            "multilayer_perceptron ran in: 0.0018260478973388672 sec\n",
            "multilayer_perceptron ran in: 0.001806020736694336 sec\n",
            "multilayer_perceptron ran in: 0.0018107891082763672 sec\n",
            "multilayer_perceptron ran in: 0.002166271209716797 sec\n",
            "multilayer_perceptron ran in: 0.0017709732055664062 sec\n",
            "multilayer_perceptron ran in: 0.001859903335571289 sec\n",
            "multilayer_perceptron ran in: 0.0017108917236328125 sec\n",
            "multilayer_perceptron ran in: 0.0018799304962158203 sec\n",
            "multilayer_perceptron ran in: 0.001821756362915039 sec\n",
            "multilayer_perceptron ran in: 0.002521991729736328 sec\n",
            "multilayer_perceptron ran in: 0.0018200874328613281 sec\n",
            "multilayer_perceptron ran in: 0.0019290447235107422 sec\n",
            "multilayer_perceptron ran in: 0.0018978118896484375 sec\n",
            "multilayer_perceptron ran in: 0.0021543502807617188 sec\n",
            "multilayer_perceptron ran in: 0.0018384456634521484 sec\n",
            "multilayer_perceptron ran in: 0.0018582344055175781 sec\n",
            "multilayer_perceptron ran in: 0.001707315444946289 sec\n",
            "multilayer_perceptron ran in: 0.0018162727355957031 sec\n",
            "multilayer_perceptron ran in: 0.0019092559814453125 sec\n",
            "multilayer_perceptron ran in: 0.0018157958984375 sec\n",
            "multilayer_perceptron ran in: 0.0023343563079833984 sec\n",
            "multilayer_perceptron ran in: 0.0018858909606933594 sec\n",
            "multilayer_perceptron ran in: 0.0017971992492675781 sec\n",
            "multilayer_perceptron ran in: 0.0018718242645263672 sec\n",
            "multilayer_perceptron ran in: 0.0020203590393066406 sec\n",
            "multilayer_perceptron ran in: 0.002240896224975586 sec\n",
            "multilayer_perceptron ran in: 0.0019099712371826172 sec\n",
            "multilayer_perceptron ran in: 0.0016300678253173828 sec\n",
            "multilayer_perceptron ran in: 0.0017132759094238281 sec\n",
            "multilayer_perceptron ran in: 0.0017063617706298828 sec\n",
            "multilayer_perceptron ran in: 0.0017693042755126953 sec\n",
            "multilayer_perceptron ran in: 0.0018792152404785156 sec\n",
            "multilayer_perceptron ran in: 0.002146005630493164 sec\n",
            "multilayer_perceptron ran in: 0.002493143081665039 sec\n",
            "multilayer_perceptron ran in: 0.0018570423126220703 sec\n",
            "multilayer_perceptron ran in: 0.001760721206665039 sec\n",
            "multilayer_perceptron ran in: 0.001726388931274414 sec\n",
            "multilayer_perceptron ran in: 0.0017733573913574219 sec\n",
            "multilayer_perceptron ran in: 0.0022628307342529297 sec\n",
            "multilayer_perceptron ran in: 0.002052783966064453 sec\n",
            "multilayer_perceptron ran in: 0.0018186569213867188 sec\n",
            "multilayer_perceptron ran in: 0.001989126205444336 sec\n",
            "multilayer_perceptron ran in: 0.0017123222351074219 sec\n",
            "multilayer_perceptron ran in: 0.0017635822296142578 sec\n",
            "multilayer_perceptron ran in: 0.0018622875213623047 sec\n",
            "multilayer_perceptron ran in: 0.0017843246459960938 sec\n",
            "multilayer_perceptron ran in: 0.001817941665649414 sec\n",
            "multilayer_perceptron ran in: 0.0018668174743652344 sec\n",
            "multilayer_perceptron ran in: 0.0019252300262451172 sec\n",
            "multilayer_perceptron ran in: 0.0017359256744384766 sec\n",
            "multilayer_perceptron ran in: 0.0017077922821044922 sec\n",
            "multilayer_perceptron ran in: 0.0019838809967041016 sec\n",
            "multilayer_perceptron ran in: 0.0019609928131103516 sec\n",
            "multilayer_perceptron ran in: 0.0018372535705566406 sec\n",
            "multilayer_perceptron ran in: 0.0018606185913085938 sec\n",
            "multilayer_perceptron ran in: 0.002364635467529297 sec\n",
            "multilayer_perceptron ran in: 0.0020999908447265625 sec\n",
            "multilayer_perceptron ran in: 0.002012014389038086 sec\n",
            "multilayer_perceptron ran in: 0.0018074512481689453 sec\n",
            "multilayer_perceptron ran in: 0.001775979995727539 sec\n",
            "multilayer_perceptron ran in: 0.001989603042602539 sec\n",
            "multilayer_perceptron ran in: 0.0019621849060058594 sec\n",
            "multilayer_perceptron ran in: 0.0017421245574951172 sec\n",
            "multilayer_perceptron ran in: 0.0017452239990234375 sec\n",
            "multilayer_perceptron ran in: 0.0018014907836914062 sec\n",
            "multilayer_perceptron ran in: 0.0016477108001708984 sec\n",
            "multilayer_perceptron ran in: 0.0018203258514404297 sec\n",
            "multilayer_perceptron ran in: 0.0017936229705810547 sec\n",
            "multilayer_perceptron ran in: 0.0017597675323486328 sec\n",
            "multilayer_perceptron ran in: 0.0018472671508789062 sec\n",
            "multilayer_perceptron ran in: 0.001989126205444336 sec\n",
            "multilayer_perceptron ran in: 0.0018074512481689453 sec\n",
            "multilayer_perceptron ran in: 0.0016608238220214844 sec\n",
            "multilayer_perceptron ran in: 0.0017104148864746094 sec\n",
            "multilayer_perceptron ran in: 0.0018336772918701172 sec\n",
            "multilayer_perceptron ran in: 0.001683950424194336 sec\n",
            "multilayer_perceptron ran in: 0.001857757568359375 sec\n",
            "multilayer_perceptron ran in: 0.0018367767333984375 sec\n",
            "multilayer_perceptron ran in: 0.0018224716186523438 sec\n",
            "multilayer_perceptron ran in: 0.0017333030700683594 sec\n",
            "multilayer_perceptron ran in: 0.003173351287841797 sec\n",
            "multilayer_perceptron ran in: 0.0018453598022460938 sec\n",
            "multilayer_perceptron ran in: 0.0020058155059814453 sec\n",
            "multilayer_perceptron ran in: 0.0017483234405517578 sec\n",
            "multilayer_perceptron ran in: 0.0017406940460205078 sec\n",
            "multilayer_perceptron ran in: 0.0017063617706298828 sec\n",
            "multilayer_perceptron ran in: 0.0018496513366699219 sec\n",
            "multilayer_perceptron ran in: 0.0021092891693115234 sec\n",
            "multilayer_perceptron ran in: 0.001901388168334961 sec\n",
            "multilayer_perceptron ran in: 0.0018568038940429688 sec\n",
            "multilayer_perceptron ran in: 0.0018832683563232422 sec\n",
            "multilayer_perceptron ran in: 0.0019986629486083984 sec\n",
            "multilayer_perceptron ran in: 0.0018563270568847656 sec\n",
            "multilayer_perceptron ran in: 0.0022330284118652344 sec\n",
            "multilayer_perceptron ran in: 0.0017709732055664062 sec\n",
            "multilayer_perceptron ran in: 0.002864360809326172 sec\n",
            "multilayer_perceptron ran in: 0.0017342567443847656 sec\n",
            "multilayer_perceptron ran in: 0.0019009113311767578 sec\n",
            "multilayer_perceptron ran in: 0.0018482208251953125 sec\n",
            "multilayer_perceptron ran in: 0.0017619132995605469 sec\n",
            "multilayer_perceptron ran in: 0.0017344951629638672 sec\n",
            "multilayer_perceptron ran in: 0.0018737316131591797 sec\n",
            "multilayer_perceptron ran in: 0.0017743110656738281 sec\n",
            "multilayer_perceptron ran in: 0.0017139911651611328 sec\n",
            "multilayer_perceptron ran in: 0.0017993450164794922 sec\n",
            "multilayer_perceptron ran in: 0.001837015151977539 sec\n",
            "multilayer_perceptron ran in: 0.0019040107727050781 sec\n",
            "multilayer_perceptron ran in: 0.002020120620727539 sec\n",
            "multilayer_perceptron ran in: 0.0019674301147460938 sec\n",
            "multilayer_perceptron ran in: 0.0018718242645263672 sec\n",
            "multilayer_perceptron ran in: 0.001901388168334961 sec\n",
            "multilayer_perceptron ran in: 0.0018596649169921875 sec\n",
            "multilayer_perceptron ran in: 0.0019047260284423828 sec\n",
            "multilayer_perceptron ran in: 0.0018634796142578125 sec\n",
            "multilayer_perceptron ran in: 0.002935171127319336 sec\n",
            "multilayer_perceptron ran in: 0.0034813880920410156 sec\n",
            "multilayer_perceptron ran in: 0.0019028186798095703 sec\n",
            "multilayer_perceptron ran in: 0.0018551349639892578 sec\n",
            "multilayer_perceptron ran in: 0.002587556838989258 sec\n",
            "multilayer_perceptron ran in: 0.0017871856689453125 sec\n",
            "multilayer_perceptron ran in: 0.0017368793487548828 sec\n",
            "multilayer_perceptron ran in: 0.001756906509399414 sec\n",
            "multilayer_perceptron ran in: 0.003634929656982422 sec\n",
            "multilayer_perceptron ran in: 0.0019850730895996094 sec\n",
            "multilayer_perceptron ran in: 0.0017960071563720703 sec\n",
            "multilayer_perceptron ran in: 0.0018737316131591797 sec\n",
            "multilayer_perceptron ran in: 0.0018916130065917969 sec\n",
            "multilayer_perceptron ran in: 0.0020897388458251953 sec\n",
            "multilayer_perceptron ran in: 0.0034949779510498047 sec\n",
            "multilayer_perceptron ran in: 0.002176523208618164 sec\n",
            "multilayer_perceptron ran in: 0.00196075439453125 sec\n",
            "multilayer_perceptron ran in: 0.0018308162689208984 sec\n",
            "multilayer_perceptron ran in: 0.0021741390228271484 sec\n",
            "multilayer_perceptron ran in: 0.0016505718231201172 sec\n",
            "multilayer_perceptron ran in: 0.0017821788787841797 sec\n",
            "multilayer_perceptron ran in: 0.0017633438110351562 sec\n",
            "multilayer_perceptron ran in: 0.003336191177368164 sec\n",
            "multilayer_perceptron ran in: 0.0034809112548828125 sec\n",
            "multilayer_perceptron ran in: 0.0022652149200439453 sec\n",
            "multilayer_perceptron ran in: 0.0018377304077148438 sec\n",
            "multilayer_perceptron ran in: 0.00173187255859375 sec\n",
            "multilayer_perceptron ran in: 0.002184629440307617 sec\n",
            "Epoch: 1 Cost=4715.0444\n",
            "multilayer_perceptron ran in: 0.0017807483673095703 sec\n",
            "multilayer_perceptron ran in: 0.0017189979553222656 sec\n",
            "multilayer_perceptron ran in: 0.0018873214721679688 sec\n",
            "multilayer_perceptron ran in: 0.001901865005493164 sec\n",
            "multilayer_perceptron ran in: 0.001758575439453125 sec\n",
            "multilayer_perceptron ran in: 0.0019006729125976562 sec\n",
            "multilayer_perceptron ran in: 0.0018427371978759766 sec\n",
            "multilayer_perceptron ran in: 0.0017242431640625 sec\n",
            "multilayer_perceptron ran in: 0.003518342971801758 sec\n",
            "multilayer_perceptron ran in: 0.0033257007598876953 sec\n",
            "multilayer_perceptron ran in: 0.0018346309661865234 sec\n",
            "multilayer_perceptron ran in: 0.0020835399627685547 sec\n",
            "multilayer_perceptron ran in: 0.0017893314361572266 sec\n",
            "multilayer_perceptron ran in: 0.0018372535705566406 sec\n",
            "multilayer_perceptron ran in: 0.00185394287109375 sec\n",
            "multilayer_perceptron ran in: 0.0018279552459716797 sec\n",
            "multilayer_perceptron ran in: 0.001795053482055664 sec\n",
            "multilayer_perceptron ran in: 0.002178192138671875 sec\n",
            "multilayer_perceptron ran in: 0.0018973350524902344 sec\n",
            "multilayer_perceptron ran in: 0.001697540283203125 sec\n",
            "multilayer_perceptron ran in: 0.001972675323486328 sec\n",
            "multilayer_perceptron ran in: 0.0025510787963867188 sec\n",
            "multilayer_perceptron ran in: 0.0020563602447509766 sec\n",
            "multilayer_perceptron ran in: 0.0019860267639160156 sec\n",
            "multilayer_perceptron ran in: 0.0018198490142822266 sec\n",
            "multilayer_perceptron ran in: 0.0022819042205810547 sec\n",
            "multilayer_perceptron ran in: 0.0017354488372802734 sec\n",
            "multilayer_perceptron ran in: 0.0019083023071289062 sec\n",
            "multilayer_perceptron ran in: 0.002101898193359375 sec\n",
            "multilayer_perceptron ran in: 0.0018780231475830078 sec\n",
            "multilayer_perceptron ran in: 0.0018384456634521484 sec\n",
            "multilayer_perceptron ran in: 0.003127574920654297 sec\n",
            "multilayer_perceptron ran in: 0.002644062042236328 sec\n",
            "multilayer_perceptron ran in: 0.0022335052490234375 sec\n",
            "multilayer_perceptron ran in: 0.0026640892028808594 sec\n",
            "multilayer_perceptron ran in: 0.0024983882904052734 sec\n",
            "multilayer_perceptron ran in: 0.0024738311767578125 sec\n",
            "multilayer_perceptron ran in: 0.0019237995147705078 sec\n",
            "multilayer_perceptron ran in: 0.002809762954711914 sec\n",
            "multilayer_perceptron ran in: 0.002244710922241211 sec\n",
            "multilayer_perceptron ran in: 0.002185344696044922 sec\n",
            "multilayer_perceptron ran in: 0.002105712890625 sec\n",
            "multilayer_perceptron ran in: 0.002123594284057617 sec\n",
            "multilayer_perceptron ran in: 0.0023255348205566406 sec\n",
            "multilayer_perceptron ran in: 0.0021991729736328125 sec\n",
            "multilayer_perceptron ran in: 0.0027909278869628906 sec\n",
            "multilayer_perceptron ran in: 0.0019378662109375 sec\n",
            "multilayer_perceptron ran in: 0.0022614002227783203 sec\n",
            "multilayer_perceptron ran in: 0.0021326541900634766 sec\n",
            "multilayer_perceptron ran in: 0.0022840499877929688 sec\n",
            "multilayer_perceptron ran in: 0.0063936710357666016 sec\n",
            "multilayer_perceptron ran in: 0.0022742748260498047 sec\n",
            "multilayer_perceptron ran in: 0.0021562576293945312 sec\n",
            "multilayer_perceptron ran in: 0.002484560012817383 sec\n",
            "multilayer_perceptron ran in: 0.002543926239013672 sec\n",
            "multilayer_perceptron ran in: 0.0022678375244140625 sec\n",
            "multilayer_perceptron ran in: 0.0021431446075439453 sec\n",
            "multilayer_perceptron ran in: 0.002382516860961914 sec\n",
            "multilayer_perceptron ran in: 0.002064943313598633 sec\n",
            "multilayer_perceptron ran in: 0.0026781558990478516 sec\n",
            "multilayer_perceptron ran in: 0.0024950504302978516 sec\n",
            "multilayer_perceptron ran in: 0.002549886703491211 sec\n",
            "multilayer_perceptron ran in: 0.002622365951538086 sec\n",
            "multilayer_perceptron ran in: 0.0025162696838378906 sec\n",
            "multilayer_perceptron ran in: 0.003376007080078125 sec\n",
            "multilayer_perceptron ran in: 0.002622365951538086 sec\n",
            "multilayer_perceptron ran in: 0.0032172203063964844 sec\n",
            "multilayer_perceptron ran in: 0.002402782440185547 sec\n",
            "multilayer_perceptron ran in: 0.0038847923278808594 sec\n",
            "multilayer_perceptron ran in: 0.0024700164794921875 sec\n",
            "multilayer_perceptron ran in: 0.002574920654296875 sec\n",
            "multilayer_perceptron ran in: 0.0028569698333740234 sec\n",
            "multilayer_perceptron ran in: 0.002689838409423828 sec\n",
            "multilayer_perceptron ran in: 0.002774953842163086 sec\n",
            "multilayer_perceptron ran in: 0.0028028488159179688 sec\n",
            "multilayer_perceptron ran in: 0.0018572807312011719 sec\n",
            "multilayer_perceptron ran in: 0.0022199153900146484 sec\n",
            "multilayer_perceptron ran in: 0.0018947124481201172 sec\n",
            "multilayer_perceptron ran in: 0.001828908920288086 sec\n",
            "multilayer_perceptron ran in: 0.0018908977508544922 sec\n",
            "multilayer_perceptron ran in: 0.0018007755279541016 sec\n",
            "multilayer_perceptron ran in: 0.0018315315246582031 sec\n",
            "multilayer_perceptron ran in: 0.0019817352294921875 sec\n",
            "multilayer_perceptron ran in: 0.0018527507781982422 sec\n",
            "multilayer_perceptron ran in: 0.001955270767211914 sec\n",
            "multilayer_perceptron ran in: 0.001986265182495117 sec\n",
            "multilayer_perceptron ran in: 0.0019888877868652344 sec\n",
            "multilayer_perceptron ran in: 0.0018944740295410156 sec\n",
            "multilayer_perceptron ran in: 0.0019059181213378906 sec\n",
            "multilayer_perceptron ran in: 0.0020003318786621094 sec\n",
            "multilayer_perceptron ran in: 0.0018520355224609375 sec\n",
            "multilayer_perceptron ran in: 0.0017771720886230469 sec\n",
            "multilayer_perceptron ran in: 0.0018527507781982422 sec\n",
            "multilayer_perceptron ran in: 0.0018301010131835938 sec\n",
            "multilayer_perceptron ran in: 0.001837015151977539 sec\n",
            "multilayer_perceptron ran in: 0.001821279525756836 sec\n",
            "multilayer_perceptron ran in: 0.0017535686492919922 sec\n",
            "multilayer_perceptron ran in: 0.0019311904907226562 sec\n",
            "multilayer_perceptron ran in: 0.001976490020751953 sec\n",
            "multilayer_perceptron ran in: 0.002138376235961914 sec\n",
            "multilayer_perceptron ran in: 0.0026094913482666016 sec\n",
            "multilayer_perceptron ran in: 0.001988649368286133 sec\n",
            "multilayer_perceptron ran in: 0.0023872852325439453 sec\n",
            "multilayer_perceptron ran in: 0.0018515586853027344 sec\n",
            "multilayer_perceptron ran in: 0.001882314682006836 sec\n",
            "multilayer_perceptron ran in: 0.001955270767211914 sec\n",
            "multilayer_perceptron ran in: 0.0019273757934570312 sec\n",
            "multilayer_perceptron ran in: 0.0019636154174804688 sec\n",
            "multilayer_perceptron ran in: 0.0019409656524658203 sec\n",
            "multilayer_perceptron ran in: 0.001836538314819336 sec\n",
            "multilayer_perceptron ran in: 0.001951456069946289 sec\n",
            "multilayer_perceptron ran in: 0.002711772918701172 sec\n",
            "multilayer_perceptron ran in: 0.002047300338745117 sec\n",
            "multilayer_perceptron ran in: 0.0020914077758789062 sec\n",
            "multilayer_perceptron ran in: 0.0017805099487304688 sec\n",
            "multilayer_perceptron ran in: 0.0020294189453125 sec\n",
            "multilayer_perceptron ran in: 0.0017824172973632812 sec\n",
            "multilayer_perceptron ran in: 0.002089262008666992 sec\n",
            "multilayer_perceptron ran in: 0.0019419193267822266 sec\n",
            "multilayer_perceptron ran in: 0.00180816650390625 sec\n",
            "multilayer_perceptron ran in: 0.0018100738525390625 sec\n",
            "multilayer_perceptron ran in: 0.0023162364959716797 sec\n",
            "multilayer_perceptron ran in: 0.0020384788513183594 sec\n",
            "multilayer_perceptron ran in: 0.0018281936645507812 sec\n",
            "multilayer_perceptron ran in: 0.0017671585083007812 sec\n",
            "multilayer_perceptron ran in: 0.0017409324645996094 sec\n",
            "multilayer_perceptron ran in: 0.0017998218536376953 sec\n",
            "multilayer_perceptron ran in: 0.00258636474609375 sec\n",
            "multilayer_perceptron ran in: 0.0019295215606689453 sec\n",
            "multilayer_perceptron ran in: 0.0020384788513183594 sec\n",
            "multilayer_perceptron ran in: 0.0035266876220703125 sec\n",
            "multilayer_perceptron ran in: 0.0030319690704345703 sec\n",
            "multilayer_perceptron ran in: 0.0023627281188964844 sec\n",
            "multilayer_perceptron ran in: 0.0017697811126708984 sec\n",
            "multilayer_perceptron ran in: 0.0019252300262451172 sec\n",
            "multilayer_perceptron ran in: 0.0018837451934814453 sec\n",
            "multilayer_perceptron ran in: 0.0017924308776855469 sec\n",
            "multilayer_perceptron ran in: 0.0024738311767578125 sec\n",
            "multilayer_perceptron ran in: 0.0019021034240722656 sec\n",
            "multilayer_perceptron ran in: 0.001985788345336914 sec\n",
            "multilayer_perceptron ran in: 0.0017039775848388672 sec\n",
            "multilayer_perceptron ran in: 0.0019681453704833984 sec\n",
            "multilayer_perceptron ran in: 0.0019788742065429688 sec\n",
            "multilayer_perceptron ran in: 0.0018696784973144531 sec\n",
            "multilayer_perceptron ran in: 0.0016448497772216797 sec\n",
            "multilayer_perceptron ran in: 0.0025320053100585938 sec\n",
            "multilayer_perceptron ran in: 0.0018336772918701172 sec\n",
            "multilayer_perceptron ran in: 0.0018646717071533203 sec\n",
            "multilayer_perceptron ran in: 0.0016894340515136719 sec\n",
            "multilayer_perceptron ran in: 0.0018851757049560547 sec\n",
            "multilayer_perceptron ran in: 0.0017838478088378906 sec\n",
            "multilayer_perceptron ran in: 0.001687765121459961 sec\n",
            "multilayer_perceptron ran in: 0.0022852420806884766 sec\n",
            "multilayer_perceptron ran in: 0.002034902572631836 sec\n",
            "multilayer_perceptron ran in: 0.0017971992492675781 sec\n",
            "multilayer_perceptron ran in: 0.002012491226196289 sec\n",
            "multilayer_perceptron ran in: 0.0017552375793457031 sec\n",
            "multilayer_perceptron ran in: 0.0019290447235107422 sec\n",
            "multilayer_perceptron ran in: 0.0018112659454345703 sec\n",
            "multilayer_perceptron ran in: 0.0021359920501708984 sec\n",
            "multilayer_perceptron ran in: 0.0018596649169921875 sec\n",
            "multilayer_perceptron ran in: 0.002251863479614258 sec\n",
            "multilayer_perceptron ran in: 0.0018362998962402344 sec\n",
            "multilayer_perceptron ran in: 0.0019009113311767578 sec\n",
            "multilayer_perceptron ran in: 0.0017790794372558594 sec\n",
            "multilayer_perceptron ran in: 0.0018072128295898438 sec\n",
            "multilayer_perceptron ran in: 0.002486705780029297 sec\n",
            "multilayer_perceptron ran in: 0.0018417835235595703 sec\n",
            "multilayer_perceptron ran in: 0.002225637435913086 sec\n",
            "multilayer_perceptron ran in: 0.0018129348754882812 sec\n",
            "multilayer_perceptron ran in: 0.001941680908203125 sec\n",
            "multilayer_perceptron ran in: 0.0033140182495117188 sec\n",
            "multilayer_perceptron ran in: 0.0021278858184814453 sec\n",
            "multilayer_perceptron ran in: 0.001867532730102539 sec\n",
            "multilayer_perceptron ran in: 0.0018475055694580078 sec\n",
            "multilayer_perceptron ran in: 0.0018970966339111328 sec\n",
            "multilayer_perceptron ran in: 0.0019421577453613281 sec\n",
            "multilayer_perceptron ran in: 0.0018684864044189453 sec\n",
            "multilayer_perceptron ran in: 0.0018992424011230469 sec\n",
            "multilayer_perceptron ran in: 0.0018455982208251953 sec\n",
            "multilayer_perceptron ran in: 0.0019488334655761719 sec\n",
            "multilayer_perceptron ran in: 0.0018513202667236328 sec\n",
            "multilayer_perceptron ran in: 0.0018794536590576172 sec\n",
            "multilayer_perceptron ran in: 0.0019123554229736328 sec\n",
            "multilayer_perceptron ran in: 0.0019130706787109375 sec\n",
            "multilayer_perceptron ran in: 0.0024597644805908203 sec\n",
            "multilayer_perceptron ran in: 0.0018203258514404297 sec\n",
            "multilayer_perceptron ran in: 0.0017986297607421875 sec\n",
            "multilayer_perceptron ran in: 0.001842498779296875 sec\n",
            "multilayer_perceptron ran in: 0.0020689964294433594 sec\n",
            "multilayer_perceptron ran in: 0.0017008781433105469 sec\n",
            "multilayer_perceptron ran in: 0.0018651485443115234 sec\n",
            "multilayer_perceptron ran in: 0.001967906951904297 sec\n",
            "multilayer_perceptron ran in: 0.003185272216796875 sec\n",
            "multilayer_perceptron ran in: 0.0019283294677734375 sec\n",
            "multilayer_perceptron ran in: 0.0018107891082763672 sec\n",
            "multilayer_perceptron ran in: 0.0019123554229736328 sec\n",
            "multilayer_perceptron ran in: 0.0017852783203125 sec\n",
            "multilayer_perceptron ran in: 0.0019214153289794922 sec\n",
            "multilayer_perceptron ran in: 0.0019080638885498047 sec\n",
            "multilayer_perceptron ran in: 0.0019221305847167969 sec\n",
            "multilayer_perceptron ran in: 0.0019083023071289062 sec\n",
            "multilayer_perceptron ran in: 0.002008199691772461 sec\n",
            "multilayer_perceptron ran in: 0.0018796920776367188 sec\n",
            "multilayer_perceptron ran in: 0.002110004425048828 sec\n",
            "multilayer_perceptron ran in: 0.0019598007202148438 sec\n",
            "multilayer_perceptron ran in: 0.0017206668853759766 sec\n",
            "multilayer_perceptron ran in: 0.0018260478973388672 sec\n",
            "multilayer_perceptron ran in: 0.0016777515411376953 sec\n",
            "multilayer_perceptron ran in: 0.002405405044555664 sec\n",
            "multilayer_perceptron ran in: 0.001888275146484375 sec\n",
            "multilayer_perceptron ran in: 0.001901865005493164 sec\n",
            "multilayer_perceptron ran in: 0.0019412040710449219 sec\n",
            "multilayer_perceptron ran in: 0.0019621849060058594 sec\n",
            "multilayer_perceptron ran in: 0.0019164085388183594 sec\n",
            "multilayer_perceptron ran in: 0.002355337142944336 sec\n",
            "multilayer_perceptron ran in: 0.003200054168701172 sec\n",
            "multilayer_perceptron ran in: 0.0019345283508300781 sec\n",
            "multilayer_perceptron ran in: 0.0021402835845947266 sec\n",
            "multilayer_perceptron ran in: 0.0019936561584472656 sec\n",
            "multilayer_perceptron ran in: 0.0019698143005371094 sec\n",
            "multilayer_perceptron ran in: 0.0018215179443359375 sec\n",
            "multilayer_perceptron ran in: 0.0018024444580078125 sec\n",
            "multilayer_perceptron ran in: 0.0018558502197265625 sec\n",
            "multilayer_perceptron ran in: 0.0018310546875 sec\n",
            "multilayer_perceptron ran in: 0.0018544197082519531 sec\n",
            "multilayer_perceptron ran in: 0.002194643020629883 sec\n",
            "multilayer_perceptron ran in: 0.0021555423736572266 sec\n",
            "multilayer_perceptron ran in: 0.0019025802612304688 sec\n",
            "multilayer_perceptron ran in: 0.002321004867553711 sec\n",
            "multilayer_perceptron ran in: 0.0020284652709960938 sec\n",
            "multilayer_perceptron ran in: 0.0019783973693847656 sec\n",
            "multilayer_perceptron ran in: 0.0017957687377929688 sec\n",
            "multilayer_perceptron ran in: 0.001894235610961914 sec\n",
            "multilayer_perceptron ran in: 0.0017547607421875 sec\n",
            "multilayer_perceptron ran in: 0.0017361640930175781 sec\n",
            "multilayer_perceptron ran in: 0.001863241195678711 sec\n",
            "multilayer_perceptron ran in: 0.001901865005493164 sec\n",
            "multilayer_perceptron ran in: 0.001905202865600586 sec\n",
            "multilayer_perceptron ran in: 0.0022187232971191406 sec\n",
            "Epoch: 2 Cost=17640.0645\n",
            "multilayer_perceptron ran in: 0.0017604827880859375 sec\n",
            "multilayer_perceptron ran in: 0.001918792724609375 sec\n",
            "multilayer_perceptron ran in: 0.0018169879913330078 sec\n",
            "multilayer_perceptron ran in: 0.002187490463256836 sec\n",
            "multilayer_perceptron ran in: 0.0019004344940185547 sec\n",
            "multilayer_perceptron ran in: 0.0018761157989501953 sec\n",
            "multilayer_perceptron ran in: 0.0019881725311279297 sec\n",
            "multilayer_perceptron ran in: 0.0018069744110107422 sec\n",
            "multilayer_perceptron ran in: 0.0018427371978759766 sec\n",
            "multilayer_perceptron ran in: 0.0025577545166015625 sec\n",
            "multilayer_perceptron ran in: 0.0019409656524658203 sec\n",
            "multilayer_perceptron ran in: 0.0018138885498046875 sec\n",
            "multilayer_perceptron ran in: 0.0018668174743652344 sec\n",
            "multilayer_perceptron ran in: 0.0019009113311767578 sec\n",
            "multilayer_perceptron ran in: 0.0018792152404785156 sec\n",
            "multilayer_perceptron ran in: 0.0025560855865478516 sec\n",
            "multilayer_perceptron ran in: 0.001936197280883789 sec\n",
            "multilayer_perceptron ran in: 0.0018460750579833984 sec\n",
            "multilayer_perceptron ran in: 0.001753091812133789 sec\n",
            "multilayer_perceptron ran in: 0.0019130706787109375 sec\n",
            "multilayer_perceptron ran in: 0.001859903335571289 sec\n",
            "multilayer_perceptron ran in: 0.0030248165130615234 sec\n",
            "multilayer_perceptron ran in: 0.0023183822631835938 sec\n",
            "multilayer_perceptron ran in: 0.0022101402282714844 sec\n",
            "multilayer_perceptron ran in: 0.0018379688262939453 sec\n",
            "multilayer_perceptron ran in: 0.0019233226776123047 sec\n",
            "multilayer_perceptron ran in: 0.0018091201782226562 sec\n",
            "multilayer_perceptron ran in: 0.0020439624786376953 sec\n",
            "multilayer_perceptron ran in: 0.002199888229370117 sec\n",
            "multilayer_perceptron ran in: 0.0021941661834716797 sec\n",
            "multilayer_perceptron ran in: 0.002366304397583008 sec\n",
            "multilayer_perceptron ran in: 0.001867055892944336 sec\n",
            "multilayer_perceptron ran in: 0.001920461654663086 sec\n",
            "multilayer_perceptron ran in: 0.0018315315246582031 sec\n",
            "multilayer_perceptron ran in: 0.0019297599792480469 sec\n",
            "multilayer_perceptron ran in: 0.0018079280853271484 sec\n",
            "multilayer_perceptron ran in: 0.001966714859008789 sec\n",
            "multilayer_perceptron ran in: 0.0027904510498046875 sec\n",
            "multilayer_perceptron ran in: 0.002562999725341797 sec\n",
            "multilayer_perceptron ran in: 0.002337217330932617 sec\n",
            "multilayer_perceptron ran in: 0.0018434524536132812 sec\n",
            "multilayer_perceptron ran in: 0.0018503665924072266 sec\n",
            "multilayer_perceptron ran in: 0.0020825862884521484 sec\n",
            "multilayer_perceptron ran in: 0.002192974090576172 sec\n",
            "multilayer_perceptron ran in: 0.001928567886352539 sec\n",
            "multilayer_perceptron ran in: 0.0029175281524658203 sec\n",
            "multilayer_perceptron ran in: 0.0023975372314453125 sec\n",
            "multilayer_perceptron ran in: 0.0027344226837158203 sec\n",
            "multilayer_perceptron ran in: 0.002330303192138672 sec\n",
            "multilayer_perceptron ran in: 0.0021271705627441406 sec\n",
            "multilayer_perceptron ran in: 0.0025129318237304688 sec\n",
            "multilayer_perceptron ran in: 0.0024421215057373047 sec\n",
            "multilayer_perceptron ran in: 0.0023956298828125 sec\n",
            "multilayer_perceptron ran in: 0.0024254322052001953 sec\n",
            "multilayer_perceptron ran in: 0.002328157424926758 sec\n",
            "multilayer_perceptron ran in: 0.0022754669189453125 sec\n",
            "multilayer_perceptron ran in: 0.0027921199798583984 sec\n",
            "multilayer_perceptron ran in: 0.0022194385528564453 sec\n",
            "multilayer_perceptron ran in: 0.005650758743286133 sec\n",
            "multilayer_perceptron ran in: 0.0021452903747558594 sec\n",
            "multilayer_perceptron ran in: 0.0020780563354492188 sec\n",
            "multilayer_perceptron ran in: 0.002239704132080078 sec\n",
            "multilayer_perceptron ran in: 0.002614736557006836 sec\n",
            "multilayer_perceptron ran in: 0.00270843505859375 sec\n",
            "multilayer_perceptron ran in: 0.0027000904083251953 sec\n",
            "multilayer_perceptron ran in: 0.0031919479370117188 sec\n",
            "multilayer_perceptron ran in: 0.0029141902923583984 sec\n",
            "multilayer_perceptron ran in: 0.0023851394653320312 sec\n",
            "multilayer_perceptron ran in: 0.0022978782653808594 sec\n",
            "multilayer_perceptron ran in: 0.00238037109375 sec\n",
            "multilayer_perceptron ran in: 0.0023522377014160156 sec\n",
            "multilayer_perceptron ran in: 0.0018868446350097656 sec\n",
            "multilayer_perceptron ran in: 0.0026845932006835938 sec\n",
            "multilayer_perceptron ran in: 0.0058286190032958984 sec\n",
            "multilayer_perceptron ran in: 0.0020754337310791016 sec\n",
            "multilayer_perceptron ran in: 0.002460956573486328 sec\n",
            "multilayer_perceptron ran in: 0.002737283706665039 sec\n",
            "multilayer_perceptron ran in: 0.002594470977783203 sec\n",
            "multilayer_perceptron ran in: 0.0023987293243408203 sec\n",
            "multilayer_perceptron ran in: 0.0024781227111816406 sec\n",
            "multilayer_perceptron ran in: 0.0031545162200927734 sec\n",
            "multilayer_perceptron ran in: 0.0024366378784179688 sec\n",
            "multilayer_perceptron ran in: 0.00446319580078125 sec\n",
            "multilayer_perceptron ran in: 0.0068514347076416016 sec\n",
            "multilayer_perceptron ran in: 0.0028197765350341797 sec\n",
            "multilayer_perceptron ran in: 0.002620697021484375 sec\n",
            "multilayer_perceptron ran in: 0.002836942672729492 sec\n",
            "multilayer_perceptron ran in: 0.0032155513763427734 sec\n",
            "multilayer_perceptron ran in: 0.002701997756958008 sec\n",
            "multilayer_perceptron ran in: 0.0018494129180908203 sec\n",
            "multilayer_perceptron ran in: 0.003400564193725586 sec\n",
            "multilayer_perceptron ran in: 0.002028226852416992 sec\n",
            "multilayer_perceptron ran in: 0.0018463134765625 sec\n",
            "multilayer_perceptron ran in: 0.001959562301635742 sec\n",
            "multilayer_perceptron ran in: 0.0021750926971435547 sec\n",
            "multilayer_perceptron ran in: 0.0018608570098876953 sec\n",
            "multilayer_perceptron ran in: 0.0019021034240722656 sec\n",
            "multilayer_perceptron ran in: 0.001840353012084961 sec\n",
            "multilayer_perceptron ran in: 0.0017561912536621094 sec\n",
            "multilayer_perceptron ran in: 0.0017621517181396484 sec\n",
            "multilayer_perceptron ran in: 0.0019145011901855469 sec\n",
            "multilayer_perceptron ran in: 0.002119302749633789 sec\n",
            "multilayer_perceptron ran in: 0.001951456069946289 sec\n",
            "multilayer_perceptron ran in: 0.0017189979553222656 sec\n",
            "multilayer_perceptron ran in: 0.0018672943115234375 sec\n",
            "multilayer_perceptron ran in: 0.0018992424011230469 sec\n",
            "multilayer_perceptron ran in: 0.0024373531341552734 sec\n",
            "multilayer_perceptron ran in: 0.0018210411071777344 sec\n",
            "multilayer_perceptron ran in: 0.0018336772918701172 sec\n",
            "multilayer_perceptron ran in: 0.0019016265869140625 sec\n",
            "multilayer_perceptron ran in: 0.0018625259399414062 sec\n",
            "multilayer_perceptron ran in: 0.0021371841430664062 sec\n",
            "multilayer_perceptron ran in: 0.0018115043640136719 sec\n",
            "multilayer_perceptron ran in: 0.0019867420196533203 sec\n",
            "multilayer_perceptron ran in: 0.0017993450164794922 sec\n",
            "multilayer_perceptron ran in: 0.0017571449279785156 sec\n",
            "multilayer_perceptron ran in: 0.0018875598907470703 sec\n",
            "multilayer_perceptron ran in: 0.0019426345825195312 sec\n",
            "multilayer_perceptron ran in: 0.0017740726470947266 sec\n",
            "multilayer_perceptron ran in: 0.0022020339965820312 sec\n",
            "multilayer_perceptron ran in: 0.001821756362915039 sec\n",
            "multilayer_perceptron ran in: 0.004011631011962891 sec\n",
            "multilayer_perceptron ran in: 0.0020890235900878906 sec\n",
            "multilayer_perceptron ran in: 0.001867532730102539 sec\n",
            "multilayer_perceptron ran in: 0.0019390583038330078 sec\n",
            "multilayer_perceptron ran in: 0.002391815185546875 sec\n",
            "multilayer_perceptron ran in: 0.0017974376678466797 sec\n",
            "multilayer_perceptron ran in: 0.0018246173858642578 sec\n",
            "multilayer_perceptron ran in: 0.0018351078033447266 sec\n",
            "multilayer_perceptron ran in: 0.0019307136535644531 sec\n",
            "multilayer_perceptron ran in: 0.001949310302734375 sec\n",
            "multilayer_perceptron ran in: 0.002318859100341797 sec\n",
            "multilayer_perceptron ran in: 0.0019588470458984375 sec\n",
            "multilayer_perceptron ran in: 0.0019314289093017578 sec\n",
            "multilayer_perceptron ran in: 0.001806020736694336 sec\n",
            "multilayer_perceptron ran in: 0.0025386810302734375 sec\n",
            "multilayer_perceptron ran in: 0.0018723011016845703 sec\n",
            "multilayer_perceptron ran in: 0.0022537708282470703 sec\n",
            "multilayer_perceptron ran in: 0.0018086433410644531 sec\n",
            "multilayer_perceptron ran in: 0.0018231868743896484 sec\n",
            "multilayer_perceptron ran in: 0.0019047260284423828 sec\n",
            "multilayer_perceptron ran in: 0.0018203258514404297 sec\n",
            "multilayer_perceptron ran in: 0.0020339488983154297 sec\n",
            "multilayer_perceptron ran in: 0.0019974708557128906 sec\n",
            "multilayer_perceptron ran in: 0.0019330978393554688 sec\n",
            "multilayer_perceptron ran in: 0.0019333362579345703 sec\n",
            "multilayer_perceptron ran in: 0.0017337799072265625 sec\n",
            "multilayer_perceptron ran in: 0.0017952919006347656 sec\n",
            "multilayer_perceptron ran in: 0.0019345283508300781 sec\n",
            "multilayer_perceptron ran in: 0.00179290771484375 sec\n",
            "multilayer_perceptron ran in: 0.0020744800567626953 sec\n",
            "multilayer_perceptron ran in: 0.0018436908721923828 sec\n",
            "multilayer_perceptron ran in: 0.0018248558044433594 sec\n",
            "multilayer_perceptron ran in: 0.0022902488708496094 sec\n",
            "multilayer_perceptron ran in: 0.0018286705017089844 sec\n",
            "multilayer_perceptron ran in: 0.0019459724426269531 sec\n",
            "multilayer_perceptron ran in: 0.0020694732666015625 sec\n",
            "multilayer_perceptron ran in: 0.0018851757049560547 sec\n",
            "multilayer_perceptron ran in: 0.002615690231323242 sec\n",
            "multilayer_perceptron ran in: 0.0021741390228271484 sec\n",
            "multilayer_perceptron ran in: 0.001905679702758789 sec\n",
            "multilayer_perceptron ran in: 0.002210378646850586 sec\n",
            "multilayer_perceptron ran in: 0.0018875598907470703 sec\n",
            "multilayer_perceptron ran in: 0.0042285919189453125 sec\n",
            "multilayer_perceptron ran in: 0.002482175827026367 sec\n",
            "multilayer_perceptron ran in: 0.002161741256713867 sec\n",
            "multilayer_perceptron ran in: 0.0020537376403808594 sec\n",
            "multilayer_perceptron ran in: 0.0017948150634765625 sec\n",
            "multilayer_perceptron ran in: 0.0017955303192138672 sec\n",
            "multilayer_perceptron ran in: 0.00189208984375 sec\n",
            "multilayer_perceptron ran in: 0.0017940998077392578 sec\n",
            "multilayer_perceptron ran in: 0.001865386962890625 sec\n",
            "multilayer_perceptron ran in: 0.0017015933990478516 sec\n",
            "multilayer_perceptron ran in: 0.002189159393310547 sec\n",
            "multilayer_perceptron ran in: 0.001961946487426758 sec\n",
            "multilayer_perceptron ran in: 0.0025615692138671875 sec\n",
            "multilayer_perceptron ran in: 0.0018851757049560547 sec\n",
            "multilayer_perceptron ran in: 0.0018897056579589844 sec\n",
            "multilayer_perceptron ran in: 0.001987457275390625 sec\n",
            "multilayer_perceptron ran in: 0.002017498016357422 sec\n",
            "multilayer_perceptron ran in: 0.0023152828216552734 sec\n",
            "multilayer_perceptron ran in: 0.002375364303588867 sec\n",
            "multilayer_perceptron ran in: 0.0019817352294921875 sec\n",
            "multilayer_perceptron ran in: 0.0020134449005126953 sec\n",
            "multilayer_perceptron ran in: 0.0018374919891357422 sec\n",
            "multilayer_perceptron ran in: 0.0018858909606933594 sec\n",
            "multilayer_perceptron ran in: 0.0017774105072021484 sec\n",
            "multilayer_perceptron ran in: 0.0019452571868896484 sec\n",
            "multilayer_perceptron ran in: 0.001888275146484375 sec\n",
            "multilayer_perceptron ran in: 0.0021681785583496094 sec\n",
            "multilayer_perceptron ran in: 0.002680063247680664 sec\n",
            "multilayer_perceptron ran in: 0.0019865036010742188 sec\n",
            "multilayer_perceptron ran in: 0.001970052719116211 sec\n",
            "multilayer_perceptron ran in: 0.0019297599792480469 sec\n",
            "multilayer_perceptron ran in: 0.0018057823181152344 sec\n",
            "multilayer_perceptron ran in: 0.0020339488983154297 sec\n",
            "multilayer_perceptron ran in: 0.0020837783813476562 sec\n",
            "multilayer_perceptron ran in: 0.0027005672454833984 sec\n",
            "multilayer_perceptron ran in: 0.0016720294952392578 sec\n",
            "multilayer_perceptron ran in: 0.002792835235595703 sec\n",
            "multilayer_perceptron ran in: 0.0020058155059814453 sec\n",
            "multilayer_perceptron ran in: 0.001840353012084961 sec\n",
            "multilayer_perceptron ran in: 0.0024111270904541016 sec\n",
            "multilayer_perceptron ran in: 0.0017833709716796875 sec\n",
            "multilayer_perceptron ran in: 0.0018992424011230469 sec\n",
            "multilayer_perceptron ran in: 0.0019757747650146484 sec\n",
            "multilayer_perceptron ran in: 0.0023937225341796875 sec\n",
            "multilayer_perceptron ran in: 0.001967191696166992 sec\n",
            "multilayer_perceptron ran in: 0.0017921924591064453 sec\n",
            "multilayer_perceptron ran in: 0.0024001598358154297 sec\n",
            "multilayer_perceptron ran in: 0.0019049644470214844 sec\n",
            "multilayer_perceptron ran in: 0.001882791519165039 sec\n",
            "multilayer_perceptron ran in: 0.0018985271453857422 sec\n",
            "multilayer_perceptron ran in: 0.0019168853759765625 sec\n",
            "multilayer_perceptron ran in: 0.0017857551574707031 sec\n",
            "multilayer_perceptron ran in: 0.0018093585968017578 sec\n",
            "multilayer_perceptron ran in: 0.0018420219421386719 sec\n",
            "multilayer_perceptron ran in: 0.0021364688873291016 sec\n",
            "multilayer_perceptron ran in: 0.0019648075103759766 sec\n",
            "multilayer_perceptron ran in: 0.0020363330841064453 sec\n",
            "multilayer_perceptron ran in: 0.002012491226196289 sec\n",
            "multilayer_perceptron ran in: 0.0019347667694091797 sec\n",
            "multilayer_perceptron ran in: 0.0018978118896484375 sec\n",
            "multilayer_perceptron ran in: 0.0017735958099365234 sec\n",
            "multilayer_perceptron ran in: 0.003046274185180664 sec\n",
            "multilayer_perceptron ran in: 0.0019752979278564453 sec\n",
            "multilayer_perceptron ran in: 0.002268075942993164 sec\n",
            "multilayer_perceptron ran in: 0.0017268657684326172 sec\n",
            "multilayer_perceptron ran in: 0.0024378299713134766 sec\n",
            "multilayer_perceptron ran in: 0.003838777542114258 sec\n",
            "multilayer_perceptron ran in: 0.004674196243286133 sec\n",
            "multilayer_perceptron ran in: 0.002019166946411133 sec\n",
            "multilayer_perceptron ran in: 0.0020301342010498047 sec\n",
            "multilayer_perceptron ran in: 0.001918792724609375 sec\n",
            "multilayer_perceptron ran in: 0.0019845962524414062 sec\n",
            "multilayer_perceptron ran in: 0.0019850730895996094 sec\n",
            "multilayer_perceptron ran in: 0.002209901809692383 sec\n",
            "multilayer_perceptron ran in: 0.0019903182983398438 sec\n",
            "multilayer_perceptron ran in: 0.00193023681640625 sec\n",
            "multilayer_perceptron ran in: 0.0019059181213378906 sec\n",
            "Epoch: 3 Cost=5811.6553\n",
            "multilayer_perceptron ran in: 0.0018947124481201172 sec\n",
            "multilayer_perceptron ran in: 0.003049612045288086 sec\n",
            "multilayer_perceptron ran in: 0.0020024776458740234 sec\n",
            "multilayer_perceptron ran in: 0.002043485641479492 sec\n",
            "multilayer_perceptron ran in: 0.002135038375854492 sec\n",
            "multilayer_perceptron ran in: 0.001964569091796875 sec\n",
            "multilayer_perceptron ran in: 0.0018928050994873047 sec\n",
            "multilayer_perceptron ran in: 0.0018444061279296875 sec\n",
            "multilayer_perceptron ran in: 0.0018987655639648438 sec\n",
            "multilayer_perceptron ran in: 0.0023658275604248047 sec\n",
            "multilayer_perceptron ran in: 0.003289461135864258 sec\n",
            "multilayer_perceptron ran in: 0.002646207809448242 sec\n",
            "multilayer_perceptron ran in: 0.001992940902709961 sec\n",
            "multilayer_perceptron ran in: 0.0019299983978271484 sec\n",
            "multilayer_perceptron ran in: 0.0019974708557128906 sec\n",
            "multilayer_perceptron ran in: 0.0018391609191894531 sec\n",
            "multilayer_perceptron ran in: 0.0019860267639160156 sec\n",
            "multilayer_perceptron ran in: 0.001998424530029297 sec\n",
            "multilayer_perceptron ran in: 0.0018527507781982422 sec\n",
            "multilayer_perceptron ran in: 0.0018208026885986328 sec\n",
            "multilayer_perceptron ran in: 0.0017921924591064453 sec\n",
            "multilayer_perceptron ran in: 0.0041120052337646484 sec\n",
            "multilayer_perceptron ran in: 0.001979827880859375 sec\n",
            "multilayer_perceptron ran in: 0.002542734146118164 sec\n",
            "multilayer_perceptron ran in: 0.001985311508178711 sec\n",
            "multilayer_perceptron ran in: 0.0018687248229980469 sec\n",
            "multilayer_perceptron ran in: 0.001909494400024414 sec\n",
            "multilayer_perceptron ran in: 0.0025568008422851562 sec\n",
            "multilayer_perceptron ran in: 0.00215911865234375 sec\n",
            "multilayer_perceptron ran in: 0.0032796859741210938 sec\n",
            "multilayer_perceptron ran in: 0.0018241405487060547 sec\n",
            "multilayer_perceptron ran in: 0.0019080638885498047 sec\n",
            "multilayer_perceptron ran in: 0.0023484230041503906 sec\n",
            "multilayer_perceptron ran in: 0.002125978469848633 sec\n",
            "multilayer_perceptron ran in: 0.001972675323486328 sec\n",
            "multilayer_perceptron ran in: 0.0018241405487060547 sec\n",
            "multilayer_perceptron ran in: 0.003095865249633789 sec\n",
            "multilayer_perceptron ran in: 0.0018253326416015625 sec\n",
            "multilayer_perceptron ran in: 0.001890420913696289 sec\n",
            "multilayer_perceptron ran in: 0.001867055892944336 sec\n",
            "multilayer_perceptron ran in: 0.0018503665924072266 sec\n",
            "multilayer_perceptron ran in: 0.0018360614776611328 sec\n",
            "multilayer_perceptron ran in: 0.0017979145050048828 sec\n",
            "multilayer_perceptron ran in: 0.0017852783203125 sec\n",
            "multilayer_perceptron ran in: 0.001966238021850586 sec\n",
            "multilayer_perceptron ran in: 0.0017600059509277344 sec\n",
            "multilayer_perceptron ran in: 0.002471923828125 sec\n",
            "multilayer_perceptron ran in: 0.002127408981323242 sec\n",
            "multilayer_perceptron ran in: 0.0017769336700439453 sec\n",
            "multilayer_perceptron ran in: 0.0018982887268066406 sec\n",
            "multilayer_perceptron ran in: 0.0019071102142333984 sec\n",
            "multilayer_perceptron ran in: 0.0044252872467041016 sec\n",
            "multilayer_perceptron ran in: 0.0020186901092529297 sec\n",
            "multilayer_perceptron ran in: 0.0020897388458251953 sec\n",
            "multilayer_perceptron ran in: 0.00189208984375 sec\n",
            "multilayer_perceptron ran in: 0.002012491226196289 sec\n",
            "multilayer_perceptron ran in: 0.0018684864044189453 sec\n",
            "multilayer_perceptron ran in: 0.001978158950805664 sec\n",
            "multilayer_perceptron ran in: 0.002414226531982422 sec\n",
            "multilayer_perceptron ran in: 0.0019156932830810547 sec\n",
            "multilayer_perceptron ran in: 0.0017962455749511719 sec\n",
            "multilayer_perceptron ran in: 0.0019376277923583984 sec\n",
            "multilayer_perceptron ran in: 0.0017631053924560547 sec\n",
            "multilayer_perceptron ran in: 0.0017139911651611328 sec\n",
            "multilayer_perceptron ran in: 0.0017845630645751953 sec\n",
            "multilayer_perceptron ran in: 0.0017552375793457031 sec\n",
            "multilayer_perceptron ran in: 0.0017986297607421875 sec\n",
            "multilayer_perceptron ran in: 0.0018002986907958984 sec\n",
            "multilayer_perceptron ran in: 0.0019605159759521484 sec\n",
            "multilayer_perceptron ran in: 0.001949310302734375 sec\n",
            "multilayer_perceptron ran in: 0.0017402172088623047 sec\n",
            "multilayer_perceptron ran in: 0.0019648075103759766 sec\n",
            "multilayer_perceptron ran in: 0.0018177032470703125 sec\n",
            "multilayer_perceptron ran in: 0.0030388832092285156 sec\n",
            "multilayer_perceptron ran in: 0.002523183822631836 sec\n",
            "multilayer_perceptron ran in: 0.002419710159301758 sec\n",
            "multilayer_perceptron ran in: 0.002187013626098633 sec\n",
            "multilayer_perceptron ran in: 0.002100706100463867 sec\n",
            "multilayer_perceptron ran in: 0.003057718276977539 sec\n",
            "multilayer_perceptron ran in: 0.0020835399627685547 sec\n",
            "multilayer_perceptron ran in: 0.002347707748413086 sec\n",
            "multilayer_perceptron ran in: 0.0020923614501953125 sec\n",
            "multilayer_perceptron ran in: 0.0021491050720214844 sec\n",
            "multilayer_perceptron ran in: 0.002145051956176758 sec\n",
            "multilayer_perceptron ran in: 0.002112865447998047 sec\n",
            "multilayer_perceptron ran in: 0.0021626949310302734 sec\n",
            "multilayer_perceptron ran in: 0.0022003650665283203 sec\n",
            "multilayer_perceptron ran in: 0.002371072769165039 sec\n",
            "multilayer_perceptron ran in: 0.002361297607421875 sec\n",
            "multilayer_perceptron ran in: 0.002054452896118164 sec\n",
            "multilayer_perceptron ran in: 0.0021364688873291016 sec\n",
            "multilayer_perceptron ran in: 0.003037691116333008 sec\n",
            "multilayer_perceptron ran in: 0.002707958221435547 sec\n",
            "multilayer_perceptron ran in: 0.0022323131561279297 sec\n",
            "multilayer_perceptron ran in: 0.0021131038665771484 sec\n",
            "multilayer_perceptron ran in: 0.0053212642669677734 sec\n",
            "multilayer_perceptron ran in: 0.002386808395385742 sec\n",
            "multilayer_perceptron ran in: 0.002803325653076172 sec\n",
            "multilayer_perceptron ran in: 0.0025606155395507812 sec\n",
            "multilayer_perceptron ran in: 0.002447843551635742 sec\n",
            "multilayer_perceptron ran in: 0.002249002456665039 sec\n",
            "multilayer_perceptron ran in: 0.002482175827026367 sec\n",
            "multilayer_perceptron ran in: 0.0026586055755615234 sec\n",
            "multilayer_perceptron ran in: 0.0023720264434814453 sec\n",
            "multilayer_perceptron ran in: 0.002552509307861328 sec\n",
            "multilayer_perceptron ran in: 0.00247955322265625 sec\n",
            "multilayer_perceptron ran in: 0.002384662628173828 sec\n",
            "multilayer_perceptron ran in: 0.002473115921020508 sec\n",
            "multilayer_perceptron ran in: 0.0023310184478759766 sec\n",
            "multilayer_perceptron ran in: 0.0022859573364257812 sec\n",
            "multilayer_perceptron ran in: 0.0022940635681152344 sec\n",
            "multilayer_perceptron ran in: 0.0023276805877685547 sec\n",
            "multilayer_perceptron ran in: 0.002186298370361328 sec\n",
            "multilayer_perceptron ran in: 0.0025556087493896484 sec\n",
            "multilayer_perceptron ran in: 0.0022385120391845703 sec\n",
            "multilayer_perceptron ran in: 0.0022368431091308594 sec\n",
            "multilayer_perceptron ran in: 0.002230405807495117 sec\n",
            "multilayer_perceptron ran in: 0.0022466182708740234 sec\n",
            "multilayer_perceptron ran in: 0.002480030059814453 sec\n",
            "multilayer_perceptron ran in: 0.002823352813720703 sec\n",
            "multilayer_perceptron ran in: 0.00235748291015625 sec\n",
            "multilayer_perceptron ran in: 0.0022923946380615234 sec\n",
            "multilayer_perceptron ran in: 0.0023605823516845703 sec\n",
            "multilayer_perceptron ran in: 0.0023622512817382812 sec\n",
            "multilayer_perceptron ran in: 0.002738475799560547 sec\n",
            "multilayer_perceptron ran in: 0.0029892921447753906 sec\n",
            "multilayer_perceptron ran in: 0.006940126419067383 sec\n",
            "multilayer_perceptron ran in: 0.0024569034576416016 sec\n",
            "multilayer_perceptron ran in: 0.004906177520751953 sec\n",
            "multilayer_perceptron ran in: 0.0030117034912109375 sec\n",
            "multilayer_perceptron ran in: 0.0018374919891357422 sec\n",
            "multilayer_perceptron ran in: 0.002015829086303711 sec\n",
            "multilayer_perceptron ran in: 0.0018630027770996094 sec\n",
            "multilayer_perceptron ran in: 0.00183868408203125 sec\n",
            "multilayer_perceptron ran in: 0.001834869384765625 sec\n",
            "multilayer_perceptron ran in: 0.0017580986022949219 sec\n",
            "multilayer_perceptron ran in: 0.0017976760864257812 sec\n",
            "multilayer_perceptron ran in: 0.0017993450164794922 sec\n",
            "multilayer_perceptron ran in: 0.0018923282623291016 sec\n",
            "multilayer_perceptron ran in: 0.0029332637786865234 sec\n",
            "multilayer_perceptron ran in: 0.0018372535705566406 sec\n",
            "multilayer_perceptron ran in: 0.0019905567169189453 sec\n",
            "multilayer_perceptron ran in: 0.001886129379272461 sec\n",
            "multilayer_perceptron ran in: 0.0017399787902832031 sec\n",
            "multilayer_perceptron ran in: 0.0018019676208496094 sec\n",
            "multilayer_perceptron ran in: 0.0025129318237304688 sec\n",
            "multilayer_perceptron ran in: 0.0016634464263916016 sec\n",
            "multilayer_perceptron ran in: 0.0018079280853271484 sec\n",
            "multilayer_perceptron ran in: 0.0017495155334472656 sec\n",
            "multilayer_perceptron ran in: 0.0020904541015625 sec\n",
            "multilayer_perceptron ran in: 0.001819610595703125 sec\n",
            "multilayer_perceptron ran in: 0.0021882057189941406 sec\n",
            "multilayer_perceptron ran in: 0.001819610595703125 sec\n",
            "multilayer_perceptron ran in: 0.0017557144165039062 sec\n",
            "multilayer_perceptron ran in: 0.0018491744995117188 sec\n",
            "multilayer_perceptron ran in: 0.0018463134765625 sec\n",
            "multilayer_perceptron ran in: 0.0020570755004882812 sec\n",
            "multilayer_perceptron ran in: 0.001953601837158203 sec\n",
            "multilayer_perceptron ran in: 0.0020694732666015625 sec\n",
            "multilayer_perceptron ran in: 0.0018649101257324219 sec\n",
            "multilayer_perceptron ran in: 0.003775358200073242 sec\n",
            "multilayer_perceptron ran in: 0.0019550323486328125 sec\n",
            "multilayer_perceptron ran in: 0.0018503665924072266 sec\n",
            "multilayer_perceptron ran in: 0.0018148422241210938 sec\n",
            "multilayer_perceptron ran in: 0.001817464828491211 sec\n",
            "multilayer_perceptron ran in: 0.0020554065704345703 sec\n",
            "multilayer_perceptron ran in: 0.001856088638305664 sec\n",
            "multilayer_perceptron ran in: 0.002984285354614258 sec\n",
            "multilayer_perceptron ran in: 0.0018703937530517578 sec\n",
            "multilayer_perceptron ran in: 0.0018453598022460938 sec\n",
            "multilayer_perceptron ran in: 0.0018584728240966797 sec\n",
            "multilayer_perceptron ran in: 0.0017888545989990234 sec\n",
            "multilayer_perceptron ran in: 0.0016641616821289062 sec\n",
            "multilayer_perceptron ran in: 0.001718759536743164 sec\n",
            "multilayer_perceptron ran in: 0.0018696784973144531 sec\n",
            "multilayer_perceptron ran in: 0.001931905746459961 sec\n",
            "multilayer_perceptron ran in: 0.0018532276153564453 sec\n",
            "multilayer_perceptron ran in: 0.0018963813781738281 sec\n",
            "multilayer_perceptron ran in: 0.0017504692077636719 sec\n",
            "multilayer_perceptron ran in: 0.0019652843475341797 sec\n",
            "multilayer_perceptron ran in: 0.001962900161743164 sec\n",
            "multilayer_perceptron ran in: 0.0029032230377197266 sec\n",
            "multilayer_perceptron ran in: 0.0026760101318359375 sec\n",
            "multilayer_perceptron ran in: 0.0017859935760498047 sec\n",
            "multilayer_perceptron ran in: 0.0020744800567626953 sec\n",
            "multilayer_perceptron ran in: 0.0019016265869140625 sec\n",
            "multilayer_perceptron ran in: 0.0018260478973388672 sec\n",
            "multilayer_perceptron ran in: 0.0022890567779541016 sec\n",
            "multilayer_perceptron ran in: 0.0020644664764404297 sec\n",
            "multilayer_perceptron ran in: 0.0022842884063720703 sec\n",
            "multilayer_perceptron ran in: 0.0019311904907226562 sec\n",
            "multilayer_perceptron ran in: 0.002386808395385742 sec\n",
            "multilayer_perceptron ran in: 0.0019855499267578125 sec\n",
            "multilayer_perceptron ran in: 0.0018305778503417969 sec\n",
            "multilayer_perceptron ran in: 0.0019092559814453125 sec\n",
            "multilayer_perceptron ran in: 0.0023915767669677734 sec\n",
            "multilayer_perceptron ran in: 0.0019686222076416016 sec\n",
            "multilayer_perceptron ran in: 0.0019588470458984375 sec\n",
            "multilayer_perceptron ran in: 0.002016782760620117 sec\n",
            "multilayer_perceptron ran in: 0.0018095970153808594 sec\n",
            "multilayer_perceptron ran in: 0.001768350601196289 sec\n",
            "multilayer_perceptron ran in: 0.0020601749420166016 sec\n",
            "multilayer_perceptron ran in: 0.0020017623901367188 sec\n",
            "multilayer_perceptron ran in: 0.0017516613006591797 sec\n",
            "multilayer_perceptron ran in: 0.004622936248779297 sec\n",
            "multilayer_perceptron ran in: 0.0018396377563476562 sec\n",
            "multilayer_perceptron ran in: 0.0018758773803710938 sec\n",
            "multilayer_perceptron ran in: 0.0019083023071289062 sec\n",
            "multilayer_perceptron ran in: 0.002858877182006836 sec\n",
            "multilayer_perceptron ran in: 0.0031070709228515625 sec\n",
            "multilayer_perceptron ran in: 0.0021393299102783203 sec\n",
            "multilayer_perceptron ran in: 0.0020551681518554688 sec\n",
            "multilayer_perceptron ran in: 0.001739501953125 sec\n",
            "multilayer_perceptron ran in: 0.0018584728240966797 sec\n",
            "multilayer_perceptron ran in: 0.0027933120727539062 sec\n",
            "multilayer_perceptron ran in: 0.0018534660339355469 sec\n",
            "multilayer_perceptron ran in: 0.0023877620697021484 sec\n",
            "multilayer_perceptron ran in: 0.0028486251831054688 sec\n",
            "multilayer_perceptron ran in: 0.0020101070404052734 sec\n",
            "multilayer_perceptron ran in: 0.0021638870239257812 sec\n",
            "multilayer_perceptron ran in: 0.002019643783569336 sec\n",
            "multilayer_perceptron ran in: 0.0023109912872314453 sec\n",
            "multilayer_perceptron ran in: 0.0017695426940917969 sec\n",
            "multilayer_perceptron ran in: 0.001851797103881836 sec\n",
            "multilayer_perceptron ran in: 0.0017592906951904297 sec\n",
            "multilayer_perceptron ran in: 0.0020122528076171875 sec\n",
            "multilayer_perceptron ran in: 0.001832723617553711 sec\n",
            "multilayer_perceptron ran in: 0.001767873764038086 sec\n",
            "multilayer_perceptron ran in: 0.001859426498413086 sec\n",
            "multilayer_perceptron ran in: 0.0019164085388183594 sec\n",
            "multilayer_perceptron ran in: 0.003721475601196289 sec\n",
            "multilayer_perceptron ran in: 0.002454042434692383 sec\n",
            "multilayer_perceptron ran in: 0.0017278194427490234 sec\n",
            "multilayer_perceptron ran in: 0.0018048286437988281 sec\n",
            "multilayer_perceptron ran in: 0.0017178058624267578 sec\n",
            "multilayer_perceptron ran in: 0.0018572807312011719 sec\n",
            "multilayer_perceptron ran in: 0.00182342529296875 sec\n",
            "multilayer_perceptron ran in: 0.0018260478973388672 sec\n",
            "multilayer_perceptron ran in: 0.001726388931274414 sec\n",
            "multilayer_perceptron ran in: 0.0017824172973632812 sec\n",
            "Epoch: 4 Cost=6571.4019\n",
            "multilayer_perceptron ran in: 0.0019087791442871094 sec\n",
            "multilayer_perceptron ran in: 0.0018706321716308594 sec\n",
            "multilayer_perceptron ran in: 0.001878499984741211 sec\n",
            "multilayer_perceptron ran in: 0.0019402503967285156 sec\n",
            "multilayer_perceptron ran in: 0.002460002899169922 sec\n",
            "multilayer_perceptron ran in: 0.0019021034240722656 sec\n",
            "multilayer_perceptron ran in: 0.0018620491027832031 sec\n",
            "multilayer_perceptron ran in: 0.0019183158874511719 sec\n",
            "multilayer_perceptron ran in: 0.0019481182098388672 sec\n",
            "multilayer_perceptron ran in: 0.0018856525421142578 sec\n",
            "multilayer_perceptron ran in: 0.0017857551574707031 sec\n",
            "multilayer_perceptron ran in: 0.0018177032470703125 sec\n",
            "multilayer_perceptron ran in: 0.0018093585968017578 sec\n",
            "multilayer_perceptron ran in: 0.001806020736694336 sec\n",
            "multilayer_perceptron ran in: 0.0018267631530761719 sec\n",
            "multilayer_perceptron ran in: 0.0019409656524658203 sec\n",
            "multilayer_perceptron ran in: 0.0019207000732421875 sec\n",
            "multilayer_perceptron ran in: 0.002290010452270508 sec\n",
            "multilayer_perceptron ran in: 0.0017981529235839844 sec\n",
            "multilayer_perceptron ran in: 0.0019261837005615234 sec\n",
            "multilayer_perceptron ran in: 0.0017769336700439453 sec\n",
            "multilayer_perceptron ran in: 0.0018265247344970703 sec\n",
            "multilayer_perceptron ran in: 0.002542257308959961 sec\n",
            "multilayer_perceptron ran in: 0.001947164535522461 sec\n",
            "multilayer_perceptron ran in: 0.0017859935760498047 sec\n",
            "multilayer_perceptron ran in: 0.0018973350524902344 sec\n",
            "multilayer_perceptron ran in: 0.0018379688262939453 sec\n",
            "multilayer_perceptron ran in: 0.00217437744140625 sec\n",
            "multilayer_perceptron ran in: 0.0018296241760253906 sec\n",
            "multilayer_perceptron ran in: 0.0017898082733154297 sec\n",
            "multilayer_perceptron ran in: 0.0017619132995605469 sec\n",
            "multilayer_perceptron ran in: 0.002377748489379883 sec\n",
            "multilayer_perceptron ran in: 0.0017728805541992188 sec\n",
            "multilayer_perceptron ran in: 0.001882791519165039 sec\n",
            "multilayer_perceptron ran in: 0.0020689964294433594 sec\n",
            "multilayer_perceptron ran in: 0.0018672943115234375 sec\n",
            "multilayer_perceptron ran in: 0.0019106864929199219 sec\n",
            "multilayer_perceptron ran in: 0.0020046234130859375 sec\n",
            "multilayer_perceptron ran in: 0.002390146255493164 sec\n",
            "multilayer_perceptron ran in: 0.0020978450775146484 sec\n",
            "multilayer_perceptron ran in: 0.0019071102142333984 sec\n",
            "multilayer_perceptron ran in: 0.002480030059814453 sec\n",
            "multilayer_perceptron ran in: 0.0024678707122802734 sec\n",
            "multilayer_perceptron ran in: 0.0017287731170654297 sec\n",
            "multilayer_perceptron ran in: 0.0018362998962402344 sec\n",
            "multilayer_perceptron ran in: 0.001814126968383789 sec\n",
            "multilayer_perceptron ran in: 0.0018110275268554688 sec\n",
            "multilayer_perceptron ran in: 0.0017199516296386719 sec\n",
            "multilayer_perceptron ran in: 0.0020995140075683594 sec\n",
            "multilayer_perceptron ran in: 0.0020830631256103516 sec\n",
            "multilayer_perceptron ran in: 0.0018243789672851562 sec\n",
            "multilayer_perceptron ran in: 0.0017971992492675781 sec\n",
            "multilayer_perceptron ran in: 0.002027750015258789 sec\n",
            "multilayer_perceptron ran in: 0.0019555091857910156 sec\n",
            "multilayer_perceptron ran in: 0.0019083023071289062 sec\n",
            "multilayer_perceptron ran in: 0.0018696784973144531 sec\n",
            "multilayer_perceptron ran in: 0.0019690990447998047 sec\n",
            "multilayer_perceptron ran in: 0.0018296241760253906 sec\n",
            "multilayer_perceptron ran in: 0.0020346641540527344 sec\n",
            "multilayer_perceptron ran in: 0.0038743019104003906 sec\n",
            "multilayer_perceptron ran in: 0.0026907920837402344 sec\n",
            "multilayer_perceptron ran in: 0.0019989013671875 sec\n",
            "multilayer_perceptron ran in: 0.0018000602722167969 sec\n",
            "multilayer_perceptron ran in: 0.0017855167388916016 sec\n",
            "multilayer_perceptron ran in: 0.0018990039825439453 sec\n",
            "multilayer_perceptron ran in: 0.0017583370208740234 sec\n",
            "multilayer_perceptron ran in: 0.002012491226196289 sec\n",
            "multilayer_perceptron ran in: 0.0017004013061523438 sec\n",
            "multilayer_perceptron ran in: 0.0017855167388916016 sec\n",
            "multilayer_perceptron ran in: 0.0016872882843017578 sec\n",
            "multilayer_perceptron ran in: 0.002349853515625 sec\n",
            "multilayer_perceptron ran in: 0.0020363330841064453 sec\n",
            "multilayer_perceptron ran in: 0.0021076202392578125 sec\n",
            "multilayer_perceptron ran in: 0.0017709732055664062 sec\n",
            "multilayer_perceptron ran in: 0.0025246143341064453 sec\n",
            "multilayer_perceptron ran in: 0.0019385814666748047 sec\n",
            "multilayer_perceptron ran in: 0.002015352249145508 sec\n",
            "multilayer_perceptron ran in: 0.0018665790557861328 sec\n",
            "multilayer_perceptron ran in: 0.0018417835235595703 sec\n",
            "multilayer_perceptron ran in: 0.0019011497497558594 sec\n",
            "multilayer_perceptron ran in: 0.001817941665649414 sec\n",
            "multilayer_perceptron ran in: 0.0018208026885986328 sec\n",
            "multilayer_perceptron ran in: 0.0019731521606445312 sec\n",
            "multilayer_perceptron ran in: 0.0018177032470703125 sec\n",
            "multilayer_perceptron ran in: 0.0017728805541992188 sec\n",
            "multilayer_perceptron ran in: 0.001894235610961914 sec\n",
            "multilayer_perceptron ran in: 0.0018186569213867188 sec\n",
            "multilayer_perceptron ran in: 0.0040209293365478516 sec\n",
            "multilayer_perceptron ran in: 0.0018889904022216797 sec\n",
            "multilayer_perceptron ran in: 0.0018057823181152344 sec\n",
            "multilayer_perceptron ran in: 0.003572225570678711 sec\n",
            "multilayer_perceptron ran in: 0.001806497573852539 sec\n",
            "multilayer_perceptron ran in: 0.0019712448120117188 sec\n",
            "multilayer_perceptron ran in: 0.0017714500427246094 sec\n",
            "multilayer_perceptron ran in: 0.001817941665649414 sec\n",
            "multilayer_perceptron ran in: 0.0028336048126220703 sec\n",
            "multilayer_perceptron ran in: 0.0018298625946044922 sec\n",
            "multilayer_perceptron ran in: 0.001861572265625 sec\n",
            "multilayer_perceptron ran in: 0.0018584728240966797 sec\n",
            "multilayer_perceptron ran in: 0.0018496513366699219 sec\n",
            "multilayer_perceptron ran in: 0.0018095970153808594 sec\n",
            "multilayer_perceptron ran in: 0.0019140243530273438 sec\n",
            "multilayer_perceptron ran in: 0.0018579959869384766 sec\n",
            "multilayer_perceptron ran in: 0.0018918514251708984 sec\n",
            "multilayer_perceptron ran in: 0.0022912025451660156 sec\n",
            "multilayer_perceptron ran in: 0.0018451213836669922 sec\n",
            "multilayer_perceptron ran in: 0.0018587112426757812 sec\n",
            "multilayer_perceptron ran in: 0.0018472671508789062 sec\n",
            "multilayer_perceptron ran in: 0.0019249916076660156 sec\n",
            "multilayer_perceptron ran in: 0.003271818161010742 sec\n",
            "multilayer_perceptron ran in: 0.0018613338470458984 sec\n",
            "multilayer_perceptron ran in: 0.0020055770874023438 sec\n",
            "multilayer_perceptron ran in: 0.0024449825286865234 sec\n",
            "multilayer_perceptron ran in: 0.0023050308227539062 sec\n",
            "multilayer_perceptron ran in: 0.0035202503204345703 sec\n",
            "multilayer_perceptron ran in: 0.0026564598083496094 sec\n",
            "multilayer_perceptron ran in: 0.0022559165954589844 sec\n",
            "multilayer_perceptron ran in: 0.0024819374084472656 sec\n",
            "multilayer_perceptron ran in: 0.002963542938232422 sec\n",
            "multilayer_perceptron ran in: 0.002334117889404297 sec\n",
            "multilayer_perceptron ran in: 0.002402067184448242 sec\n",
            "multilayer_perceptron ran in: 0.002252340316772461 sec\n",
            "multilayer_perceptron ran in: 0.002906322479248047 sec\n",
            "multilayer_perceptron ran in: 0.002338409423828125 sec\n",
            "multilayer_perceptron ran in: 0.002933979034423828 sec\n",
            "multilayer_perceptron ran in: 0.0026764869689941406 sec\n",
            "multilayer_perceptron ran in: 0.0052280426025390625 sec\n",
            "multilayer_perceptron ran in: 0.002146005630493164 sec\n",
            "multilayer_perceptron ran in: 0.00218963623046875 sec\n",
            "multilayer_perceptron ran in: 0.002211332321166992 sec\n",
            "multilayer_perceptron ran in: 0.002120494842529297 sec\n",
            "multilayer_perceptron ran in: 0.002144336700439453 sec\n",
            "multilayer_perceptron ran in: 0.002288341522216797 sec\n",
            "multilayer_perceptron ran in: 0.002619504928588867 sec\n",
            "multilayer_perceptron ran in: 0.002073526382446289 sec\n",
            "multilayer_perceptron ran in: 0.002587556838989258 sec\n",
            "multilayer_perceptron ran in: 0.002347230911254883 sec\n",
            "multilayer_perceptron ran in: 0.0021309852600097656 sec\n",
            "multilayer_perceptron ran in: 0.002117156982421875 sec\n",
            "multilayer_perceptron ran in: 0.0025403499603271484 sec\n",
            "multilayer_perceptron ran in: 0.004679203033447266 sec\n",
            "multilayer_perceptron ran in: 0.0028870105743408203 sec\n",
            "multilayer_perceptron ran in: 0.002537965774536133 sec\n",
            "multilayer_perceptron ran in: 0.0024929046630859375 sec\n",
            "multilayer_perceptron ran in: 0.0025510787963867188 sec\n",
            "multilayer_perceptron ran in: 0.00225067138671875 sec\n",
            "multilayer_perceptron ran in: 0.002923250198364258 sec\n",
            "multilayer_perceptron ran in: 0.002338886260986328 sec\n",
            "multilayer_perceptron ran in: 0.002299785614013672 sec\n",
            "multilayer_perceptron ran in: 0.0025703907012939453 sec\n",
            "multilayer_perceptron ran in: 0.002354145050048828 sec\n",
            "multilayer_perceptron ran in: 0.002416372299194336 sec\n",
            "multilayer_perceptron ran in: 0.0023255348205566406 sec\n",
            "multilayer_perceptron ran in: 0.0023581981658935547 sec\n",
            "multilayer_perceptron ran in: 0.002473115921020508 sec\n",
            "multilayer_perceptron ran in: 0.0023703575134277344 sec\n",
            "multilayer_perceptron ran in: 0.0022423267364501953 sec\n",
            "multilayer_perceptron ran in: 0.002356290817260742 sec\n",
            "multilayer_perceptron ran in: 0.002305269241333008 sec\n",
            "multilayer_perceptron ran in: 0.0023221969604492188 sec\n",
            "multilayer_perceptron ran in: 0.002385377883911133 sec\n",
            "multilayer_perceptron ran in: 0.0030574798583984375 sec\n",
            "multilayer_perceptron ran in: 0.0025730133056640625 sec\n",
            "multilayer_perceptron ran in: 0.0026292800903320312 sec\n",
            "multilayer_perceptron ran in: 0.0024797916412353516 sec\n",
            "multilayer_perceptron ran in: 0.0025632381439208984 sec\n",
            "multilayer_perceptron ran in: 0.0026726722717285156 sec\n",
            "multilayer_perceptron ran in: 0.0018169879913330078 sec\n",
            "multilayer_perceptron ran in: 0.0017676353454589844 sec\n",
            "multilayer_perceptron ran in: 0.0017802715301513672 sec\n",
            "multilayer_perceptron ran in: 0.0019252300262451172 sec\n",
            "multilayer_perceptron ran in: 0.0017871856689453125 sec\n",
            "multilayer_perceptron ran in: 0.0018811225891113281 sec\n",
            "multilayer_perceptron ran in: 0.0019414424896240234 sec\n",
            "multilayer_perceptron ran in: 0.002232789993286133 sec\n",
            "multilayer_perceptron ran in: 0.0017271041870117188 sec\n",
            "multilayer_perceptron ran in: 0.002193927764892578 sec\n",
            "multilayer_perceptron ran in: 0.002061605453491211 sec\n",
            "multilayer_perceptron ran in: 0.0018718242645263672 sec\n",
            "multilayer_perceptron ran in: 0.0016825199127197266 sec\n",
            "multilayer_perceptron ran in: 0.0023224353790283203 sec\n",
            "multilayer_perceptron ran in: 0.0018851757049560547 sec\n",
            "multilayer_perceptron ran in: 0.0027637481689453125 sec\n",
            "multilayer_perceptron ran in: 0.001827239990234375 sec\n",
            "multilayer_perceptron ran in: 0.0023877620697021484 sec\n",
            "multilayer_perceptron ran in: 0.0019822120666503906 sec\n",
            "multilayer_perceptron ran in: 0.001959085464477539 sec\n",
            "multilayer_perceptron ran in: 0.0019152164459228516 sec\n",
            "multilayer_perceptron ran in: 0.0019114017486572266 sec\n",
            "multilayer_perceptron ran in: 0.0019791126251220703 sec\n",
            "multilayer_perceptron ran in: 0.002371072769165039 sec\n",
            "multilayer_perceptron ran in: 0.0017964839935302734 sec\n",
            "multilayer_perceptron ran in: 0.0018782615661621094 sec\n",
            "multilayer_perceptron ran in: 0.0031557083129882812 sec\n",
            "multilayer_perceptron ran in: 0.0030994415283203125 sec\n",
            "multilayer_perceptron ran in: 0.0017404556274414062 sec\n",
            "multilayer_perceptron ran in: 0.0022542476654052734 sec\n",
            "multilayer_perceptron ran in: 0.0018513202667236328 sec\n",
            "multilayer_perceptron ran in: 0.0018277168273925781 sec\n",
            "multilayer_perceptron ran in: 0.0018031597137451172 sec\n",
            "multilayer_perceptron ran in: 0.001819610595703125 sec\n",
            "multilayer_perceptron ran in: 0.0018239021301269531 sec\n",
            "multilayer_perceptron ran in: 0.0016894340515136719 sec\n",
            "multilayer_perceptron ran in: 0.0018270015716552734 sec\n",
            "multilayer_perceptron ran in: 0.00176239013671875 sec\n",
            "multilayer_perceptron ran in: 0.001979827880859375 sec\n",
            "multilayer_perceptron ran in: 0.001743316650390625 sec\n",
            "multilayer_perceptron ran in: 0.001756906509399414 sec\n",
            "multilayer_perceptron ran in: 0.002685070037841797 sec\n",
            "multilayer_perceptron ran in: 0.001817941665649414 sec\n",
            "multilayer_perceptron ran in: 0.0019686222076416016 sec\n",
            "multilayer_perceptron ran in: 0.0018126964569091797 sec\n",
            "multilayer_perceptron ran in: 0.002022266387939453 sec\n",
            "multilayer_perceptron ran in: 0.0019130706787109375 sec\n",
            "multilayer_perceptron ran in: 0.0029342174530029297 sec\n",
            "multilayer_perceptron ran in: 0.002325773239135742 sec\n",
            "multilayer_perceptron ran in: 0.001964092254638672 sec\n",
            "multilayer_perceptron ran in: 0.0018143653869628906 sec\n",
            "multilayer_perceptron ran in: 0.0019321441650390625 sec\n",
            "multilayer_perceptron ran in: 0.0019178390502929688 sec\n",
            "multilayer_perceptron ran in: 0.001787424087524414 sec\n",
            "multilayer_perceptron ran in: 0.001836538314819336 sec\n",
            "multilayer_perceptron ran in: 0.0018301010131835938 sec\n",
            "multilayer_perceptron ran in: 0.0016736984252929688 sec\n",
            "multilayer_perceptron ran in: 0.0019061565399169922 sec\n",
            "multilayer_perceptron ran in: 0.0017845630645751953 sec\n",
            "multilayer_perceptron ran in: 0.0018177032470703125 sec\n",
            "multilayer_perceptron ran in: 0.0019245147705078125 sec\n",
            "multilayer_perceptron ran in: 0.002523183822631836 sec\n",
            "multilayer_perceptron ran in: 0.0018947124481201172 sec\n",
            "multilayer_perceptron ran in: 0.002187490463256836 sec\n",
            "multilayer_perceptron ran in: 0.0021347999572753906 sec\n",
            "multilayer_perceptron ran in: 0.001901865005493164 sec\n",
            "multilayer_perceptron ran in: 0.002178192138671875 sec\n",
            "multilayer_perceptron ran in: 0.0017991065979003906 sec\n",
            "multilayer_perceptron ran in: 0.002880096435546875 sec\n",
            "multilayer_perceptron ran in: 0.001983165740966797 sec\n",
            "multilayer_perceptron ran in: 0.0021681785583496094 sec\n",
            "multilayer_perceptron ran in: 0.0018014907836914062 sec\n",
            "multilayer_perceptron ran in: 0.002229452133178711 sec\n",
            "Epoch: 5 Cost=10223.3506\n",
            "multilayer_perceptron ran in: 0.0018062591552734375 sec\n",
            "multilayer_perceptron ran in: 0.002020597457885742 sec\n",
            "multilayer_perceptron ran in: 0.0018377304077148438 sec\n",
            "multilayer_perceptron ran in: 0.0018281936645507812 sec\n",
            "multilayer_perceptron ran in: 0.0018336772918701172 sec\n",
            "multilayer_perceptron ran in: 0.0018584728240966797 sec\n",
            "multilayer_perceptron ran in: 0.0018777847290039062 sec\n",
            "multilayer_perceptron ran in: 0.0020837783813476562 sec\n",
            "multilayer_perceptron ran in: 0.0018277168273925781 sec\n",
            "multilayer_perceptron ran in: 0.0021996498107910156 sec\n",
            "multilayer_perceptron ran in: 0.0018889904022216797 sec\n",
            "multilayer_perceptron ran in: 0.001832723617553711 sec\n",
            "multilayer_perceptron ran in: 0.0024242401123046875 sec\n",
            "multilayer_perceptron ran in: 0.0019028186798095703 sec\n",
            "multilayer_perceptron ran in: 0.00182342529296875 sec\n",
            "multilayer_perceptron ran in: 0.001821756362915039 sec\n",
            "multilayer_perceptron ran in: 0.001893758773803711 sec\n",
            "multilayer_perceptron ran in: 0.0020165443420410156 sec\n",
            "multilayer_perceptron ran in: 0.002157926559448242 sec\n",
            "multilayer_perceptron ran in: 0.0018794536590576172 sec\n",
            "multilayer_perceptron ran in: 0.0019440650939941406 sec\n",
            "multilayer_perceptron ran in: 0.0022754669189453125 sec\n",
            "multilayer_perceptron ran in: 0.0021529197692871094 sec\n",
            "multilayer_perceptron ran in: 0.0019676685333251953 sec\n",
            "multilayer_perceptron ran in: 0.0020072460174560547 sec\n",
            "multilayer_perceptron ran in: 0.001894235610961914 sec\n",
            "multilayer_perceptron ran in: 0.0018913745880126953 sec\n",
            "multilayer_perceptron ran in: 0.0018744468688964844 sec\n",
            "multilayer_perceptron ran in: 0.0018429756164550781 sec\n",
            "multilayer_perceptron ran in: 0.001870870590209961 sec\n",
            "multilayer_perceptron ran in: 0.0018978118896484375 sec\n",
            "multilayer_perceptron ran in: 0.001859426498413086 sec\n",
            "multilayer_perceptron ran in: 0.0017178058624267578 sec\n",
            "multilayer_perceptron ran in: 0.0018649101257324219 sec\n",
            "multilayer_perceptron ran in: 0.0018153190612792969 sec\n",
            "multilayer_perceptron ran in: 0.0016832351684570312 sec\n",
            "multilayer_perceptron ran in: 0.001859903335571289 sec\n",
            "multilayer_perceptron ran in: 0.001798868179321289 sec\n",
            "multilayer_perceptron ran in: 0.0028553009033203125 sec\n",
            "multilayer_perceptron ran in: 0.003061056137084961 sec\n",
            "multilayer_perceptron ran in: 0.00177001953125 sec\n",
            "multilayer_perceptron ran in: 0.0018682479858398438 sec\n",
            "multilayer_perceptron ran in: 0.0025322437286376953 sec\n",
            "multilayer_perceptron ran in: 0.001730203628540039 sec\n",
            "multilayer_perceptron ran in: 0.002114534378051758 sec\n",
            "multilayer_perceptron ran in: 0.0018310546875 sec\n",
            "multilayer_perceptron ran in: 0.0019385814666748047 sec\n",
            "multilayer_perceptron ran in: 0.0019009113311767578 sec\n",
            "multilayer_perceptron ran in: 0.002073049545288086 sec\n",
            "multilayer_perceptron ran in: 0.002025127410888672 sec\n",
            "multilayer_perceptron ran in: 0.002028942108154297 sec\n",
            "multilayer_perceptron ran in: 0.001832723617553711 sec\n",
            "multilayer_perceptron ran in: 0.0017437934875488281 sec\n",
            "multilayer_perceptron ran in: 0.0018858909606933594 sec\n",
            "multilayer_perceptron ran in: 0.0018699169158935547 sec\n",
            "multilayer_perceptron ran in: 0.0023572444915771484 sec\n",
            "multilayer_perceptron ran in: 0.0019371509552001953 sec\n",
            "multilayer_perceptron ran in: 0.002103090286254883 sec\n",
            "multilayer_perceptron ran in: 0.0018270015716552734 sec\n",
            "multilayer_perceptron ran in: 0.0018994808197021484 sec\n",
            "multilayer_perceptron ran in: 0.002197265625 sec\n",
            "multilayer_perceptron ran in: 0.001779794692993164 sec\n",
            "multilayer_perceptron ran in: 0.0021271705627441406 sec\n",
            "multilayer_perceptron ran in: 0.0037424564361572266 sec\n",
            "multilayer_perceptron ran in: 0.0020782947540283203 sec\n",
            "multilayer_perceptron ran in: 0.002448558807373047 sec\n",
            "multilayer_perceptron ran in: 0.0018181800842285156 sec\n",
            "multilayer_perceptron ran in: 0.0019288063049316406 sec\n",
            "multilayer_perceptron ran in: 0.0018405914306640625 sec\n",
            "multilayer_perceptron ran in: 0.004248619079589844 sec\n",
            "multilayer_perceptron ran in: 0.0018720626831054688 sec\n",
            "multilayer_perceptron ran in: 0.0018944740295410156 sec\n",
            "multilayer_perceptron ran in: 0.001734018325805664 sec\n",
            "multilayer_perceptron ran in: 0.001775979995727539 sec\n",
            "multilayer_perceptron ran in: 0.0018033981323242188 sec\n",
            "multilayer_perceptron ran in: 0.0017426013946533203 sec\n",
            "multilayer_perceptron ran in: 0.0018532276153564453 sec\n",
            "multilayer_perceptron ran in: 0.0017504692077636719 sec\n",
            "multilayer_perceptron ran in: 0.00388336181640625 sec\n",
            "multilayer_perceptron ran in: 0.0018210411071777344 sec\n",
            "multilayer_perceptron ran in: 0.0024542808532714844 sec\n",
            "multilayer_perceptron ran in: 0.001970052719116211 sec\n",
            "multilayer_perceptron ran in: 0.0019228458404541016 sec\n",
            "multilayer_perceptron ran in: 0.0017364025115966797 sec\n",
            "multilayer_perceptron ran in: 0.0019845962524414062 sec\n",
            "multilayer_perceptron ran in: 0.0021359920501708984 sec\n",
            "multilayer_perceptron ran in: 0.0019676685333251953 sec\n",
            "multilayer_perceptron ran in: 0.0017838478088378906 sec\n",
            "multilayer_perceptron ran in: 0.0020275115966796875 sec\n",
            "multilayer_perceptron ran in: 0.0018596649169921875 sec\n",
            "multilayer_perceptron ran in: 0.0017554759979248047 sec\n",
            "multilayer_perceptron ran in: 0.001825094223022461 sec\n",
            "multilayer_perceptron ran in: 0.0017995834350585938 sec\n",
            "multilayer_perceptron ran in: 0.0017442703247070312 sec\n",
            "multilayer_perceptron ran in: 0.0026056766510009766 sec\n",
            "multilayer_perceptron ran in: 0.002105712890625 sec\n",
            "multilayer_perceptron ran in: 0.0018029212951660156 sec\n",
            "multilayer_perceptron ran in: 0.0017285346984863281 sec\n",
            "multilayer_perceptron ran in: 0.0032825469970703125 sec\n",
            "multilayer_perceptron ran in: 0.001764535903930664 sec\n",
            "multilayer_perceptron ran in: 0.0018126964569091797 sec\n",
            "multilayer_perceptron ran in: 0.001741170883178711 sec\n",
            "multilayer_perceptron ran in: 0.0021622180938720703 sec\n",
            "multilayer_perceptron ran in: 0.0020780563354492188 sec\n",
            "multilayer_perceptron ran in: 0.0019407272338867188 sec\n",
            "multilayer_perceptron ran in: 0.0018191337585449219 sec\n",
            "multilayer_perceptron ran in: 0.0017752647399902344 sec\n",
            "multilayer_perceptron ran in: 0.0019307136535644531 sec\n",
            "multilayer_perceptron ran in: 0.002727985382080078 sec\n",
            "multilayer_perceptron ran in: 0.0020503997802734375 sec\n",
            "multilayer_perceptron ran in: 0.001688241958618164 sec\n",
            "multilayer_perceptron ran in: 0.003615856170654297 sec\n",
            "multilayer_perceptron ran in: 0.0018718242645263672 sec\n",
            "multilayer_perceptron ran in: 0.0020551681518554688 sec\n",
            "multilayer_perceptron ran in: 0.0017895698547363281 sec\n",
            "multilayer_perceptron ran in: 0.0017805099487304688 sec\n",
            "multilayer_perceptron ran in: 0.001988649368286133 sec\n",
            "multilayer_perceptron ran in: 0.002602100372314453 sec\n",
            "multilayer_perceptron ran in: 0.001978635787963867 sec\n",
            "multilayer_perceptron ran in: 0.0019500255584716797 sec\n",
            "multilayer_perceptron ran in: 0.0021886825561523438 sec\n",
            "multilayer_perceptron ran in: 0.0017240047454833984 sec\n",
            "multilayer_perceptron ran in: 0.001861572265625 sec\n",
            "multilayer_perceptron ran in: 0.00182342529296875 sec\n",
            "multilayer_perceptron ran in: 0.0018589496612548828 sec\n",
            "multilayer_perceptron ran in: 0.0023174285888671875 sec\n",
            "multilayer_perceptron ran in: 0.0017404556274414062 sec\n",
            "multilayer_perceptron ran in: 0.001888275146484375 sec\n",
            "multilayer_perceptron ran in: 0.0020024776458740234 sec\n",
            "multilayer_perceptron ran in: 0.0019428730010986328 sec\n",
            "multilayer_perceptron ran in: 0.002001047134399414 sec\n",
            "multilayer_perceptron ran in: 0.0018343925476074219 sec\n",
            "multilayer_perceptron ran in: 0.001728057861328125 sec\n",
            "multilayer_perceptron ran in: 0.00188446044921875 sec\n",
            "multilayer_perceptron ran in: 0.0020554065704345703 sec\n",
            "multilayer_perceptron ran in: 0.0018360614776611328 sec\n",
            "multilayer_perceptron ran in: 0.002841472625732422 sec\n",
            "multilayer_perceptron ran in: 0.0028984546661376953 sec\n",
            "multilayer_perceptron ran in: 0.0019555091857910156 sec\n",
            "multilayer_perceptron ran in: 0.0036089420318603516 sec\n",
            "multilayer_perceptron ran in: 0.0018351078033447266 sec\n",
            "multilayer_perceptron ran in: 0.002039194107055664 sec\n",
            "multilayer_perceptron ran in: 0.0019021034240722656 sec\n",
            "multilayer_perceptron ran in: 0.0020155906677246094 sec\n",
            "multilayer_perceptron ran in: 0.00186920166015625 sec\n",
            "multilayer_perceptron ran in: 0.001882791519165039 sec\n",
            "multilayer_perceptron ran in: 0.0017991065979003906 sec\n",
            "multilayer_perceptron ran in: 0.0018723011016845703 sec\n",
            "multilayer_perceptron ran in: 0.0017597675323486328 sec\n",
            "multilayer_perceptron ran in: 0.0019383430480957031 sec\n",
            "multilayer_perceptron ran in: 0.0018072128295898438 sec\n",
            "multilayer_perceptron ran in: 0.002774953842163086 sec\n",
            "multilayer_perceptron ran in: 0.002744436264038086 sec\n",
            "multilayer_perceptron ran in: 0.003069162368774414 sec\n",
            "multilayer_perceptron ran in: 0.002336263656616211 sec\n",
            "multilayer_perceptron ran in: 0.0024437904357910156 sec\n",
            "multilayer_perceptron ran in: 0.002582073211669922 sec\n",
            "multilayer_perceptron ran in: 0.002406597137451172 sec\n",
            "multilayer_perceptron ran in: 0.0020990371704101562 sec\n",
            "multilayer_perceptron ran in: 0.001958131790161133 sec\n",
            "multilayer_perceptron ran in: 0.0022814273834228516 sec\n",
            "multilayer_perceptron ran in: 0.0021462440490722656 sec\n",
            "multilayer_perceptron ran in: 0.0021359920501708984 sec\n",
            "multilayer_perceptron ran in: 0.0021619796752929688 sec\n",
            "multilayer_perceptron ran in: 0.007537126541137695 sec\n",
            "multilayer_perceptron ran in: 0.001981496810913086 sec\n",
            "multilayer_perceptron ran in: 0.002003908157348633 sec\n",
            "multilayer_perceptron ran in: 0.0020782947540283203 sec\n",
            "multilayer_perceptron ran in: 0.0019032955169677734 sec\n",
            "multilayer_perceptron ran in: 0.0020961761474609375 sec\n",
            "multilayer_perceptron ran in: 0.0020716190338134766 sec\n",
            "multilayer_perceptron ran in: 0.0020296573638916016 sec\n",
            "multilayer_perceptron ran in: 0.002149343490600586 sec\n",
            "multilayer_perceptron ran in: 0.002270221710205078 sec\n",
            "multilayer_perceptron ran in: 0.0025527477264404297 sec\n",
            "multilayer_perceptron ran in: 0.0023734569549560547 sec\n",
            "multilayer_perceptron ran in: 0.0025887489318847656 sec\n",
            "multilayer_perceptron ran in: 0.0025844573974609375 sec\n",
            "multilayer_perceptron ran in: 0.002608060836791992 sec\n",
            "multilayer_perceptron ran in: 0.004097938537597656 sec\n",
            "multilayer_perceptron ran in: 0.0025768280029296875 sec\n",
            "multilayer_perceptron ran in: 0.0021560192108154297 sec\n",
            "multilayer_perceptron ran in: 0.0024929046630859375 sec\n",
            "multilayer_perceptron ran in: 0.00273895263671875 sec\n",
            "multilayer_perceptron ran in: 0.002371072769165039 sec\n",
            "multilayer_perceptron ran in: 0.0023484230041503906 sec\n",
            "multilayer_perceptron ran in: 0.002396821975708008 sec\n",
            "multilayer_perceptron ran in: 0.002375364303588867 sec\n",
            "multilayer_perceptron ran in: 0.0022928714752197266 sec\n",
            "multilayer_perceptron ran in: 0.002274036407470703 sec\n",
            "multilayer_perceptron ran in: 0.0023796558380126953 sec\n",
            "multilayer_perceptron ran in: 0.005239963531494141 sec\n",
            "multilayer_perceptron ran in: 0.002167940139770508 sec\n",
            "multilayer_perceptron ran in: 0.0022232532501220703 sec\n",
            "multilayer_perceptron ran in: 0.002514362335205078 sec\n",
            "multilayer_perceptron ran in: 0.0023000240325927734 sec\n",
            "multilayer_perceptron ran in: 0.0025162696838378906 sec\n",
            "multilayer_perceptron ran in: 0.0025098323822021484 sec\n",
            "multilayer_perceptron ran in: 0.0026068687438964844 sec\n",
            "multilayer_perceptron ran in: 0.002645730972290039 sec\n",
            "multilayer_perceptron ran in: 0.0029773712158203125 sec\n",
            "multilayer_perceptron ran in: 0.0022416114807128906 sec\n",
            "multilayer_perceptron ran in: 0.0021276473999023438 sec\n",
            "multilayer_perceptron ran in: 0.0016961097717285156 sec\n",
            "multilayer_perceptron ran in: 0.0019147396087646484 sec\n",
            "multilayer_perceptron ran in: 0.00196075439453125 sec\n",
            "multilayer_perceptron ran in: 0.0017254352569580078 sec\n",
            "multilayer_perceptron ran in: 0.0018777847290039062 sec\n",
            "multilayer_perceptron ran in: 0.0019669532775878906 sec\n",
            "multilayer_perceptron ran in: 0.0019233226776123047 sec\n",
            "multilayer_perceptron ran in: 0.0018184185028076172 sec\n",
            "multilayer_perceptron ran in: 0.0019030570983886719 sec\n",
            "multilayer_perceptron ran in: 0.002203702926635742 sec\n",
            "multilayer_perceptron ran in: 0.002051830291748047 sec\n",
            "multilayer_perceptron ran in: 0.001840353012084961 sec\n",
            "multilayer_perceptron ran in: 0.0019259452819824219 sec\n",
            "multilayer_perceptron ran in: 0.001999378204345703 sec\n",
            "multilayer_perceptron ran in: 0.001781463623046875 sec\n",
            "multilayer_perceptron ran in: 0.002118825912475586 sec\n",
            "multilayer_perceptron ran in: 0.001886606216430664 sec\n",
            "multilayer_perceptron ran in: 0.0019028186798095703 sec\n",
            "multilayer_perceptron ran in: 0.0019969940185546875 sec\n",
            "multilayer_perceptron ran in: 0.0019092559814453125 sec\n",
            "multilayer_perceptron ran in: 0.0018696784973144531 sec\n",
            "multilayer_perceptron ran in: 0.0023126602172851562 sec\n",
            "multilayer_perceptron ran in: 0.0023779869079589844 sec\n",
            "multilayer_perceptron ran in: 0.0017380714416503906 sec\n",
            "multilayer_perceptron ran in: 0.002073526382446289 sec\n",
            "multilayer_perceptron ran in: 0.0018153190612792969 sec\n",
            "multilayer_perceptron ran in: 0.0018906593322753906 sec\n",
            "multilayer_perceptron ran in: 0.0022192001342773438 sec\n",
            "multilayer_perceptron ran in: 0.0018527507781982422 sec\n",
            "multilayer_perceptron ran in: 0.0019431114196777344 sec\n",
            "multilayer_perceptron ran in: 0.001817464828491211 sec\n",
            "multilayer_perceptron ran in: 0.0017096996307373047 sec\n",
            "multilayer_perceptron ran in: 0.0018587112426757812 sec\n",
            "multilayer_perceptron ran in: 0.0018041133880615234 sec\n",
            "multilayer_perceptron ran in: 0.0032901763916015625 sec\n",
            "multilayer_perceptron ran in: 0.0027048587799072266 sec\n",
            "multilayer_perceptron ran in: 0.0025000572204589844 sec\n",
            "Epoch: 6 Cost=14811.5850\n",
            "multilayer_perceptron ran in: 0.0017802715301513672 sec\n",
            "multilayer_perceptron ran in: 0.001932382583618164 sec\n",
            "multilayer_perceptron ran in: 0.001967906951904297 sec\n",
            "multilayer_perceptron ran in: 0.002349376678466797 sec\n",
            "multilayer_perceptron ran in: 0.0019021034240722656 sec\n",
            "multilayer_perceptron ran in: 0.0017976760864257812 sec\n",
            "multilayer_perceptron ran in: 0.0021147727966308594 sec\n",
            "multilayer_perceptron ran in: 0.0019922256469726562 sec\n",
            "multilayer_perceptron ran in: 0.0019183158874511719 sec\n",
            "multilayer_perceptron ran in: 0.0020170211791992188 sec\n",
            "multilayer_perceptron ran in: 0.0018830299377441406 sec\n",
            "multilayer_perceptron ran in: 0.0025441646575927734 sec\n",
            "multilayer_perceptron ran in: 0.0018913745880126953 sec\n",
            "multilayer_perceptron ran in: 0.001852273941040039 sec\n",
            "multilayer_perceptron ran in: 0.0023102760314941406 sec\n",
            "multilayer_perceptron ran in: 0.001825571060180664 sec\n",
            "multilayer_perceptron ran in: 0.0018672943115234375 sec\n",
            "multilayer_perceptron ran in: 0.0018775463104248047 sec\n",
            "multilayer_perceptron ran in: 0.001781463623046875 sec\n",
            "multilayer_perceptron ran in: 0.0018372535705566406 sec\n",
            "multilayer_perceptron ran in: 0.002647876739501953 sec\n",
            "multilayer_perceptron ran in: 0.001813650131225586 sec\n",
            "multilayer_perceptron ran in: 0.0019183158874511719 sec\n",
            "multilayer_perceptron ran in: 0.001947164535522461 sec\n",
            "multilayer_perceptron ran in: 0.0018982887268066406 sec\n",
            "multilayer_perceptron ran in: 0.0018281936645507812 sec\n",
            "multilayer_perceptron ran in: 0.0025911331176757812 sec\n",
            "multilayer_perceptron ran in: 0.0018951892852783203 sec\n",
            "multilayer_perceptron ran in: 0.0017189979553222656 sec\n",
            "multilayer_perceptron ran in: 0.001796722412109375 sec\n",
            "multilayer_perceptron ran in: 0.0018572807312011719 sec\n",
            "multilayer_perceptron ran in: 0.0017552375793457031 sec\n",
            "multilayer_perceptron ran in: 0.002466917037963867 sec\n",
            "multilayer_perceptron ran in: 0.002201080322265625 sec\n",
            "multilayer_perceptron ran in: 0.001783132553100586 sec\n",
            "multilayer_perceptron ran in: 0.0018193721771240234 sec\n",
            "multilayer_perceptron ran in: 0.0018775463104248047 sec\n",
            "multilayer_perceptron ran in: 0.002384662628173828 sec\n",
            "multilayer_perceptron ran in: 0.001969575881958008 sec\n",
            "multilayer_perceptron ran in: 0.0021512508392333984 sec\n",
            "multilayer_perceptron ran in: 0.0025217533111572266 sec\n",
            "multilayer_perceptron ran in: 0.0019087791442871094 sec\n",
            "multilayer_perceptron ran in: 0.001964092254638672 sec\n",
            "multilayer_perceptron ran in: 0.0018126964569091797 sec\n",
            "multilayer_perceptron ran in: 0.001935720443725586 sec\n",
            "multilayer_perceptron ran in: 0.002039670944213867 sec\n",
            "multilayer_perceptron ran in: 0.0018875598907470703 sec\n",
            "multilayer_perceptron ran in: 0.001949310302734375 sec\n",
            "multilayer_perceptron ran in: 0.0018053054809570312 sec\n",
            "multilayer_perceptron ran in: 0.0019202232360839844 sec\n",
            "multilayer_perceptron ran in: 0.00191497802734375 sec\n",
            "multilayer_perceptron ran in: 0.0018420219421386719 sec\n",
            "multilayer_perceptron ran in: 0.005145549774169922 sec\n",
            "multilayer_perceptron ran in: 0.0020935535430908203 sec\n",
            "multilayer_perceptron ran in: 0.0018720626831054688 sec\n",
            "multilayer_perceptron ran in: 0.002424478530883789 sec\n",
            "multilayer_perceptron ran in: 0.0018355846405029297 sec\n",
            "multilayer_perceptron ran in: 0.002246379852294922 sec\n",
            "multilayer_perceptron ran in: 0.0019121170043945312 sec\n",
            "multilayer_perceptron ran in: 0.0023674964904785156 sec\n",
            "multilayer_perceptron ran in: 0.001725912094116211 sec\n",
            "multilayer_perceptron ran in: 0.0017557144165039062 sec\n",
            "multilayer_perceptron ran in: 0.0017871856689453125 sec\n",
            "multilayer_perceptron ran in: 0.0018401145935058594 sec\n",
            "multilayer_perceptron ran in: 0.0025043487548828125 sec\n",
            "multilayer_perceptron ran in: 0.0027053356170654297 sec\n",
            "multilayer_perceptron ran in: 0.0017733573913574219 sec\n",
            "multilayer_perceptron ran in: 0.001870870590209961 sec\n",
            "multilayer_perceptron ran in: 0.0019066333770751953 sec\n",
            "multilayer_perceptron ran in: 0.00189971923828125 sec\n",
            "multilayer_perceptron ran in: 0.0017824172973632812 sec\n",
            "multilayer_perceptron ran in: 0.002029895782470703 sec\n",
            "multilayer_perceptron ran in: 0.0017857551574707031 sec\n",
            "multilayer_perceptron ran in: 0.0035398006439208984 sec\n",
            "multilayer_perceptron ran in: 0.0017242431640625 sec\n",
            "multilayer_perceptron ran in: 0.00185394287109375 sec\n",
            "multilayer_perceptron ran in: 0.003055095672607422 sec\n",
            "multilayer_perceptron ran in: 0.0018057823181152344 sec\n",
            "multilayer_perceptron ran in: 0.0017383098602294922 sec\n",
            "multilayer_perceptron ran in: 0.0018227100372314453 sec\n",
            "multilayer_perceptron ran in: 0.001943349838256836 sec\n",
            "multilayer_perceptron ran in: 0.0017881393432617188 sec\n",
            "multilayer_perceptron ran in: 0.0021343231201171875 sec\n",
            "multilayer_perceptron ran in: 0.0019369125366210938 sec\n",
            "multilayer_perceptron ran in: 0.0018944740295410156 sec\n",
            "multilayer_perceptron ran in: 0.00199127197265625 sec\n",
            "multilayer_perceptron ran in: 0.0018422603607177734 sec\n",
            "multilayer_perceptron ran in: 0.0018682479858398438 sec\n",
            "multilayer_perceptron ran in: 0.0017817020416259766 sec\n",
            "multilayer_perceptron ran in: 0.001837015151977539 sec\n",
            "multilayer_perceptron ran in: 0.001810312271118164 sec\n",
            "multilayer_perceptron ran in: 0.002027273178100586 sec\n",
            "multilayer_perceptron ran in: 0.0020482540130615234 sec\n",
            "multilayer_perceptron ran in: 0.0017714500427246094 sec\n",
            "multilayer_perceptron ran in: 0.001870870590209961 sec\n",
            "multilayer_perceptron ran in: 0.0025091171264648438 sec\n",
            "multilayer_perceptron ran in: 0.0017862319946289062 sec\n",
            "multilayer_perceptron ran in: 0.0020503997802734375 sec\n",
            "multilayer_perceptron ran in: 0.0037631988525390625 sec\n",
            "multilayer_perceptron ran in: 0.0017464160919189453 sec\n",
            "multilayer_perceptron ran in: 0.001764059066772461 sec\n",
            "multilayer_perceptron ran in: 0.001928567886352539 sec\n",
            "multilayer_perceptron ran in: 0.002613067626953125 sec\n",
            "multilayer_perceptron ran in: 0.001995563507080078 sec\n",
            "multilayer_perceptron ran in: 0.001834869384765625 sec\n",
            "multilayer_perceptron ran in: 0.0017092227935791016 sec\n",
            "multilayer_perceptron ran in: 0.0019185543060302734 sec\n",
            "multilayer_perceptron ran in: 0.0019106864929199219 sec\n",
            "multilayer_perceptron ran in: 0.0017523765563964844 sec\n",
            "multilayer_perceptron ran in: 0.0018336772918701172 sec\n",
            "multilayer_perceptron ran in: 0.0029211044311523438 sec\n",
            "multilayer_perceptron ran in: 0.0020952224731445312 sec\n",
            "multilayer_perceptron ran in: 0.0019664764404296875 sec\n",
            "multilayer_perceptron ran in: 0.0018835067749023438 sec\n",
            "multilayer_perceptron ran in: 0.0017843246459960938 sec\n",
            "multilayer_perceptron ran in: 0.005885601043701172 sec\n",
            "multilayer_perceptron ran in: 0.001856088638305664 sec\n",
            "multilayer_perceptron ran in: 0.0018818378448486328 sec\n",
            "multilayer_perceptron ran in: 0.0017461776733398438 sec\n",
            "multilayer_perceptron ran in: 0.002088308334350586 sec\n",
            "multilayer_perceptron ran in: 0.0019304752349853516 sec\n",
            "multilayer_perceptron ran in: 0.0020906925201416016 sec\n",
            "multilayer_perceptron ran in: 0.001882791519165039 sec\n",
            "multilayer_perceptron ran in: 0.0019202232360839844 sec\n",
            "multilayer_perceptron ran in: 0.0018513202667236328 sec\n",
            "multilayer_perceptron ran in: 0.0017685890197753906 sec\n",
            "multilayer_perceptron ran in: 0.0017642974853515625 sec\n",
            "multilayer_perceptron ran in: 0.0018897056579589844 sec\n",
            "multilayer_perceptron ran in: 0.0019311904907226562 sec\n",
            "multilayer_perceptron ran in: 0.0018475055694580078 sec\n",
            "multilayer_perceptron ran in: 0.0018048286437988281 sec\n",
            "multilayer_perceptron ran in: 0.001981496810913086 sec\n",
            "multilayer_perceptron ran in: 0.0018684864044189453 sec\n",
            "multilayer_perceptron ran in: 0.0018339157104492188 sec\n",
            "multilayer_perceptron ran in: 0.002278566360473633 sec\n",
            "multilayer_perceptron ran in: 0.001798868179321289 sec\n",
            "multilayer_perceptron ran in: 0.002027273178100586 sec\n",
            "multilayer_perceptron ran in: 0.0022706985473632812 sec\n",
            "multilayer_perceptron ran in: 0.0018575191497802734 sec\n",
            "multilayer_perceptron ran in: 0.0018620491027832031 sec\n",
            "multilayer_perceptron ran in: 0.0017752647399902344 sec\n",
            "multilayer_perceptron ran in: 0.0017735958099365234 sec\n",
            "multilayer_perceptron ran in: 0.0018014907836914062 sec\n",
            "multilayer_perceptron ran in: 0.0017714500427246094 sec\n",
            "multilayer_perceptron ran in: 0.0018007755279541016 sec\n",
            "multilayer_perceptron ran in: 0.0021228790283203125 sec\n",
            "multilayer_perceptron ran in: 0.0018525123596191406 sec\n",
            "multilayer_perceptron ran in: 0.0019388198852539062 sec\n",
            "multilayer_perceptron ran in: 0.002538442611694336 sec\n",
            "multilayer_perceptron ran in: 0.0017659664154052734 sec\n",
            "multilayer_perceptron ran in: 0.0021457672119140625 sec\n",
            "multilayer_perceptron ran in: 0.0019221305847167969 sec\n",
            "multilayer_perceptron ran in: 0.0018188953399658203 sec\n",
            "multilayer_perceptron ran in: 0.001779317855834961 sec\n",
            "multilayer_perceptron ran in: 0.0018870830535888672 sec\n",
            "multilayer_perceptron ran in: 0.0020580291748046875 sec\n",
            "multilayer_perceptron ran in: 0.0020782947540283203 sec\n",
            "multilayer_perceptron ran in: 0.0020723342895507812 sec\n",
            "multilayer_perceptron ran in: 0.0019507408142089844 sec\n",
            "multilayer_perceptron ran in: 0.002305269241333008 sec\n",
            "multilayer_perceptron ran in: 0.001984834671020508 sec\n",
            "multilayer_perceptron ran in: 0.0019147396087646484 sec\n",
            "multilayer_perceptron ran in: 0.0018992424011230469 sec\n",
            "multilayer_perceptron ran in: 0.0018846988677978516 sec\n",
            "multilayer_perceptron ran in: 0.0018143653869628906 sec\n",
            "multilayer_perceptron ran in: 0.0021834373474121094 sec\n",
            "multilayer_perceptron ran in: 0.0018074512481689453 sec\n",
            "multilayer_perceptron ran in: 0.0018181800842285156 sec\n",
            "multilayer_perceptron ran in: 0.0018122196197509766 sec\n",
            "multilayer_perceptron ran in: 0.0021598339080810547 sec\n",
            "multilayer_perceptron ran in: 0.0017230510711669922 sec\n",
            "multilayer_perceptron ran in: 0.0018782615661621094 sec\n",
            "multilayer_perceptron ran in: 0.0022182464599609375 sec\n",
            "multilayer_perceptron ran in: 0.0018935203552246094 sec\n",
            "multilayer_perceptron ran in: 0.0018160343170166016 sec\n",
            "multilayer_perceptron ran in: 0.0018625259399414062 sec\n",
            "multilayer_perceptron ran in: 0.0019648075103759766 sec\n",
            "multilayer_perceptron ran in: 0.0018463134765625 sec\n",
            "multilayer_perceptron ran in: 0.0019412040710449219 sec\n",
            "multilayer_perceptron ran in: 0.0026144981384277344 sec\n",
            "multilayer_perceptron ran in: 0.0044629573822021484 sec\n",
            "multilayer_perceptron ran in: 0.001916646957397461 sec\n",
            "multilayer_perceptron ran in: 0.0031647682189941406 sec\n",
            "multilayer_perceptron ran in: 0.0025191307067871094 sec\n",
            "multilayer_perceptron ran in: 0.0019958019256591797 sec\n",
            "multilayer_perceptron ran in: 0.0020263195037841797 sec\n",
            "multilayer_perceptron ran in: 0.0025894641876220703 sec\n",
            "multilayer_perceptron ran in: 0.0020897388458251953 sec\n",
            "multilayer_perceptron ran in: 0.002155780792236328 sec\n",
            "multilayer_perceptron ran in: 0.002059459686279297 sec\n",
            "multilayer_perceptron ran in: 0.0022199153900146484 sec\n",
            "multilayer_perceptron ran in: 0.002194643020629883 sec\n",
            "multilayer_perceptron ran in: 0.0023241043090820312 sec\n",
            "multilayer_perceptron ran in: 0.0021996498107910156 sec\n",
            "multilayer_perceptron ran in: 0.0021550655364990234 sec\n",
            "multilayer_perceptron ran in: 0.001984834671020508 sec\n",
            "multilayer_perceptron ran in: 0.0031828880310058594 sec\n",
            "multilayer_perceptron ran in: 0.002341032028198242 sec\n",
            "multilayer_perceptron ran in: 0.002174854278564453 sec\n",
            "multilayer_perceptron ran in: 0.002481222152709961 sec\n",
            "multilayer_perceptron ran in: 0.0020363330841064453 sec\n",
            "multilayer_perceptron ran in: 0.0020852088928222656 sec\n",
            "multilayer_perceptron ran in: 0.0020411014556884766 sec\n",
            "multilayer_perceptron ran in: 0.0025763511657714844 sec\n",
            "multilayer_perceptron ran in: 0.0024640560150146484 sec\n",
            "multilayer_perceptron ran in: 0.002572298049926758 sec\n",
            "multilayer_perceptron ran in: 0.0023126602172851562 sec\n",
            "multilayer_perceptron ran in: 0.0020971298217773438 sec\n",
            "multilayer_perceptron ran in: 0.0024933815002441406 sec\n",
            "multilayer_perceptron ran in: 0.0027866363525390625 sec\n",
            "multilayer_perceptron ran in: 0.002145051956176758 sec\n",
            "multilayer_perceptron ran in: 0.0024361610412597656 sec\n",
            "multilayer_perceptron ran in: 0.0023512840270996094 sec\n",
            "multilayer_perceptron ran in: 0.0025522708892822266 sec\n",
            "multilayer_perceptron ran in: 0.002359628677368164 sec\n",
            "multilayer_perceptron ran in: 0.0023398399353027344 sec\n",
            "multilayer_perceptron ran in: 0.002303600311279297 sec\n",
            "multilayer_perceptron ran in: 0.0023076534271240234 sec\n",
            "multilayer_perceptron ran in: 0.002362489700317383 sec\n",
            "multilayer_perceptron ran in: 0.002351045608520508 sec\n",
            "multilayer_perceptron ran in: 0.0023467540740966797 sec\n",
            "multilayer_perceptron ran in: 0.002330780029296875 sec\n",
            "multilayer_perceptron ran in: 0.0027272701263427734 sec\n",
            "multilayer_perceptron ran in: 0.0022618770599365234 sec\n",
            "multilayer_perceptron ran in: 0.002470254898071289 sec\n",
            "multilayer_perceptron ran in: 0.0023491382598876953 sec\n",
            "multilayer_perceptron ran in: 0.003414630889892578 sec\n",
            "multilayer_perceptron ran in: 0.0023567676544189453 sec\n",
            "multilayer_perceptron ran in: 0.0028829574584960938 sec\n",
            "multilayer_perceptron ran in: 0.002264738082885742 sec\n",
            "multilayer_perceptron ran in: 0.002212047576904297 sec\n",
            "multilayer_perceptron ran in: 0.0023975372314453125 sec\n",
            "multilayer_perceptron ran in: 0.0026519298553466797 sec\n",
            "multilayer_perceptron ran in: 0.0024764537811279297 sec\n",
            "multilayer_perceptron ran in: 0.002444028854370117 sec\n",
            "multilayer_perceptron ran in: 0.002538919448852539 sec\n",
            "multilayer_perceptron ran in: 0.0024805068969726562 sec\n",
            "multilayer_perceptron ran in: 0.0016968250274658203 sec\n",
            "multilayer_perceptron ran in: 0.0018002986907958984 sec\n",
            "multilayer_perceptron ran in: 0.0018696784973144531 sec\n",
            "Epoch: 7 Cost=21233.7363\n",
            "multilayer_perceptron ran in: 0.001905202865600586 sec\n",
            "multilayer_perceptron ran in: 0.0018498897552490234 sec\n",
            "multilayer_perceptron ran in: 0.0018949508666992188 sec\n",
            "multilayer_perceptron ran in: 0.001821279525756836 sec\n",
            "multilayer_perceptron ran in: 0.0021386146545410156 sec\n",
            "multilayer_perceptron ran in: 0.001692056655883789 sec\n",
            "multilayer_perceptron ran in: 0.0017812252044677734 sec\n",
            "multilayer_perceptron ran in: 0.0021049976348876953 sec\n",
            "multilayer_perceptron ran in: 0.0016987323760986328 sec\n",
            "multilayer_perceptron ran in: 0.0019152164459228516 sec\n",
            "multilayer_perceptron ran in: 0.0017824172973632812 sec\n",
            "multilayer_perceptron ran in: 0.0020003318786621094 sec\n",
            "multilayer_perceptron ran in: 0.002368927001953125 sec\n",
            "multilayer_perceptron ran in: 0.0034334659576416016 sec\n",
            "multilayer_perceptron ran in: 0.0018124580383300781 sec\n",
            "multilayer_perceptron ran in: 0.0017774105072021484 sec\n",
            "multilayer_perceptron ran in: 0.0018782615661621094 sec\n",
            "multilayer_perceptron ran in: 0.0018966197967529297 sec\n",
            "multilayer_perceptron ran in: 0.0030291080474853516 sec\n",
            "multilayer_perceptron ran in: 0.0018091201782226562 sec\n",
            "multilayer_perceptron ran in: 0.0018267631530761719 sec\n",
            "multilayer_perceptron ran in: 0.0020570755004882812 sec\n",
            "multilayer_perceptron ran in: 0.0019290447235107422 sec\n",
            "multilayer_perceptron ran in: 0.0023660659790039062 sec\n",
            "multilayer_perceptron ran in: 0.001947164535522461 sec\n",
            "multilayer_perceptron ran in: 0.0017993450164794922 sec\n",
            "multilayer_perceptron ran in: 0.0018362998962402344 sec\n",
            "multilayer_perceptron ran in: 0.0019116401672363281 sec\n",
            "multilayer_perceptron ran in: 0.0019087791442871094 sec\n",
            "multilayer_perceptron ran in: 0.001821756362915039 sec\n",
            "multilayer_perceptron ran in: 0.002210855484008789 sec\n",
            "multilayer_perceptron ran in: 0.0018668174743652344 sec\n",
            "multilayer_perceptron ran in: 0.001958131790161133 sec\n",
            "multilayer_perceptron ran in: 0.0018086433410644531 sec\n",
            "multilayer_perceptron ran in: 0.0018346309661865234 sec\n",
            "multilayer_perceptron ran in: 0.0017511844635009766 sec\n",
            "multilayer_perceptron ran in: 0.0017712116241455078 sec\n",
            "multilayer_perceptron ran in: 0.0017299652099609375 sec\n",
            "multilayer_perceptron ran in: 0.0019001960754394531 sec\n",
            "multilayer_perceptron ran in: 0.0018906593322753906 sec\n",
            "multilayer_perceptron ran in: 0.0018575191497802734 sec\n",
            "multilayer_perceptron ran in: 0.002607107162475586 sec\n",
            "multilayer_perceptron ran in: 0.0017931461334228516 sec\n",
            "multilayer_perceptron ran in: 0.0020079612731933594 sec\n",
            "multilayer_perceptron ran in: 0.0018925666809082031 sec\n",
            "multilayer_perceptron ran in: 0.0017502307891845703 sec\n",
            "multilayer_perceptron ran in: 0.0017728805541992188 sec\n",
            "multilayer_perceptron ran in: 0.002722024917602539 sec\n",
            "multilayer_perceptron ran in: 0.0017578601837158203 sec\n",
            "multilayer_perceptron ran in: 0.0017399787902832031 sec\n",
            "multilayer_perceptron ran in: 0.0018181800842285156 sec\n",
            "multilayer_perceptron ran in: 0.0029015541076660156 sec\n",
            "multilayer_perceptron ran in: 0.0018608570098876953 sec\n",
            "multilayer_perceptron ran in: 0.0018322467803955078 sec\n",
            "multilayer_perceptron ran in: 0.0024170875549316406 sec\n",
            "multilayer_perceptron ran in: 0.0025403499603271484 sec\n",
            "multilayer_perceptron ran in: 0.0018377304077148438 sec\n",
            "multilayer_perceptron ran in: 0.0018894672393798828 sec\n",
            "multilayer_perceptron ran in: 0.0027892589569091797 sec\n",
            "multilayer_perceptron ran in: 0.0018680095672607422 sec\n",
            "multilayer_perceptron ran in: 0.0018694400787353516 sec\n",
            "multilayer_perceptron ran in: 0.0018165111541748047 sec\n",
            "multilayer_perceptron ran in: 0.0018758773803710938 sec\n",
            "multilayer_perceptron ran in: 0.0018417835235595703 sec\n",
            "multilayer_perceptron ran in: 0.006104230880737305 sec\n",
            "multilayer_perceptron ran in: 0.0017240047454833984 sec\n",
            "multilayer_perceptron ran in: 0.0020503997802734375 sec\n",
            "multilayer_perceptron ran in: 0.0017685890197753906 sec\n",
            "multilayer_perceptron ran in: 0.001909494400024414 sec\n",
            "multilayer_perceptron ran in: 0.0022678375244140625 sec\n",
            "multilayer_perceptron ran in: 0.0018427371978759766 sec\n",
            "multilayer_perceptron ran in: 0.001753091812133789 sec\n",
            "multilayer_perceptron ran in: 0.0029947757720947266 sec\n",
            "multilayer_perceptron ran in: 0.0019383430480957031 sec\n",
            "multilayer_perceptron ran in: 0.0017290115356445312 sec\n",
            "multilayer_perceptron ran in: 0.0018525123596191406 sec\n",
            "multilayer_perceptron ran in: 0.0017511844635009766 sec\n",
            "multilayer_perceptron ran in: 0.0018105506896972656 sec\n",
            "multilayer_perceptron ran in: 0.0017421245574951172 sec\n",
            "multilayer_perceptron ran in: 0.0017733573913574219 sec\n",
            "multilayer_perceptron ran in: 0.0018281936645507812 sec\n",
            "multilayer_perceptron ran in: 0.0017828941345214844 sec\n",
            "multilayer_perceptron ran in: 0.0018460750579833984 sec\n",
            "multilayer_perceptron ran in: 0.0017757415771484375 sec\n",
            "multilayer_perceptron ran in: 0.0017039775848388672 sec\n",
            "multilayer_perceptron ran in: 0.0018863677978515625 sec\n",
            "multilayer_perceptron ran in: 0.0018808841705322266 sec\n",
            "multilayer_perceptron ran in: 0.0018222332000732422 sec\n",
            "multilayer_perceptron ran in: 0.0017690658569335938 sec\n",
            "multilayer_perceptron ran in: 0.0025327205657958984 sec\n",
            "multilayer_perceptron ran in: 0.0016994476318359375 sec\n",
            "multilayer_perceptron ran in: 0.0017743110656738281 sec\n",
            "multilayer_perceptron ran in: 0.0018010139465332031 sec\n",
            "multilayer_perceptron ran in: 0.0019073486328125 sec\n",
            "multilayer_perceptron ran in: 0.001958131790161133 sec\n",
            "multilayer_perceptron ran in: 0.0024843215942382812 sec\n",
            "multilayer_perceptron ran in: 0.002447366714477539 sec\n",
            "multilayer_perceptron ran in: 0.002526521682739258 sec\n",
            "multilayer_perceptron ran in: 0.0019805431365966797 sec\n",
            "multilayer_perceptron ran in: 0.0019683837890625 sec\n",
            "multilayer_perceptron ran in: 0.0017249584197998047 sec\n",
            "multilayer_perceptron ran in: 0.0018346309661865234 sec\n",
            "multilayer_perceptron ran in: 0.001811981201171875 sec\n",
            "multilayer_perceptron ran in: 0.0024733543395996094 sec\n",
            "multilayer_perceptron ran in: 0.001953125 sec\n",
            "multilayer_perceptron ran in: 0.0018551349639892578 sec\n",
            "multilayer_perceptron ran in: 0.0017886161804199219 sec\n",
            "multilayer_perceptron ran in: 0.0018434524536132812 sec\n",
            "multilayer_perceptron ran in: 0.0017850399017333984 sec\n",
            "multilayer_perceptron ran in: 0.0019969940185546875 sec\n",
            "multilayer_perceptron ran in: 0.0017635822296142578 sec\n",
            "multilayer_perceptron ran in: 0.0018663406372070312 sec\n",
            "multilayer_perceptron ran in: 0.0022263526916503906 sec\n",
            "multilayer_perceptron ran in: 0.0018420219421386719 sec\n",
            "multilayer_perceptron ran in: 0.0025365352630615234 sec\n",
            "multilayer_perceptron ran in: 0.001775979995727539 sec\n",
            "multilayer_perceptron ran in: 0.0019183158874511719 sec\n",
            "multilayer_perceptron ran in: 0.004217863082885742 sec\n",
            "multilayer_perceptron ran in: 0.001672983169555664 sec\n",
            "multilayer_perceptron ran in: 0.001986980438232422 sec\n",
            "multilayer_perceptron ran in: 0.0019614696502685547 sec\n",
            "multilayer_perceptron ran in: 0.0018582344055175781 sec\n",
            "multilayer_perceptron ran in: 0.0018215179443359375 sec\n",
            "multilayer_perceptron ran in: 0.0018956661224365234 sec\n",
            "multilayer_perceptron ran in: 0.0020508766174316406 sec\n",
            "multilayer_perceptron ran in: 0.001928091049194336 sec\n",
            "multilayer_perceptron ran in: 0.0019059181213378906 sec\n",
            "multilayer_perceptron ran in: 0.002146005630493164 sec\n",
            "multilayer_perceptron ran in: 0.0018429756164550781 sec\n",
            "multilayer_perceptron ran in: 0.0018208026885986328 sec\n",
            "multilayer_perceptron ran in: 0.001775503158569336 sec\n",
            "multilayer_perceptron ran in: 0.0019044876098632812 sec\n",
            "multilayer_perceptron ran in: 0.0019812583923339844 sec\n",
            "multilayer_perceptron ran in: 0.0018863677978515625 sec\n",
            "multilayer_perceptron ran in: 0.0018734931945800781 sec\n",
            "multilayer_perceptron ran in: 0.002366781234741211 sec\n",
            "multilayer_perceptron ran in: 0.0018208026885986328 sec\n",
            "multilayer_perceptron ran in: 0.0018434524536132812 sec\n",
            "multilayer_perceptron ran in: 0.0016715526580810547 sec\n",
            "multilayer_perceptron ran in: 0.0018231868743896484 sec\n",
            "multilayer_perceptron ran in: 0.0019028186798095703 sec\n",
            "multilayer_perceptron ran in: 0.0017511844635009766 sec\n",
            "multilayer_perceptron ran in: 0.0017802715301513672 sec\n",
            "multilayer_perceptron ran in: 0.0026290416717529297 sec\n",
            "multilayer_perceptron ran in: 0.0019023418426513672 sec\n",
            "multilayer_perceptron ran in: 0.0018322467803955078 sec\n",
            "multilayer_perceptron ran in: 0.0018389225006103516 sec\n",
            "multilayer_perceptron ran in: 0.0018622875213623047 sec\n",
            "multilayer_perceptron ran in: 0.001810312271118164 sec\n",
            "multilayer_perceptron ran in: 0.0016584396362304688 sec\n",
            "multilayer_perceptron ran in: 0.0018258094787597656 sec\n",
            "multilayer_perceptron ran in: 0.0020895004272460938 sec\n",
            "multilayer_perceptron ran in: 0.0025560855865478516 sec\n",
            "multilayer_perceptron ran in: 0.001750946044921875 sec\n",
            "multilayer_perceptron ran in: 0.0018346309661865234 sec\n",
            "multilayer_perceptron ran in: 0.0018410682678222656 sec\n",
            "multilayer_perceptron ran in: 0.0020246505737304688 sec\n",
            "multilayer_perceptron ran in: 0.0024068355560302734 sec\n",
            "multilayer_perceptron ran in: 0.0022335052490234375 sec\n",
            "multilayer_perceptron ran in: 0.0019614696502685547 sec\n",
            "multilayer_perceptron ran in: 0.001935720443725586 sec\n",
            "multilayer_perceptron ran in: 0.001739501953125 sec\n",
            "multilayer_perceptron ran in: 0.0017609596252441406 sec\n",
            "multilayer_perceptron ran in: 0.0017790794372558594 sec\n",
            "multilayer_perceptron ran in: 0.0033864974975585938 sec\n",
            "multilayer_perceptron ran in: 0.0037665367126464844 sec\n",
            "multilayer_perceptron ran in: 0.0018486976623535156 sec\n",
            "multilayer_perceptron ran in: 0.0017986297607421875 sec\n",
            "multilayer_perceptron ran in: 0.0018527507781982422 sec\n",
            "multilayer_perceptron ran in: 0.0017774105072021484 sec\n",
            "multilayer_perceptron ran in: 0.0018885135650634766 sec\n",
            "multilayer_perceptron ran in: 0.002002239227294922 sec\n",
            "multilayer_perceptron ran in: 0.001878976821899414 sec\n",
            "multilayer_perceptron ran in: 0.001913309097290039 sec\n",
            "multilayer_perceptron ran in: 0.0019342899322509766 sec\n",
            "multilayer_perceptron ran in: 0.0017552375793457031 sec\n",
            "multilayer_perceptron ran in: 0.0017480850219726562 sec\n",
            "multilayer_perceptron ran in: 0.0018520355224609375 sec\n",
            "multilayer_perceptron ran in: 0.0018918514251708984 sec\n",
            "multilayer_perceptron ran in: 0.0025832653045654297 sec\n",
            "multilayer_perceptron ran in: 0.002440929412841797 sec\n",
            "multilayer_perceptron ran in: 0.0018575191497802734 sec\n",
            "multilayer_perceptron ran in: 0.002613067626953125 sec\n",
            "multilayer_perceptron ran in: 0.0019063949584960938 sec\n",
            "multilayer_perceptron ran in: 0.0019137859344482422 sec\n",
            "multilayer_perceptron ran in: 0.0018205642700195312 sec\n",
            "multilayer_perceptron ran in: 0.0017693042755126953 sec\n",
            "multilayer_perceptron ran in: 0.001977682113647461 sec\n",
            "multilayer_perceptron ran in: 0.001867055892944336 sec\n",
            "multilayer_perceptron ran in: 0.0018165111541748047 sec\n",
            "multilayer_perceptron ran in: 0.002687215805053711 sec\n",
            "multilayer_perceptron ran in: 0.0017535686492919922 sec\n",
            "multilayer_perceptron ran in: 0.0018470287322998047 sec\n",
            "multilayer_perceptron ran in: 0.0017576217651367188 sec\n",
            "multilayer_perceptron ran in: 0.001718759536743164 sec\n",
            "multilayer_perceptron ran in: 0.003566741943359375 sec\n",
            "multilayer_perceptron ran in: 0.0017707347869873047 sec\n",
            "multilayer_perceptron ran in: 0.0019965171813964844 sec\n",
            "multilayer_perceptron ran in: 0.0017840862274169922 sec\n",
            "multilayer_perceptron ran in: 0.001760721206665039 sec\n",
            "multilayer_perceptron ran in: 0.0018088817596435547 sec\n",
            "multilayer_perceptron ran in: 0.0017724037170410156 sec\n",
            "multilayer_perceptron ran in: 0.002458333969116211 sec\n",
            "multilayer_perceptron ran in: 0.0017354488372802734 sec\n",
            "multilayer_perceptron ran in: 0.0018105506896972656 sec\n",
            "multilayer_perceptron ran in: 0.002373933792114258 sec\n",
            "multilayer_perceptron ran in: 0.002082347869873047 sec\n",
            "multilayer_perceptron ran in: 0.0019202232360839844 sec\n",
            "multilayer_perceptron ran in: 0.0018231868743896484 sec\n",
            "multilayer_perceptron ran in: 0.0037899017333984375 sec\n",
            "multilayer_perceptron ran in: 0.0018281936645507812 sec\n",
            "multilayer_perceptron ran in: 0.001711130142211914 sec\n",
            "multilayer_perceptron ran in: 0.002033710479736328 sec\n",
            "multilayer_perceptron ran in: 0.0029807090759277344 sec\n",
            "multilayer_perceptron ran in: 0.001814126968383789 sec\n",
            "multilayer_perceptron ran in: 0.001953125 sec\n",
            "multilayer_perceptron ran in: 0.0017597675323486328 sec\n",
            "multilayer_perceptron ran in: 0.0018472671508789062 sec\n",
            "multilayer_perceptron ran in: 0.001806020736694336 sec\n",
            "multilayer_perceptron ran in: 0.0018541812896728516 sec\n",
            "multilayer_perceptron ran in: 0.0018115043640136719 sec\n",
            "multilayer_perceptron ran in: 0.0018339157104492188 sec\n",
            "multilayer_perceptron ran in: 0.0025031566619873047 sec\n",
            "multilayer_perceptron ran in: 0.0020360946655273438 sec\n",
            "multilayer_perceptron ran in: 0.0030336380004882812 sec\n",
            "multilayer_perceptron ran in: 0.002721548080444336 sec\n",
            "multilayer_perceptron ran in: 0.0024580955505371094 sec\n",
            "multilayer_perceptron ran in: 0.0032837390899658203 sec\n",
            "multilayer_perceptron ran in: 0.002720355987548828 sec\n",
            "multilayer_perceptron ran in: 0.002207517623901367 sec\n",
            "multilayer_perceptron ran in: 0.002229452133178711 sec\n",
            "multilayer_perceptron ran in: 0.0021483898162841797 sec\n",
            "multilayer_perceptron ran in: 0.002372264862060547 sec\n",
            "multilayer_perceptron ran in: 0.0022706985473632812 sec\n",
            "multilayer_perceptron ran in: 0.002386331558227539 sec\n",
            "multilayer_perceptron ran in: 0.002554655075073242 sec\n",
            "multilayer_perceptron ran in: 0.002382040023803711 sec\n",
            "multilayer_perceptron ran in: 0.002107381820678711 sec\n",
            "multilayer_perceptron ran in: 0.0022079944610595703 sec\n",
            "multilayer_perceptron ran in: 0.002191305160522461 sec\n",
            "Epoch: 8 Cost=27719.4785\n",
            "multilayer_perceptron ran in: 0.0021457672119140625 sec\n",
            "multilayer_perceptron ran in: 0.002084016799926758 sec\n",
            "multilayer_perceptron ran in: 0.002046346664428711 sec\n",
            "multilayer_perceptron ran in: 0.0025179386138916016 sec\n",
            "multilayer_perceptron ran in: 0.0025560855865478516 sec\n",
            "multilayer_perceptron ran in: 0.0022897720336914062 sec\n",
            "multilayer_perceptron ran in: 0.002324819564819336 sec\n",
            "multilayer_perceptron ran in: 0.0036895275115966797 sec\n",
            "multilayer_perceptron ran in: 0.004271030426025391 sec\n",
            "multilayer_perceptron ran in: 0.0031561851501464844 sec\n",
            "multilayer_perceptron ran in: 0.0049440860748291016 sec\n",
            "multilayer_perceptron ran in: 0.0021071434020996094 sec\n",
            "multilayer_perceptron ran in: 0.0026578903198242188 sec\n",
            "multilayer_perceptron ran in: 0.0025908946990966797 sec\n",
            "multilayer_perceptron ran in: 0.0024695396423339844 sec\n",
            "multilayer_perceptron ran in: 0.002496480941772461 sec\n",
            "multilayer_perceptron ran in: 0.0025005340576171875 sec\n",
            "multilayer_perceptron ran in: 0.0023767948150634766 sec\n",
            "multilayer_perceptron ran in: 0.0022635459899902344 sec\n",
            "multilayer_perceptron ran in: 0.0023729801177978516 sec\n",
            "multilayer_perceptron ran in: 0.0025217533111572266 sec\n",
            "multilayer_perceptron ran in: 0.0023391246795654297 sec\n",
            "multilayer_perceptron ran in: 0.002254009246826172 sec\n",
            "multilayer_perceptron ran in: 0.002431154251098633 sec\n",
            "multilayer_perceptron ran in: 0.002665281295776367 sec\n",
            "multilayer_perceptron ran in: 0.002566814422607422 sec\n",
            "multilayer_perceptron ran in: 0.003389596939086914 sec\n",
            "multilayer_perceptron ran in: 0.0026116371154785156 sec\n",
            "multilayer_perceptron ran in: 0.003773212432861328 sec\n",
            "multilayer_perceptron ran in: 0.0019268989562988281 sec\n",
            "multilayer_perceptron ran in: 0.0018718242645263672 sec\n",
            "multilayer_perceptron ran in: 0.0017833709716796875 sec\n",
            "multilayer_perceptron ran in: 0.0018107891082763672 sec\n",
            "multilayer_perceptron ran in: 0.0018219947814941406 sec\n",
            "multilayer_perceptron ran in: 0.0019426345825195312 sec\n",
            "multilayer_perceptron ran in: 0.0017223358154296875 sec\n",
            "multilayer_perceptron ran in: 0.0037276744842529297 sec\n",
            "multilayer_perceptron ran in: 0.0019278526306152344 sec\n",
            "multilayer_perceptron ran in: 0.001760244369506836 sec\n",
            "multilayer_perceptron ran in: 0.0019245147705078125 sec\n",
            "multilayer_perceptron ran in: 0.0017461776733398438 sec\n",
            "multilayer_perceptron ran in: 0.0018277168273925781 sec\n",
            "multilayer_perceptron ran in: 0.0026352405548095703 sec\n",
            "multilayer_perceptron ran in: 0.001863718032836914 sec\n",
            "multilayer_perceptron ran in: 0.001909017562866211 sec\n",
            "multilayer_perceptron ran in: 0.0018477439880371094 sec\n",
            "multilayer_perceptron ran in: 0.0031309127807617188 sec\n",
            "multilayer_perceptron ran in: 0.0019440650939941406 sec\n",
            "multilayer_perceptron ran in: 0.0025031566619873047 sec\n",
            "multilayer_perceptron ran in: 0.0017638206481933594 sec\n",
            "multilayer_perceptron ran in: 0.001800537109375 sec\n",
            "multilayer_perceptron ran in: 0.0038187503814697266 sec\n",
            "multilayer_perceptron ran in: 0.0018208026885986328 sec\n",
            "multilayer_perceptron ran in: 0.0018572807312011719 sec\n",
            "multilayer_perceptron ran in: 0.0018150806427001953 sec\n",
            "multilayer_perceptron ran in: 0.0019104480743408203 sec\n",
            "multilayer_perceptron ran in: 0.0035371780395507812 sec\n",
            "multilayer_perceptron ran in: 0.001912832260131836 sec\n",
            "multilayer_perceptron ran in: 0.0017900466918945312 sec\n",
            "multilayer_perceptron ran in: 0.0018336772918701172 sec\n",
            "multilayer_perceptron ran in: 0.0017540454864501953 sec\n",
            "multilayer_perceptron ran in: 0.003179788589477539 sec\n",
            "multilayer_perceptron ran in: 0.0019261837005615234 sec\n",
            "multilayer_perceptron ran in: 0.0018298625946044922 sec\n",
            "multilayer_perceptron ran in: 0.0019023418426513672 sec\n",
            "multilayer_perceptron ran in: 0.001953601837158203 sec\n",
            "multilayer_perceptron ran in: 0.0036122798919677734 sec\n",
            "multilayer_perceptron ran in: 0.002575397491455078 sec\n",
            "multilayer_perceptron ran in: 0.002061605453491211 sec\n",
            "multilayer_perceptron ran in: 0.0017762184143066406 sec\n",
            "multilayer_perceptron ran in: 0.001917123794555664 sec\n",
            "multilayer_perceptron ran in: 0.0019989013671875 sec\n",
            "multilayer_perceptron ran in: 0.0026247501373291016 sec\n",
            "multilayer_perceptron ran in: 0.0018775463104248047 sec\n",
            "multilayer_perceptron ran in: 0.002187013626098633 sec\n",
            "multilayer_perceptron ran in: 0.0018603801727294922 sec\n",
            "multilayer_perceptron ran in: 0.001981973648071289 sec\n",
            "multilayer_perceptron ran in: 0.002169370651245117 sec\n",
            "multilayer_perceptron ran in: 0.0018391609191894531 sec\n",
            "multilayer_perceptron ran in: 0.0017766952514648438 sec\n",
            "multilayer_perceptron ran in: 0.0017998218536376953 sec\n",
            "multilayer_perceptron ran in: 0.001791238784790039 sec\n",
            "multilayer_perceptron ran in: 0.001978635787963867 sec\n",
            "multilayer_perceptron ran in: 0.0025212764739990234 sec\n",
            "multilayer_perceptron ran in: 0.0017936229705810547 sec\n",
            "multilayer_perceptron ran in: 0.0017251968383789062 sec\n",
            "multilayer_perceptron ran in: 0.0023801326751708984 sec\n",
            "multilayer_perceptron ran in: 0.002112865447998047 sec\n",
            "multilayer_perceptron ran in: 0.0018787384033203125 sec\n",
            "multilayer_perceptron ran in: 0.0017786026000976562 sec\n",
            "multilayer_perceptron ran in: 0.0019025802612304688 sec\n",
            "multilayer_perceptron ran in: 0.001772165298461914 sec\n",
            "multilayer_perceptron ran in: 0.0017290115356445312 sec\n",
            "multilayer_perceptron ran in: 0.0018033981323242188 sec\n",
            "multilayer_perceptron ran in: 0.0017504692077636719 sec\n",
            "multilayer_perceptron ran in: 0.0018451213836669922 sec\n",
            "multilayer_perceptron ran in: 0.006738901138305664 sec\n",
            "multilayer_perceptron ran in: 0.0017344951629638672 sec\n",
            "multilayer_perceptron ran in: 0.0018210411071777344 sec\n",
            "multilayer_perceptron ran in: 0.001958131790161133 sec\n",
            "multilayer_perceptron ran in: 0.0019598007202148438 sec\n",
            "multilayer_perceptron ran in: 0.005614519119262695 sec\n",
            "multilayer_perceptron ran in: 0.001734018325805664 sec\n",
            "multilayer_perceptron ran in: 0.002087116241455078 sec\n",
            "multilayer_perceptron ran in: 0.0019426345825195312 sec\n",
            "multilayer_perceptron ran in: 0.0017666816711425781 sec\n",
            "multilayer_perceptron ran in: 0.0016696453094482422 sec\n",
            "multilayer_perceptron ran in: 0.0019261837005615234 sec\n",
            "multilayer_perceptron ran in: 0.0017914772033691406 sec\n",
            "multilayer_perceptron ran in: 0.002295970916748047 sec\n",
            "multilayer_perceptron ran in: 0.003330230712890625 sec\n",
            "multilayer_perceptron ran in: 0.0021882057189941406 sec\n",
            "multilayer_perceptron ran in: 0.0017809867858886719 sec\n",
            "multilayer_perceptron ran in: 0.0018243789672851562 sec\n",
            "multilayer_perceptron ran in: 0.0019059181213378906 sec\n",
            "multilayer_perceptron ran in: 0.0017251968383789062 sec\n",
            "multilayer_perceptron ran in: 0.0019032955169677734 sec\n",
            "multilayer_perceptron ran in: 0.002874612808227539 sec\n",
            "multilayer_perceptron ran in: 0.0020225048065185547 sec\n",
            "multilayer_perceptron ran in: 0.00170135498046875 sec\n",
            "multilayer_perceptron ran in: 0.0025637149810791016 sec\n",
            "multilayer_perceptron ran in: 0.0017821788787841797 sec\n",
            "multilayer_perceptron ran in: 0.0018544197082519531 sec\n",
            "multilayer_perceptron ran in: 0.0019352436065673828 sec\n",
            "multilayer_perceptron ran in: 0.0018961429595947266 sec\n",
            "multilayer_perceptron ran in: 0.0019571781158447266 sec\n",
            "multilayer_perceptron ran in: 0.0018935203552246094 sec\n",
            "multilayer_perceptron ran in: 0.001779317855834961 sec\n",
            "multilayer_perceptron ran in: 0.0021805763244628906 sec\n",
            "multilayer_perceptron ran in: 0.0021157264709472656 sec\n",
            "multilayer_perceptron ran in: 0.0019192695617675781 sec\n",
            "multilayer_perceptron ran in: 0.0018396377563476562 sec\n",
            "multilayer_perceptron ran in: 0.001990795135498047 sec\n",
            "multilayer_perceptron ran in: 0.0018839836120605469 sec\n",
            "multilayer_perceptron ran in: 0.0017848014831542969 sec\n",
            "multilayer_perceptron ran in: 0.00191497802734375 sec\n",
            "multilayer_perceptron ran in: 0.0018565654754638672 sec\n",
            "multilayer_perceptron ran in: 0.0023059844970703125 sec\n",
            "multilayer_perceptron ran in: 0.0017578601837158203 sec\n",
            "multilayer_perceptron ran in: 0.001924753189086914 sec\n",
            "multilayer_perceptron ran in: 0.0018546581268310547 sec\n",
            "multilayer_perceptron ran in: 0.002470254898071289 sec\n",
            "multilayer_perceptron ran in: 0.001811981201171875 sec\n",
            "multilayer_perceptron ran in: 0.0028014183044433594 sec\n",
            "multilayer_perceptron ran in: 0.0019345283508300781 sec\n",
            "multilayer_perceptron ran in: 0.0019257068634033203 sec\n",
            "multilayer_perceptron ran in: 0.0018887519836425781 sec\n",
            "multilayer_perceptron ran in: 0.0018551349639892578 sec\n",
            "multilayer_perceptron ran in: 0.0018875598907470703 sec\n",
            "multilayer_perceptron ran in: 0.0018973350524902344 sec\n",
            "multilayer_perceptron ran in: 0.0018455982208251953 sec\n",
            "multilayer_perceptron ran in: 0.0037522315979003906 sec\n",
            "multilayer_perceptron ran in: 0.002560138702392578 sec\n",
            "multilayer_perceptron ran in: 0.001811981201171875 sec\n",
            "multilayer_perceptron ran in: 0.0018398761749267578 sec\n",
            "multilayer_perceptron ran in: 0.001772165298461914 sec\n",
            "multilayer_perceptron ran in: 0.0019378662109375 sec\n",
            "multilayer_perceptron ran in: 0.002604961395263672 sec\n",
            "multilayer_perceptron ran in: 0.00202178955078125 sec\n",
            "multilayer_perceptron ran in: 0.0017981529235839844 sec\n",
            "multilayer_perceptron ran in: 0.0018091201782226562 sec\n",
            "multilayer_perceptron ran in: 0.0018634796142578125 sec\n",
            "multilayer_perceptron ran in: 0.002271413803100586 sec\n",
            "multilayer_perceptron ran in: 0.0018913745880126953 sec\n",
            "multilayer_perceptron ran in: 0.0017817020416259766 sec\n",
            "multilayer_perceptron ran in: 0.0017535686492919922 sec\n",
            "multilayer_perceptron ran in: 0.001750946044921875 sec\n",
            "multilayer_perceptron ran in: 0.001810312271118164 sec\n",
            "multilayer_perceptron ran in: 0.0018270015716552734 sec\n",
            "multilayer_perceptron ran in: 0.001931905746459961 sec\n",
            "multilayer_perceptron ran in: 0.001791238784790039 sec\n",
            "multilayer_perceptron ran in: 0.0017979145050048828 sec\n",
            "multilayer_perceptron ran in: 0.001974344253540039 sec\n",
            "multilayer_perceptron ran in: 0.0020818710327148438 sec\n",
            "multilayer_perceptron ran in: 0.001894235610961914 sec\n",
            "multilayer_perceptron ran in: 0.0018923282623291016 sec\n",
            "multilayer_perceptron ran in: 0.0018291473388671875 sec\n",
            "multilayer_perceptron ran in: 0.00197601318359375 sec\n",
            "multilayer_perceptron ran in: 0.001802682876586914 sec\n",
            "multilayer_perceptron ran in: 0.002696514129638672 sec\n",
            "multilayer_perceptron ran in: 0.0018548965454101562 sec\n",
            "multilayer_perceptron ran in: 0.0018711090087890625 sec\n",
            "multilayer_perceptron ran in: 0.0017855167388916016 sec\n",
            "multilayer_perceptron ran in: 0.0018377304077148438 sec\n",
            "multilayer_perceptron ran in: 0.0018680095672607422 sec\n",
            "multilayer_perceptron ran in: 0.001970529556274414 sec\n",
            "multilayer_perceptron ran in: 0.0018873214721679688 sec\n",
            "multilayer_perceptron ran in: 0.0017702579498291016 sec\n",
            "multilayer_perceptron ran in: 0.0019168853759765625 sec\n",
            "multilayer_perceptron ran in: 0.0017724037170410156 sec\n",
            "multilayer_perceptron ran in: 0.0019197463989257812 sec\n",
            "multilayer_perceptron ran in: 0.0018515586853027344 sec\n",
            "multilayer_perceptron ran in: 0.0018053054809570312 sec\n",
            "multilayer_perceptron ran in: 0.0021419525146484375 sec\n",
            "multilayer_perceptron ran in: 0.0020568370819091797 sec\n",
            "multilayer_perceptron ran in: 0.001978158950805664 sec\n",
            "multilayer_perceptron ran in: 0.0019023418426513672 sec\n",
            "multilayer_perceptron ran in: 0.0018410682678222656 sec\n",
            "multilayer_perceptron ran in: 0.0017991065979003906 sec\n",
            "multilayer_perceptron ran in: 0.001863718032836914 sec\n",
            "multilayer_perceptron ran in: 0.001814126968383789 sec\n",
            "multilayer_perceptron ran in: 0.0018703937530517578 sec\n",
            "multilayer_perceptron ran in: 0.0018475055694580078 sec\n",
            "multilayer_perceptron ran in: 0.001935720443725586 sec\n",
            "multilayer_perceptron ran in: 0.0019464492797851562 sec\n",
            "multilayer_perceptron ran in: 0.001913309097290039 sec\n",
            "multilayer_perceptron ran in: 0.0018513202667236328 sec\n",
            "multilayer_perceptron ran in: 0.0018668174743652344 sec\n",
            "multilayer_perceptron ran in: 0.0017969608306884766 sec\n",
            "multilayer_perceptron ran in: 0.00177764892578125 sec\n",
            "multilayer_perceptron ran in: 0.0017933845520019531 sec\n",
            "multilayer_perceptron ran in: 0.0017132759094238281 sec\n",
            "multilayer_perceptron ran in: 0.0018184185028076172 sec\n",
            "multilayer_perceptron ran in: 0.002092123031616211 sec\n",
            "multilayer_perceptron ran in: 0.0018434524536132812 sec\n",
            "multilayer_perceptron ran in: 0.0017650127410888672 sec\n",
            "multilayer_perceptron ran in: 0.0018889904022216797 sec\n",
            "multilayer_perceptron ran in: 0.0022690296173095703 sec\n",
            "multilayer_perceptron ran in: 0.0035469532012939453 sec\n",
            "multilayer_perceptron ran in: 0.001874685287475586 sec\n",
            "multilayer_perceptron ran in: 0.0018362998962402344 sec\n",
            "multilayer_perceptron ran in: 0.0019195079803466797 sec\n",
            "multilayer_perceptron ran in: 0.0017850399017333984 sec\n",
            "multilayer_perceptron ran in: 0.0018918514251708984 sec\n",
            "multilayer_perceptron ran in: 0.0017547607421875 sec\n",
            "multilayer_perceptron ran in: 0.0019168853759765625 sec\n",
            "multilayer_perceptron ran in: 0.002060413360595703 sec\n",
            "multilayer_perceptron ran in: 0.0018434524536132812 sec\n",
            "multilayer_perceptron ran in: 0.00182342529296875 sec\n",
            "multilayer_perceptron ran in: 0.0019240379333496094 sec\n",
            "multilayer_perceptron ran in: 0.0018591880798339844 sec\n",
            "multilayer_perceptron ran in: 0.0017201900482177734 sec\n",
            "multilayer_perceptron ran in: 0.0020041465759277344 sec\n",
            "multilayer_perceptron ran in: 0.0018613338470458984 sec\n",
            "multilayer_perceptron ran in: 0.002214670181274414 sec\n",
            "multilayer_perceptron ran in: 0.0017802715301513672 sec\n",
            "multilayer_perceptron ran in: 0.00438380241394043 sec\n",
            "multilayer_perceptron ran in: 0.0018835067749023438 sec\n",
            "multilayer_perceptron ran in: 0.0017752647399902344 sec\n",
            "multilayer_perceptron ran in: 0.0020987987518310547 sec\n",
            "Epoch: 9 Cost=32709.7637\n",
            "multilayer_perceptron ran in: 0.0022089481353759766 sec\n",
            "multilayer_perceptron ran in: 0.0019528865814208984 sec\n",
            "multilayer_perceptron ran in: 0.0019464492797851562 sec\n",
            "multilayer_perceptron ran in: 0.001901865005493164 sec\n",
            "multilayer_perceptron ran in: 0.0018970966339111328 sec\n",
            "multilayer_perceptron ran in: 0.0018310546875 sec\n",
            "multilayer_perceptron ran in: 0.0020236968994140625 sec\n",
            "multilayer_perceptron ran in: 0.0017032623291015625 sec\n",
            "multilayer_perceptron ran in: 0.0031392574310302734 sec\n",
            "multilayer_perceptron ran in: 0.001837015151977539 sec\n",
            "multilayer_perceptron ran in: 0.0020744800567626953 sec\n",
            "multilayer_perceptron ran in: 0.0018928050994873047 sec\n",
            "multilayer_perceptron ran in: 0.001990079879760742 sec\n",
            "multilayer_perceptron ran in: 0.0017209053039550781 sec\n",
            "multilayer_perceptron ran in: 0.004839658737182617 sec\n",
            "multilayer_perceptron ran in: 0.0017468929290771484 sec\n",
            "multilayer_perceptron ran in: 0.0018262863159179688 sec\n",
            "multilayer_perceptron ran in: 0.0018968582153320312 sec\n",
            "multilayer_perceptron ran in: 0.0026781558990478516 sec\n",
            "multilayer_perceptron ran in: 0.0077457427978515625 sec\n",
            "multilayer_perceptron ran in: 0.002107858657836914 sec\n",
            "multilayer_perceptron ran in: 0.002254009246826172 sec\n",
            "multilayer_perceptron ran in: 0.0027725696563720703 sec\n",
            "multilayer_perceptron ran in: 0.0021703243255615234 sec\n",
            "multilayer_perceptron ran in: 0.004869699478149414 sec\n",
            "multilayer_perceptron ran in: 0.0022766590118408203 sec\n",
            "multilayer_perceptron ran in: 0.002323627471923828 sec\n",
            "multilayer_perceptron ran in: 0.002307415008544922 sec\n",
            "multilayer_perceptron ran in: 0.002298593521118164 sec\n",
            "multilayer_perceptron ran in: 0.0023674964904785156 sec\n",
            "multilayer_perceptron ran in: 0.002216339111328125 sec\n",
            "multilayer_perceptron ran in: 0.0024747848510742188 sec\n",
            "multilayer_perceptron ran in: 0.0023200511932373047 sec\n",
            "multilayer_perceptron ran in: 0.0023980140686035156 sec\n",
            "multilayer_perceptron ran in: 0.002158641815185547 sec\n",
            "multilayer_perceptron ran in: 0.0020389556884765625 sec\n",
            "multilayer_perceptron ran in: 0.002104520797729492 sec\n",
            "multilayer_perceptron ran in: 0.0020058155059814453 sec\n",
            "multilayer_perceptron ran in: 0.0022995471954345703 sec\n",
            "multilayer_perceptron ran in: 0.0024521350860595703 sec\n",
            "multilayer_perceptron ran in: 0.006075382232666016 sec\n",
            "multilayer_perceptron ran in: 0.0018644332885742188 sec\n",
            "multilayer_perceptron ran in: 0.0025415420532226562 sec\n",
            "multilayer_perceptron ran in: 0.0021209716796875 sec\n",
            "multilayer_perceptron ran in: 0.002071857452392578 sec\n",
            "multilayer_perceptron ran in: 0.002789020538330078 sec\n",
            "multilayer_perceptron ran in: 0.002523183822631836 sec\n",
            "multilayer_perceptron ran in: 0.002371549606323242 sec\n",
            "multilayer_perceptron ran in: 0.0025131702423095703 sec\n",
            "multilayer_perceptron ran in: 0.0026292800903320312 sec\n",
            "multilayer_perceptron ran in: 0.0023813247680664062 sec\n",
            "multilayer_perceptron ran in: 0.0022950172424316406 sec\n",
            "multilayer_perceptron ran in: 0.0020093917846679688 sec\n",
            "multilayer_perceptron ran in: 0.0025823116302490234 sec\n",
            "multilayer_perceptron ran in: 0.008359193801879883 sec\n",
            "multilayer_perceptron ran in: 0.002290964126586914 sec\n",
            "multilayer_perceptron ran in: 0.0023632049560546875 sec\n",
            "multilayer_perceptron ran in: 0.0024123191833496094 sec\n",
            "multilayer_perceptron ran in: 0.0038018226623535156 sec\n",
            "multilayer_perceptron ran in: 0.0024166107177734375 sec\n",
            "multilayer_perceptron ran in: 0.00232696533203125 sec\n",
            "multilayer_perceptron ran in: 0.0022873878479003906 sec\n",
            "multilayer_perceptron ran in: 0.0024280548095703125 sec\n",
            "multilayer_perceptron ran in: 0.002208709716796875 sec\n",
            "multilayer_perceptron ran in: 0.0025277137756347656 sec\n",
            "multilayer_perceptron ran in: 0.002644777297973633 sec\n",
            "multilayer_perceptron ran in: 0.0027468204498291016 sec\n",
            "multilayer_perceptron ran in: 0.0028219223022460938 sec\n",
            "multilayer_perceptron ran in: 0.0027396678924560547 sec\n",
            "multilayer_perceptron ran in: 0.004094362258911133 sec\n",
            "multilayer_perceptron ran in: 0.001982450485229492 sec\n",
            "multilayer_perceptron ran in: 0.0019791126251220703 sec\n",
            "multilayer_perceptron ran in: 0.001714468002319336 sec\n",
            "multilayer_perceptron ran in: 0.003037691116333008 sec\n",
            "multilayer_perceptron ran in: 0.001886606216430664 sec\n",
            "multilayer_perceptron ran in: 0.0018925666809082031 sec\n",
            "multilayer_perceptron ran in: 0.00202178955078125 sec\n",
            "multilayer_perceptron ran in: 0.0017697811126708984 sec\n",
            "multilayer_perceptron ran in: 0.001806497573852539 sec\n",
            "multilayer_perceptron ran in: 0.004693508148193359 sec\n",
            "multilayer_perceptron ran in: 0.0017819404602050781 sec\n",
            "multilayer_perceptron ran in: 0.0018188953399658203 sec\n",
            "multilayer_perceptron ran in: 0.0017762184143066406 sec\n",
            "multilayer_perceptron ran in: 0.0018210411071777344 sec\n",
            "multilayer_perceptron ran in: 0.0028786659240722656 sec\n",
            "multilayer_perceptron ran in: 0.002034902572631836 sec\n",
            "multilayer_perceptron ran in: 0.003046751022338867 sec\n",
            "multilayer_perceptron ran in: 0.0018868446350097656 sec\n",
            "multilayer_perceptron ran in: 0.0019991397857666016 sec\n",
            "multilayer_perceptron ran in: 0.0018966197967529297 sec\n",
            "multilayer_perceptron ran in: 0.0018935203552246094 sec\n",
            "multilayer_perceptron ran in: 0.0018227100372314453 sec\n",
            "multilayer_perceptron ran in: 0.0018258094787597656 sec\n",
            "multilayer_perceptron ran in: 0.0017719268798828125 sec\n",
            "multilayer_perceptron ran in: 0.0017080307006835938 sec\n",
            "multilayer_perceptron ran in: 0.0017383098602294922 sec\n",
            "multilayer_perceptron ran in: 0.0018382072448730469 sec\n",
            "multilayer_perceptron ran in: 0.0017693042755126953 sec\n",
            "multilayer_perceptron ran in: 0.0017499923706054688 sec\n",
            "multilayer_perceptron ran in: 0.001748800277709961 sec\n",
            "multilayer_perceptron ran in: 0.0018138885498046875 sec\n",
            "multilayer_perceptron ran in: 0.002130270004272461 sec\n",
            "multilayer_perceptron ran in: 0.0043621063232421875 sec\n",
            "multilayer_perceptron ran in: 0.0019063949584960938 sec\n",
            "multilayer_perceptron ran in: 0.002080678939819336 sec\n",
            "multilayer_perceptron ran in: 0.0018267631530761719 sec\n",
            "multilayer_perceptron ran in: 0.002087831497192383 sec\n",
            "multilayer_perceptron ran in: 0.001981019973754883 sec\n",
            "multilayer_perceptron ran in: 0.0019102096557617188 sec\n",
            "multilayer_perceptron ran in: 0.0017199516296386719 sec\n",
            "multilayer_perceptron ran in: 0.0019698143005371094 sec\n",
            "multilayer_perceptron ran in: 0.001798391342163086 sec\n",
            "multilayer_perceptron ran in: 0.0018892288208007812 sec\n",
            "multilayer_perceptron ran in: 0.0018477439880371094 sec\n",
            "multilayer_perceptron ran in: 0.0039052963256835938 sec\n",
            "multilayer_perceptron ran in: 0.0018587112426757812 sec\n",
            "multilayer_perceptron ran in: 0.0017971992492675781 sec\n",
            "multilayer_perceptron ran in: 0.0018603801727294922 sec\n",
            "multilayer_perceptron ran in: 0.0018792152404785156 sec\n",
            "multilayer_perceptron ran in: 0.0017423629760742188 sec\n",
            "multilayer_perceptron ran in: 0.001924276351928711 sec\n",
            "multilayer_perceptron ran in: 0.0018835067749023438 sec\n",
            "multilayer_perceptron ran in: 0.0018706321716308594 sec\n",
            "multilayer_perceptron ran in: 0.0018939971923828125 sec\n",
            "multilayer_perceptron ran in: 0.0036978721618652344 sec\n",
            "multilayer_perceptron ran in: 0.001829385757446289 sec\n",
            "multilayer_perceptron ran in: 0.0017833709716796875 sec\n",
            "multilayer_perceptron ran in: 0.001773834228515625 sec\n",
            "multilayer_perceptron ran in: 0.0018241405487060547 sec\n",
            "multilayer_perceptron ran in: 0.0034668445587158203 sec\n",
            "multilayer_perceptron ran in: 0.0019736289978027344 sec\n",
            "multilayer_perceptron ran in: 0.0017101764678955078 sec\n",
            "multilayer_perceptron ran in: 0.0018455982208251953 sec\n",
            "multilayer_perceptron ran in: 0.0017800331115722656 sec\n",
            "multilayer_perceptron ran in: 0.0018851757049560547 sec\n",
            "multilayer_perceptron ran in: 0.0017795562744140625 sec\n",
            "multilayer_perceptron ran in: 0.0019068717956542969 sec\n",
            "multilayer_perceptron ran in: 0.0017821788787841797 sec\n",
            "multilayer_perceptron ran in: 0.0018811225891113281 sec\n",
            "multilayer_perceptron ran in: 0.003082275390625 sec\n",
            "multilayer_perceptron ran in: 0.0016655921936035156 sec\n",
            "multilayer_perceptron ran in: 0.0018873214721679688 sec\n",
            "multilayer_perceptron ran in: 0.0017940998077392578 sec\n",
            "multilayer_perceptron ran in: 0.0016911029815673828 sec\n",
            "multilayer_perceptron ran in: 0.001901865005493164 sec\n",
            "multilayer_perceptron ran in: 0.0019958019256591797 sec\n",
            "multilayer_perceptron ran in: 0.0017888545989990234 sec\n",
            "multilayer_perceptron ran in: 0.0018315315246582031 sec\n",
            "multilayer_perceptron ran in: 0.001744985580444336 sec\n",
            "multilayer_perceptron ran in: 0.001867532730102539 sec\n",
            "multilayer_perceptron ran in: 0.0017657279968261719 sec\n",
            "multilayer_perceptron ran in: 0.0018606185913085938 sec\n",
            "multilayer_perceptron ran in: 0.0018763542175292969 sec\n",
            "multilayer_perceptron ran in: 0.0018088817596435547 sec\n",
            "multilayer_perceptron ran in: 0.004750967025756836 sec\n",
            "multilayer_perceptron ran in: 0.0018658638000488281 sec\n",
            "multilayer_perceptron ran in: 0.001947164535522461 sec\n",
            "multilayer_perceptron ran in: 0.001922607421875 sec\n",
            "multilayer_perceptron ran in: 0.002161741256713867 sec\n",
            "multilayer_perceptron ran in: 0.002039670944213867 sec\n",
            "multilayer_perceptron ran in: 0.001912832260131836 sec\n",
            "multilayer_perceptron ran in: 0.0019214153289794922 sec\n",
            "multilayer_perceptron ran in: 0.0018110275268554688 sec\n",
            "multilayer_perceptron ran in: 0.0018961429595947266 sec\n",
            "multilayer_perceptron ran in: 0.0019075870513916016 sec\n",
            "multilayer_perceptron ran in: 0.001779794692993164 sec\n",
            "multilayer_perceptron ran in: 0.0019047260284423828 sec\n",
            "multilayer_perceptron ran in: 0.0018448829650878906 sec\n",
            "multilayer_perceptron ran in: 0.0018463134765625 sec\n",
            "multilayer_perceptron ran in: 0.002943277359008789 sec\n",
            "multilayer_perceptron ran in: 0.001996755599975586 sec\n",
            "multilayer_perceptron ran in: 0.0018877983093261719 sec\n",
            "multilayer_perceptron ran in: 0.0018410682678222656 sec\n",
            "multilayer_perceptron ran in: 0.0021004676818847656 sec\n",
            "multilayer_perceptron ran in: 0.0018384456634521484 sec\n",
            "multilayer_perceptron ran in: 0.0018525123596191406 sec\n",
            "multilayer_perceptron ran in: 0.0018448829650878906 sec\n",
            "multilayer_perceptron ran in: 0.002214193344116211 sec\n",
            "multilayer_perceptron ran in: 0.0027484893798828125 sec\n",
            "multilayer_perceptron ran in: 0.00423884391784668 sec\n",
            "multilayer_perceptron ran in: 0.0018205642700195312 sec\n",
            "multilayer_perceptron ran in: 0.0018672943115234375 sec\n",
            "multilayer_perceptron ran in: 0.0018885135650634766 sec\n",
            "multilayer_perceptron ran in: 0.0019140243530273438 sec\n",
            "multilayer_perceptron ran in: 0.003429412841796875 sec\n",
            "multilayer_perceptron ran in: 0.001901388168334961 sec\n",
            "multilayer_perceptron ran in: 0.002564668655395508 sec\n",
            "multilayer_perceptron ran in: 0.0019423961639404297 sec\n",
            "multilayer_perceptron ran in: 0.001798868179321289 sec\n",
            "multilayer_perceptron ran in: 0.0017337799072265625 sec\n",
            "multilayer_perceptron ran in: 0.002536773681640625 sec\n",
            "multilayer_perceptron ran in: 0.0018274784088134766 sec\n",
            "multilayer_perceptron ran in: 0.0018014907836914062 sec\n",
            "multilayer_perceptron ran in: 0.0027294158935546875 sec\n",
            "multilayer_perceptron ran in: 0.0016326904296875 sec\n",
            "multilayer_perceptron ran in: 0.0019228458404541016 sec\n",
            "multilayer_perceptron ran in: 0.0017893314361572266 sec\n",
            "multilayer_perceptron ran in: 0.0017974376678466797 sec\n",
            "multilayer_perceptron ran in: 0.002575397491455078 sec\n",
            "multilayer_perceptron ran in: 0.002277851104736328 sec\n",
            "multilayer_perceptron ran in: 0.0021805763244628906 sec\n",
            "multilayer_perceptron ran in: 0.0019402503967285156 sec\n",
            "multilayer_perceptron ran in: 0.0018620491027832031 sec\n",
            "multilayer_perceptron ran in: 0.0029115676879882812 sec\n",
            "multilayer_perceptron ran in: 0.0034072399139404297 sec\n",
            "multilayer_perceptron ran in: 0.002949953079223633 sec\n",
            "multilayer_perceptron ran in: 0.001775979995727539 sec\n",
            "multilayer_perceptron ran in: 0.00205230712890625 sec\n",
            "multilayer_perceptron ran in: 0.0022802352905273438 sec\n",
            "multilayer_perceptron ran in: 0.0018498897552490234 sec\n",
            "multilayer_perceptron ran in: 0.001810312271118164 sec\n",
            "multilayer_perceptron ran in: 0.0018277168273925781 sec\n",
            "multilayer_perceptron ran in: 0.0019550323486328125 sec\n",
            "multilayer_perceptron ran in: 0.0022025108337402344 sec\n",
            "multilayer_perceptron ran in: 0.002065896987915039 sec\n",
            "multilayer_perceptron ran in: 0.002301454544067383 sec\n",
            "multilayer_perceptron ran in: 0.0018382072448730469 sec\n",
            "multilayer_perceptron ran in: 0.0018153190612792969 sec\n",
            "multilayer_perceptron ran in: 0.0019397735595703125 sec\n",
            "multilayer_perceptron ran in: 0.0018353462219238281 sec\n",
            "multilayer_perceptron ran in: 0.0018329620361328125 sec\n",
            "multilayer_perceptron ran in: 0.0018694400787353516 sec\n",
            "multilayer_perceptron ran in: 0.0019032955169677734 sec\n",
            "multilayer_perceptron ran in: 0.002788066864013672 sec\n",
            "multilayer_perceptron ran in: 0.0017657279968261719 sec\n",
            "multilayer_perceptron ran in: 0.001998424530029297 sec\n",
            "multilayer_perceptron ran in: 0.0018138885498046875 sec\n",
            "multilayer_perceptron ran in: 0.001863718032836914 sec\n",
            "multilayer_perceptron ran in: 0.0018918514251708984 sec\n",
            "multilayer_perceptron ran in: 0.0020875930786132812 sec\n",
            "multilayer_perceptron ran in: 0.0019292831420898438 sec\n",
            "multilayer_perceptron ran in: 0.0020270347595214844 sec\n",
            "multilayer_perceptron ran in: 0.0018873214721679688 sec\n",
            "multilayer_perceptron ran in: 0.0018908977508544922 sec\n",
            "multilayer_perceptron ran in: 0.0018622875213623047 sec\n",
            "multilayer_perceptron ran in: 0.001840353012084961 sec\n",
            "multilayer_perceptron ran in: 0.0018696784973144531 sec\n",
            "multilayer_perceptron ran in: 0.0018813610076904297 sec\n",
            "multilayer_perceptron ran in: 0.003625154495239258 sec\n",
            "multilayer_perceptron ran in: 0.0017404556274414062 sec\n",
            "Epoch: 10 Cost=37964.0898\n",
            "multilayer_perceptron ran in: 0.0022478103637695312 sec\n",
            "multilayer_perceptron ran in: 0.001752614974975586 sec\n",
            "multilayer_perceptron ran in: 0.0019087791442871094 sec\n",
            "multilayer_perceptron ran in: 0.0018129348754882812 sec\n",
            "multilayer_perceptron ran in: 0.0018672943115234375 sec\n",
            "multilayer_perceptron ran in: 0.0021436214447021484 sec\n",
            "multilayer_perceptron ran in: 0.0019099712371826172 sec\n",
            "multilayer_perceptron ran in: 0.002493619918823242 sec\n",
            "multilayer_perceptron ran in: 0.0018353462219238281 sec\n",
            "multilayer_perceptron ran in: 0.0018601417541503906 sec\n",
            "multilayer_perceptron ran in: 0.001806020736694336 sec\n",
            "multilayer_perceptron ran in: 0.0017533302307128906 sec\n",
            "multilayer_perceptron ran in: 0.0019295215606689453 sec\n",
            "multilayer_perceptron ran in: 0.0024797916412353516 sec\n",
            "multilayer_perceptron ran in: 0.001764059066772461 sec\n",
            "multilayer_perceptron ran in: 0.001833200454711914 sec\n",
            "multilayer_perceptron ran in: 0.0017218589782714844 sec\n",
            "multilayer_perceptron ran in: 0.0018262863159179688 sec\n",
            "multilayer_perceptron ran in: 0.0018651485443115234 sec\n",
            "multilayer_perceptron ran in: 0.0018017292022705078 sec\n",
            "multilayer_perceptron ran in: 0.001912832260131836 sec\n",
            "multilayer_perceptron ran in: 0.001800537109375 sec\n",
            "multilayer_perceptron ran in: 0.001895904541015625 sec\n",
            "multilayer_perceptron ran in: 0.0018401145935058594 sec\n",
            "multilayer_perceptron ran in: 0.001878499984741211 sec\n",
            "multilayer_perceptron ran in: 0.0019538402557373047 sec\n",
            "multilayer_perceptron ran in: 0.0037364959716796875 sec\n",
            "multilayer_perceptron ran in: 0.0018706321716308594 sec\n",
            "multilayer_perceptron ran in: 0.0020453929901123047 sec\n",
            "multilayer_perceptron ran in: 0.0018978118896484375 sec\n",
            "multilayer_perceptron ran in: 0.0018568038940429688 sec\n",
            "multilayer_perceptron ran in: 0.0019898414611816406 sec\n",
            "multilayer_perceptron ran in: 0.0024471282958984375 sec\n",
            "multilayer_perceptron ran in: 0.0019903182983398438 sec\n",
            "multilayer_perceptron ran in: 0.002163410186767578 sec\n",
            "multilayer_perceptron ran in: 0.0019631385803222656 sec\n",
            "multilayer_perceptron ran in: 0.002095937728881836 sec\n",
            "multilayer_perceptron ran in: 0.0018739700317382812 sec\n",
            "multilayer_perceptron ran in: 0.0020422935485839844 sec\n",
            "multilayer_perceptron ran in: 0.0018575191497802734 sec\n",
            "multilayer_perceptron ran in: 0.001844644546508789 sec\n",
            "multilayer_perceptron ran in: 0.0019359588623046875 sec\n",
            "multilayer_perceptron ran in: 0.002299785614013672 sec\n",
            "multilayer_perceptron ran in: 0.002413511276245117 sec\n",
            "multilayer_perceptron ran in: 0.0017511844635009766 sec\n",
            "multilayer_perceptron ran in: 0.0017380714416503906 sec\n",
            "multilayer_perceptron ran in: 0.0017991065979003906 sec\n",
            "multilayer_perceptron ran in: 0.0019719600677490234 sec\n",
            "multilayer_perceptron ran in: 0.0018830299377441406 sec\n",
            "multilayer_perceptron ran in: 0.0027480125427246094 sec\n",
            "multilayer_perceptron ran in: 0.0024628639221191406 sec\n",
            "multilayer_perceptron ran in: 0.002779722213745117 sec\n",
            "multilayer_perceptron ran in: 0.0024683475494384766 sec\n",
            "multilayer_perceptron ran in: 0.002459287643432617 sec\n",
            "multilayer_perceptron ran in: 0.003926753997802734 sec\n",
            "multilayer_perceptron ran in: 0.0024251937866210938 sec\n",
            "multilayer_perceptron ran in: 0.008889913558959961 sec\n",
            "multilayer_perceptron ran in: 0.0021483898162841797 sec\n",
            "multilayer_perceptron ran in: 0.002123117446899414 sec\n",
            "multilayer_perceptron ran in: 0.0021696090698242188 sec\n",
            "multilayer_perceptron ran in: 0.003656148910522461 sec\n",
            "multilayer_perceptron ran in: 0.0022919178009033203 sec\n",
            "multilayer_perceptron ran in: 0.0024671554565429688 sec\n",
            "multilayer_perceptron ran in: 0.0022513866424560547 sec\n",
            "multilayer_perceptron ran in: 0.002109050750732422 sec\n",
            "multilayer_perceptron ran in: 0.002079010009765625 sec\n",
            "multilayer_perceptron ran in: 0.00206756591796875 sec\n",
            "multilayer_perceptron ran in: 0.0021381378173828125 sec\n",
            "multilayer_perceptron ran in: 0.0023343563079833984 sec\n",
            "multilayer_perceptron ran in: 0.002120494842529297 sec\n",
            "multilayer_perceptron ran in: 0.0026035308837890625 sec\n",
            "multilayer_perceptron ran in: 0.0022635459899902344 sec\n",
            "multilayer_perceptron ran in: 0.002393007278442383 sec\n",
            "multilayer_perceptron ran in: 0.0025806427001953125 sec\n",
            "multilayer_perceptron ran in: 0.0021135807037353516 sec\n",
            "multilayer_perceptron ran in: 0.002276182174682617 sec\n",
            "multilayer_perceptron ran in: 0.0027022361755371094 sec\n",
            "multilayer_perceptron ran in: 0.003370523452758789 sec\n",
            "multilayer_perceptron ran in: 0.002015829086303711 sec\n",
            "multilayer_perceptron ran in: 0.0024771690368652344 sec\n",
            "multilayer_perceptron ran in: 0.002503633499145508 sec\n",
            "multilayer_perceptron ran in: 0.0023963451385498047 sec\n",
            "multilayer_perceptron ran in: 0.0027132034301757812 sec\n",
            "multilayer_perceptron ran in: 0.00243377685546875 sec\n",
            "multilayer_perceptron ran in: 0.0022966861724853516 sec\n",
            "multilayer_perceptron ran in: 0.0023872852325439453 sec\n",
            "multilayer_perceptron ran in: 0.002432584762573242 sec\n",
            "multilayer_perceptron ran in: 0.004052162170410156 sec\n",
            "multilayer_perceptron ran in: 0.0024542808532714844 sec\n",
            "multilayer_perceptron ran in: 0.0022864341735839844 sec\n",
            "multilayer_perceptron ran in: 0.0022792816162109375 sec\n",
            "multilayer_perceptron ran in: 0.0022149085998535156 sec\n",
            "multilayer_perceptron ran in: 0.002585172653198242 sec\n",
            "multilayer_perceptron ran in: 0.0024292469024658203 sec\n",
            "multilayer_perceptron ran in: 0.0023810863494873047 sec\n",
            "multilayer_perceptron ran in: 0.0026497840881347656 sec\n",
            "multilayer_perceptron ran in: 0.002400636672973633 sec\n",
            "multilayer_perceptron ran in: 0.0023593902587890625 sec\n",
            "multilayer_perceptron ran in: 0.002466917037963867 sec\n",
            "multilayer_perceptron ran in: 0.0024466514587402344 sec\n",
            "multilayer_perceptron ran in: 0.0025653839111328125 sec\n",
            "multilayer_perceptron ran in: 0.0024373531341552734 sec\n",
            "multilayer_perceptron ran in: 0.002744913101196289 sec\n",
            "multilayer_perceptron ran in: 0.0027184486389160156 sec\n",
            "multilayer_perceptron ran in: 0.0023870468139648438 sec\n",
            "multilayer_perceptron ran in: 0.001844167709350586 sec\n",
            "multilayer_perceptron ran in: 0.0018763542175292969 sec\n",
            "multilayer_perceptron ran in: 0.0017385482788085938 sec\n",
            "multilayer_perceptron ran in: 0.0018894672393798828 sec\n",
            "multilayer_perceptron ran in: 0.0017955303192138672 sec\n",
            "multilayer_perceptron ran in: 0.002537965774536133 sec\n",
            "multilayer_perceptron ran in: 0.001886129379272461 sec\n",
            "multilayer_perceptron ran in: 0.0021605491638183594 sec\n",
            "multilayer_perceptron ran in: 0.006801128387451172 sec\n",
            "multilayer_perceptron ran in: 0.0027894973754882812 sec\n",
            "multilayer_perceptron ran in: 0.002374887466430664 sec\n",
            "multilayer_perceptron ran in: 0.0024995803833007812 sec\n",
            "multilayer_perceptron ran in: 0.0020606517791748047 sec\n",
            "multilayer_perceptron ran in: 0.0018892288208007812 sec\n",
            "multilayer_perceptron ran in: 0.0029785633087158203 sec\n",
            "multilayer_perceptron ran in: 0.0020720958709716797 sec\n",
            "multilayer_perceptron ran in: 0.0021352767944335938 sec\n",
            "multilayer_perceptron ran in: 0.0017728805541992188 sec\n",
            "multilayer_perceptron ran in: 0.0019621849060058594 sec\n",
            "multilayer_perceptron ran in: 0.0023910999298095703 sec\n",
            "multilayer_perceptron ran in: 0.001916646957397461 sec\n",
            "multilayer_perceptron ran in: 0.0024216175079345703 sec\n",
            "multilayer_perceptron ran in: 0.0018589496612548828 sec\n",
            "multilayer_perceptron ran in: 0.0018548965454101562 sec\n",
            "multilayer_perceptron ran in: 0.0022504329681396484 sec\n",
            "multilayer_perceptron ran in: 0.0021066665649414062 sec\n",
            "multilayer_perceptron ran in: 0.0034122467041015625 sec\n",
            "multilayer_perceptron ran in: 0.0040435791015625 sec\n",
            "multilayer_perceptron ran in: 0.002515077590942383 sec\n",
            "multilayer_perceptron ran in: 0.00226593017578125 sec\n",
            "multilayer_perceptron ran in: 0.0027077198028564453 sec\n",
            "multilayer_perceptron ran in: 0.0020661354064941406 sec\n",
            "multilayer_perceptron ran in: 0.00185394287109375 sec\n",
            "multilayer_perceptron ran in: 0.002149820327758789 sec\n",
            "multilayer_perceptron ran in: 0.002420186996459961 sec\n",
            "multilayer_perceptron ran in: 0.0020220279693603516 sec\n",
            "multilayer_perceptron ran in: 0.0018336772918701172 sec\n",
            "multilayer_perceptron ran in: 0.0023992061614990234 sec\n",
            "multilayer_perceptron ran in: 0.0021195411682128906 sec\n",
            "multilayer_perceptron ran in: 0.0018353462219238281 sec\n",
            "multilayer_perceptron ran in: 0.0029473304748535156 sec\n",
            "multilayer_perceptron ran in: 0.0019214153289794922 sec\n",
            "multilayer_perceptron ran in: 0.0027709007263183594 sec\n",
            "multilayer_perceptron ran in: 0.0021886825561523438 sec\n",
            "multilayer_perceptron ran in: 0.0035419464111328125 sec\n",
            "multilayer_perceptron ran in: 0.0030782222747802734 sec\n",
            "multilayer_perceptron ran in: 0.0025365352630615234 sec\n",
            "multilayer_perceptron ran in: 0.0019795894622802734 sec\n",
            "multilayer_perceptron ran in: 0.0017852783203125 sec\n",
            "multilayer_perceptron ran in: 0.0019855499267578125 sec\n",
            "multilayer_perceptron ran in: 0.0024881362915039062 sec\n",
            "multilayer_perceptron ran in: 0.003102540969848633 sec\n",
            "multilayer_perceptron ran in: 0.002653837203979492 sec\n",
            "multilayer_perceptron ran in: 0.004456043243408203 sec\n",
            "multilayer_perceptron ran in: 0.003871440887451172 sec\n",
            "multilayer_perceptron ran in: 0.0020449161529541016 sec\n",
            "multilayer_perceptron ran in: 0.002129077911376953 sec\n",
            "multilayer_perceptron ran in: 0.0024640560150146484 sec\n",
            "multilayer_perceptron ran in: 0.002974271774291992 sec\n",
            "multilayer_perceptron ran in: 0.001806020736694336 sec\n",
            "multilayer_perceptron ran in: 0.0017597675323486328 sec\n",
            "multilayer_perceptron ran in: 0.0019237995147705078 sec\n",
            "multilayer_perceptron ran in: 0.0017859935760498047 sec\n",
            "multilayer_perceptron ran in: 0.0016903877258300781 sec\n",
            "multilayer_perceptron ran in: 0.002186298370361328 sec\n",
            "multilayer_perceptron ran in: 0.0018799304962158203 sec\n",
            "multilayer_perceptron ran in: 0.0017609596252441406 sec\n",
            "multilayer_perceptron ran in: 0.001817464828491211 sec\n",
            "multilayer_perceptron ran in: 0.009187698364257812 sec\n",
            "multilayer_perceptron ran in: 0.0025551319122314453 sec\n",
            "multilayer_perceptron ran in: 0.0022225379943847656 sec\n",
            "multilayer_perceptron ran in: 0.004328250885009766 sec\n",
            "multilayer_perceptron ran in: 0.0040242671966552734 sec\n",
            "multilayer_perceptron ran in: 0.0041234493255615234 sec\n",
            "multilayer_perceptron ran in: 0.002541780471801758 sec\n",
            "multilayer_perceptron ran in: 0.004179477691650391 sec\n",
            "multilayer_perceptron ran in: 0.0036385059356689453 sec\n",
            "multilayer_perceptron ran in: 0.0019021034240722656 sec\n",
            "multilayer_perceptron ran in: 0.0044820308685302734 sec\n",
            "multilayer_perceptron ran in: 0.002688169479370117 sec\n",
            "multilayer_perceptron ran in: 0.001976490020751953 sec\n",
            "multilayer_perceptron ran in: 0.0019028186798095703 sec\n",
            "multilayer_perceptron ran in: 0.0018646717071533203 sec\n",
            "multilayer_perceptron ran in: 0.0029582977294921875 sec\n",
            "multilayer_perceptron ran in: 0.0018393993377685547 sec\n",
            "multilayer_perceptron ran in: 0.0018854141235351562 sec\n",
            "multilayer_perceptron ran in: 0.0023980140686035156 sec\n",
            "multilayer_perceptron ran in: 0.0018475055694580078 sec\n",
            "multilayer_perceptron ran in: 0.0018925666809082031 sec\n",
            "multilayer_perceptron ran in: 0.0057621002197265625 sec\n",
            "multilayer_perceptron ran in: 0.0018239021301269531 sec\n",
            "multilayer_perceptron ran in: 0.0017852783203125 sec\n",
            "multilayer_perceptron ran in: 0.0016989707946777344 sec\n",
            "multilayer_perceptron ran in: 0.0017347335815429688 sec\n",
            "multilayer_perceptron ran in: 0.0020112991333007812 sec\n",
            "multilayer_perceptron ran in: 0.002493143081665039 sec\n",
            "multilayer_perceptron ran in: 0.002037525177001953 sec\n",
            "multilayer_perceptron ran in: 0.0018620491027832031 sec\n",
            "multilayer_perceptron ran in: 0.002498149871826172 sec\n",
            "multilayer_perceptron ran in: 0.0018031597137451172 sec\n",
            "multilayer_perceptron ran in: 0.0018873214721679688 sec\n",
            "multilayer_perceptron ran in: 0.0018711090087890625 sec\n",
            "multilayer_perceptron ran in: 0.0018427371978759766 sec\n",
            "multilayer_perceptron ran in: 0.0017981529235839844 sec\n",
            "multilayer_perceptron ran in: 0.0030837059020996094 sec\n",
            "multilayer_perceptron ran in: 0.001878499984741211 sec\n",
            "multilayer_perceptron ran in: 0.0018124580383300781 sec\n",
            "multilayer_perceptron ran in: 0.0019338130950927734 sec\n",
            "multilayer_perceptron ran in: 0.001739501953125 sec\n",
            "multilayer_perceptron ran in: 0.0018532276153564453 sec\n",
            "multilayer_perceptron ran in: 0.002177715301513672 sec\n",
            "multilayer_perceptron ran in: 0.002438068389892578 sec\n",
            "multilayer_perceptron ran in: 0.0018515586853027344 sec\n",
            "multilayer_perceptron ran in: 0.0019850730895996094 sec\n",
            "multilayer_perceptron ran in: 0.0018665790557861328 sec\n",
            "multilayer_perceptron ran in: 0.0017361640930175781 sec\n",
            "multilayer_perceptron ran in: 0.0018982887268066406 sec\n",
            "multilayer_perceptron ran in: 0.0017628669738769531 sec\n",
            "multilayer_perceptron ran in: 0.0016019344329833984 sec\n",
            "multilayer_perceptron ran in: 0.0017282962799072266 sec\n",
            "multilayer_perceptron ran in: 0.002713441848754883 sec\n",
            "multilayer_perceptron ran in: 0.0017881393432617188 sec\n",
            "multilayer_perceptron ran in: 0.0017707347869873047 sec\n",
            "multilayer_perceptron ran in: 0.0017402172088623047 sec\n",
            "multilayer_perceptron ran in: 0.0022695064544677734 sec\n",
            "multilayer_perceptron ran in: 0.0019080638885498047 sec\n",
            "multilayer_perceptron ran in: 0.001911163330078125 sec\n",
            "multilayer_perceptron ran in: 0.001814126968383789 sec\n",
            "multilayer_perceptron ran in: 0.0017359256744384766 sec\n",
            "multilayer_perceptron ran in: 0.0017621517181396484 sec\n",
            "multilayer_perceptron ran in: 0.004370212554931641 sec\n",
            "multilayer_perceptron ran in: 0.0032355785369873047 sec\n",
            "multilayer_perceptron ran in: 0.0017726421356201172 sec\n",
            "multilayer_perceptron ran in: 0.0026366710662841797 sec\n",
            "multilayer_perceptron ran in: 0.0018863677978515625 sec\n",
            "Epoch: 11 Cost=45365.9062\n",
            "multilayer_perceptron ran in: 0.0018279552459716797 sec\n",
            "multilayer_perceptron ran in: 0.0017948150634765625 sec\n",
            "multilayer_perceptron ran in: 0.002289295196533203 sec\n",
            "multilayer_perceptron ran in: 0.001791238784790039 sec\n",
            "multilayer_perceptron ran in: 0.001912832260131836 sec\n",
            "multilayer_perceptron ran in: 0.0017671585083007812 sec\n",
            "multilayer_perceptron ran in: 0.0019702911376953125 sec\n",
            "multilayer_perceptron ran in: 0.0017781257629394531 sec\n",
            "multilayer_perceptron ran in: 0.002560138702392578 sec\n",
            "multilayer_perceptron ran in: 0.0017559528350830078 sec\n",
            "multilayer_perceptron ran in: 0.0018291473388671875 sec\n",
            "multilayer_perceptron ran in: 0.0017490386962890625 sec\n",
            "multilayer_perceptron ran in: 0.0022330284118652344 sec\n",
            "multilayer_perceptron ran in: 0.00295257568359375 sec\n",
            "multilayer_perceptron ran in: 0.0017976760864257812 sec\n",
            "multilayer_perceptron ran in: 0.001875162124633789 sec\n",
            "multilayer_perceptron ran in: 0.0019237995147705078 sec\n",
            "multilayer_perceptron ran in: 0.0019273757934570312 sec\n",
            "multilayer_perceptron ran in: 0.001851797103881836 sec\n",
            "multilayer_perceptron ran in: 0.001974821090698242 sec\n",
            "multilayer_perceptron ran in: 0.001932382583618164 sec\n",
            "multilayer_perceptron ran in: 0.0018641948699951172 sec\n",
            "multilayer_perceptron ran in: 0.00193023681640625 sec\n",
            "multilayer_perceptron ran in: 0.0017962455749511719 sec\n",
            "multilayer_perceptron ran in: 0.001976490020751953 sec\n",
            "multilayer_perceptron ran in: 0.0018928050994873047 sec\n",
            "multilayer_perceptron ran in: 0.0024933815002441406 sec\n",
            "multilayer_perceptron ran in: 0.0017223358154296875 sec\n",
            "multilayer_perceptron ran in: 0.0022597312927246094 sec\n",
            "multilayer_perceptron ran in: 0.0019054412841796875 sec\n",
            "multilayer_perceptron ran in: 0.0019767284393310547 sec\n",
            "multilayer_perceptron ran in: 0.0018122196197509766 sec\n",
            "multilayer_perceptron ran in: 0.0018224716186523438 sec\n",
            "multilayer_perceptron ran in: 0.0017673969268798828 sec\n",
            "multilayer_perceptron ran in: 0.0018897056579589844 sec\n",
            "multilayer_perceptron ran in: 0.001848459243774414 sec\n",
            "multilayer_perceptron ran in: 0.0022034645080566406 sec\n",
            "multilayer_perceptron ran in: 0.0018658638000488281 sec\n",
            "multilayer_perceptron ran in: 0.0017349720001220703 sec\n",
            "multilayer_perceptron ran in: 0.001848459243774414 sec\n",
            "multilayer_perceptron ran in: 0.0018925666809082031 sec\n",
            "multilayer_perceptron ran in: 0.0017712116241455078 sec\n",
            "multilayer_perceptron ran in: 0.0018014907836914062 sec\n",
            "multilayer_perceptron ran in: 0.001870870590209961 sec\n",
            "multilayer_perceptron ran in: 0.0021584033966064453 sec\n",
            "multilayer_perceptron ran in: 0.0018644332885742188 sec\n",
            "multilayer_perceptron ran in: 0.0018019676208496094 sec\n",
            "multilayer_perceptron ran in: 0.001821279525756836 sec\n",
            "multilayer_perceptron ran in: 0.0021255016326904297 sec\n",
            "multilayer_perceptron ran in: 0.0017161369323730469 sec\n",
            "multilayer_perceptron ran in: 0.0017940998077392578 sec\n",
            "multilayer_perceptron ran in: 0.0020499229431152344 sec\n",
            "multilayer_perceptron ran in: 0.001813650131225586 sec\n",
            "multilayer_perceptron ran in: 0.0017347335815429688 sec\n",
            "multilayer_perceptron ran in: 0.002125263214111328 sec\n",
            "multilayer_perceptron ran in: 0.001851797103881836 sec\n",
            "multilayer_perceptron ran in: 0.0018310546875 sec\n",
            "multilayer_perceptron ran in: 0.0038805007934570312 sec\n",
            "multilayer_perceptron ran in: 0.002033233642578125 sec\n",
            "multilayer_perceptron ran in: 0.0017752647399902344 sec\n",
            "multilayer_perceptron ran in: 0.0017104148864746094 sec\n",
            "multilayer_perceptron ran in: 0.0017385482788085938 sec\n",
            "multilayer_perceptron ran in: 0.0018067359924316406 sec\n",
            "multilayer_perceptron ran in: 0.00185394287109375 sec\n",
            "multilayer_perceptron ran in: 0.00188446044921875 sec\n",
            "multilayer_perceptron ran in: 0.0018725395202636719 sec\n",
            "multilayer_perceptron ran in: 0.001982450485229492 sec\n",
            "multilayer_perceptron ran in: 0.0017459392547607422 sec\n",
            "multilayer_perceptron ran in: 0.001714944839477539 sec\n",
            "multilayer_perceptron ran in: 0.0017042160034179688 sec\n",
            "multilayer_perceptron ran in: 0.0019953250885009766 sec\n",
            "multilayer_perceptron ran in: 0.0025081634521484375 sec\n",
            "multilayer_perceptron ran in: 0.0031151771545410156 sec\n",
            "multilayer_perceptron ran in: 0.0022156238555908203 sec\n",
            "multilayer_perceptron ran in: 0.002541065216064453 sec\n",
            "multilayer_perceptron ran in: 0.002773284912109375 sec\n",
            "multilayer_perceptron ran in: 0.0019767284393310547 sec\n",
            "multilayer_perceptron ran in: 0.00237274169921875 sec\n",
            "multilayer_perceptron ran in: 0.001951456069946289 sec\n",
            "multilayer_perceptron ran in: 0.0020728111267089844 sec\n",
            "multilayer_perceptron ran in: 0.0021250247955322266 sec\n",
            "multilayer_perceptron ran in: 0.0025205612182617188 sec\n",
            "multilayer_perceptron ran in: 0.0021440982818603516 sec\n",
            "multilayer_perceptron ran in: 0.002361774444580078 sec\n",
            "multilayer_perceptron ran in: 0.002100229263305664 sec\n",
            "multilayer_perceptron ran in: 0.0021419525146484375 sec\n",
            "multilayer_perceptron ran in: 0.002302408218383789 sec\n",
            "multilayer_perceptron ran in: 0.002042531967163086 sec\n",
            "multilayer_perceptron ran in: 0.002070903778076172 sec\n",
            "multilayer_perceptron ran in: 0.0021431446075439453 sec\n",
            "multilayer_perceptron ran in: 0.0020966529846191406 sec\n",
            "multilayer_perceptron ran in: 0.0023338794708251953 sec\n",
            "multilayer_perceptron ran in: 0.0025920867919921875 sec\n",
            "multilayer_perceptron ran in: 0.002454519271850586 sec\n",
            "multilayer_perceptron ran in: 0.002180814743041992 sec\n",
            "multilayer_perceptron ran in: 0.002305746078491211 sec\n",
            "multilayer_perceptron ran in: 0.0024955272674560547 sec\n",
            "multilayer_perceptron ran in: 0.002619504928588867 sec\n",
            "multilayer_perceptron ran in: 0.0022890567779541016 sec\n",
            "multilayer_perceptron ran in: 0.002431631088256836 sec\n",
            "multilayer_perceptron ran in: 0.0027036666870117188 sec\n",
            "multilayer_perceptron ran in: 0.002719879150390625 sec\n",
            "multilayer_perceptron ran in: 0.005428791046142578 sec\n",
            "multilayer_perceptron ran in: 0.002338886260986328 sec\n",
            "multilayer_perceptron ran in: 0.002292156219482422 sec\n",
            "multilayer_perceptron ran in: 0.0027534961700439453 sec\n",
            "multilayer_perceptron ran in: 0.0021674633026123047 sec\n",
            "multilayer_perceptron ran in: 0.0022346973419189453 sec\n",
            "multilayer_perceptron ran in: 0.005278587341308594 sec\n",
            "multilayer_perceptron ran in: 0.002274751663208008 sec\n",
            "multilayer_perceptron ran in: 0.002390146255493164 sec\n",
            "multilayer_perceptron ran in: 0.0031630992889404297 sec\n",
            "multilayer_perceptron ran in: 0.0024518966674804688 sec\n",
            "multilayer_perceptron ran in: 0.0022797584533691406 sec\n",
            "multilayer_perceptron ran in: 0.002281665802001953 sec\n",
            "multilayer_perceptron ran in: 0.002380847930908203 sec\n",
            "multilayer_perceptron ran in: 0.002564668655395508 sec\n",
            "multilayer_perceptron ran in: 0.0022537708282470703 sec\n",
            "multilayer_perceptron ran in: 0.0023415088653564453 sec\n",
            "multilayer_perceptron ran in: 0.0023679733276367188 sec\n",
            "multilayer_perceptron ran in: 0.002496957778930664 sec\n",
            "multilayer_perceptron ran in: 0.006314992904663086 sec\n",
            "multilayer_perceptron ran in: 0.003841876983642578 sec\n",
            "multilayer_perceptron ran in: 0.0028023719787597656 sec\n",
            "multilayer_perceptron ran in: 0.0018072128295898438 sec\n",
            "multilayer_perceptron ran in: 0.0018067359924316406 sec\n",
            "multilayer_perceptron ran in: 0.0025746822357177734 sec\n",
            "multilayer_perceptron ran in: 0.0018944740295410156 sec\n",
            "multilayer_perceptron ran in: 0.0022058486938476562 sec\n",
            "multilayer_perceptron ran in: 0.0018281936645507812 sec\n",
            "multilayer_perceptron ran in: 0.001931905746459961 sec\n",
            "multilayer_perceptron ran in: 0.001971721649169922 sec\n",
            "multilayer_perceptron ran in: 0.0017979145050048828 sec\n",
            "multilayer_perceptron ran in: 0.0018203258514404297 sec\n",
            "multilayer_perceptron ran in: 0.002830982208251953 sec\n",
            "multilayer_perceptron ran in: 0.0019230842590332031 sec\n",
            "multilayer_perceptron ran in: 0.002909421920776367 sec\n",
            "multilayer_perceptron ran in: 0.00179290771484375 sec\n",
            "multilayer_perceptron ran in: 0.0018987655639648438 sec\n",
            "multilayer_perceptron ran in: 0.002324819564819336 sec\n",
            "multilayer_perceptron ran in: 0.002138853073120117 sec\n",
            "multilayer_perceptron ran in: 0.0022983551025390625 sec\n",
            "multilayer_perceptron ran in: 0.0017654895782470703 sec\n",
            "multilayer_perceptron ran in: 0.0021293163299560547 sec\n",
            "multilayer_perceptron ran in: 0.0018086433410644531 sec\n",
            "multilayer_perceptron ran in: 0.0018951892852783203 sec\n",
            "multilayer_perceptron ran in: 0.0018575191497802734 sec\n",
            "multilayer_perceptron ran in: 0.0021469593048095703 sec\n",
            "multilayer_perceptron ran in: 0.008778095245361328 sec\n",
            "multilayer_perceptron ran in: 0.0022525787353515625 sec\n",
            "multilayer_perceptron ran in: 0.002195119857788086 sec\n",
            "multilayer_perceptron ran in: 0.0018377304077148438 sec\n",
            "multilayer_perceptron ran in: 0.0018336772918701172 sec\n",
            "multilayer_perceptron ran in: 0.0033071041107177734 sec\n",
            "multilayer_perceptron ran in: 0.00189208984375 sec\n",
            "multilayer_perceptron ran in: 0.0017688274383544922 sec\n",
            "multilayer_perceptron ran in: 0.0018172264099121094 sec\n",
            "multilayer_perceptron ran in: 0.001809835433959961 sec\n",
            "multilayer_perceptron ran in: 0.002439737319946289 sec\n",
            "multilayer_perceptron ran in: 0.0019369125366210938 sec\n",
            "multilayer_perceptron ran in: 0.0018470287322998047 sec\n",
            "multilayer_perceptron ran in: 0.0019450187683105469 sec\n",
            "multilayer_perceptron ran in: 0.0018296241760253906 sec\n",
            "multilayer_perceptron ran in: 0.003422975540161133 sec\n",
            "multilayer_perceptron ran in: 0.0017895698547363281 sec\n",
            "multilayer_perceptron ran in: 0.0018012523651123047 sec\n",
            "multilayer_perceptron ran in: 0.0017895698547363281 sec\n",
            "multilayer_perceptron ran in: 0.0019059181213378906 sec\n",
            "multilayer_perceptron ran in: 0.0023577213287353516 sec\n",
            "multilayer_perceptron ran in: 0.001967191696166992 sec\n",
            "multilayer_perceptron ran in: 0.002474069595336914 sec\n",
            "multilayer_perceptron ran in: 0.0018916130065917969 sec\n",
            "multilayer_perceptron ran in: 0.0018978118896484375 sec\n",
            "multilayer_perceptron ran in: 0.0019164085388183594 sec\n",
            "multilayer_perceptron ran in: 0.0019326210021972656 sec\n",
            "multilayer_perceptron ran in: 0.0021436214447021484 sec\n",
            "multilayer_perceptron ran in: 0.0022470951080322266 sec\n",
            "multilayer_perceptron ran in: 0.002216339111328125 sec\n",
            "multilayer_perceptron ran in: 0.0017933845520019531 sec\n",
            "multilayer_perceptron ran in: 0.0018317699432373047 sec\n",
            "multilayer_perceptron ran in: 0.0020751953125 sec\n",
            "multilayer_perceptron ran in: 0.0017457008361816406 sec\n",
            "multilayer_perceptron ran in: 0.0018270015716552734 sec\n",
            "multilayer_perceptron ran in: 0.001739501953125 sec\n",
            "multilayer_perceptron ran in: 0.0018126964569091797 sec\n",
            "multilayer_perceptron ran in: 0.0017733573913574219 sec\n",
            "multilayer_perceptron ran in: 0.0019686222076416016 sec\n",
            "multilayer_perceptron ran in: 0.0017616748809814453 sec\n",
            "multilayer_perceptron ran in: 0.003202676773071289 sec\n",
            "multilayer_perceptron ran in: 0.0019445419311523438 sec\n",
            "multilayer_perceptron ran in: 0.0017719268798828125 sec\n",
            "multilayer_perceptron ran in: 0.0016450881958007812 sec\n",
            "multilayer_perceptron ran in: 0.001703023910522461 sec\n",
            "multilayer_perceptron ran in: 0.0033233165740966797 sec\n",
            "multilayer_perceptron ran in: 0.0018129348754882812 sec\n",
            "multilayer_perceptron ran in: 0.0024824142456054688 sec\n",
            "multilayer_perceptron ran in: 0.0022945404052734375 sec\n",
            "multilayer_perceptron ran in: 0.0030586719512939453 sec\n",
            "multilayer_perceptron ran in: 0.0031812191009521484 sec\n",
            "multilayer_perceptron ran in: 0.0017826557159423828 sec\n",
            "multilayer_perceptron ran in: 0.0017578601837158203 sec\n",
            "multilayer_perceptron ran in: 0.001749277114868164 sec\n",
            "multilayer_perceptron ran in: 0.001978635787963867 sec\n",
            "multilayer_perceptron ran in: 0.0018754005432128906 sec\n",
            "multilayer_perceptron ran in: 0.0017733573913574219 sec\n",
            "multilayer_perceptron ran in: 0.0017123222351074219 sec\n",
            "multilayer_perceptron ran in: 0.0017850399017333984 sec\n",
            "multilayer_perceptron ran in: 0.001861572265625 sec\n",
            "multilayer_perceptron ran in: 0.0018243789672851562 sec\n",
            "multilayer_perceptron ran in: 0.0023140907287597656 sec\n",
            "multilayer_perceptron ran in: 0.0018627643585205078 sec\n",
            "multilayer_perceptron ran in: 0.0018260478973388672 sec\n",
            "multilayer_perceptron ran in: 0.001771688461303711 sec\n",
            "multilayer_perceptron ran in: 0.0026209354400634766 sec\n",
            "multilayer_perceptron ran in: 0.0018744468688964844 sec\n",
            "multilayer_perceptron ran in: 0.0020105838775634766 sec\n",
            "multilayer_perceptron ran in: 0.0017385482788085938 sec\n",
            "multilayer_perceptron ran in: 0.0018897056579589844 sec\n",
            "multilayer_perceptron ran in: 0.007067203521728516 sec\n",
            "multilayer_perceptron ran in: 0.0018322467803955078 sec\n",
            "multilayer_perceptron ran in: 0.0018792152404785156 sec\n",
            "multilayer_perceptron ran in: 0.0017712116241455078 sec\n",
            "multilayer_perceptron ran in: 0.0018382072448730469 sec\n",
            "multilayer_perceptron ran in: 0.0017774105072021484 sec\n",
            "multilayer_perceptron ran in: 0.0018687248229980469 sec\n",
            "multilayer_perceptron ran in: 0.001958131790161133 sec\n",
            "multilayer_perceptron ran in: 0.001790761947631836 sec\n",
            "multilayer_perceptron ran in: 0.0017671585083007812 sec\n",
            "multilayer_perceptron ran in: 0.0027494430541992188 sec\n",
            "multilayer_perceptron ran in: 0.001856088638305664 sec\n",
            "multilayer_perceptron ran in: 0.0019176006317138672 sec\n",
            "multilayer_perceptron ran in: 0.0018732547760009766 sec\n",
            "multilayer_perceptron ran in: 0.0017757415771484375 sec\n",
            "multilayer_perceptron ran in: 0.002658367156982422 sec\n",
            "multilayer_perceptron ran in: 0.0017697811126708984 sec\n",
            "multilayer_perceptron ran in: 0.001848459243774414 sec\n",
            "multilayer_perceptron ran in: 0.002405881881713867 sec\n",
            "multilayer_perceptron ran in: 0.0018248558044433594 sec\n",
            "multilayer_perceptron ran in: 0.0034623146057128906 sec\n",
            "multilayer_perceptron ran in: 0.0021736621856689453 sec\n",
            "Epoch: 12 Cost=54390.8320\n",
            "multilayer_perceptron ran in: 0.0017135143280029297 sec\n",
            "multilayer_perceptron ran in: 0.0017940998077392578 sec\n",
            "multilayer_perceptron ran in: 0.0019059181213378906 sec\n",
            "multilayer_perceptron ran in: 0.001992940902709961 sec\n",
            "multilayer_perceptron ran in: 0.002054452896118164 sec\n",
            "multilayer_perceptron ran in: 0.0020308494567871094 sec\n",
            "multilayer_perceptron ran in: 0.002164602279663086 sec\n",
            "multilayer_perceptron ran in: 0.001834869384765625 sec\n",
            "multilayer_perceptron ran in: 0.002526998519897461 sec\n",
            "multilayer_perceptron ran in: 0.0019328594207763672 sec\n",
            "multilayer_perceptron ran in: 0.0018038749694824219 sec\n",
            "multilayer_perceptron ran in: 0.0025141239166259766 sec\n",
            "multilayer_perceptron ran in: 0.001817941665649414 sec\n",
            "multilayer_perceptron ran in: 0.0018322467803955078 sec\n",
            "multilayer_perceptron ran in: 0.0017976760864257812 sec\n",
            "multilayer_perceptron ran in: 0.002423524856567383 sec\n",
            "multilayer_perceptron ran in: 0.0016896724700927734 sec\n",
            "multilayer_perceptron ran in: 0.00222015380859375 sec\n",
            "multilayer_perceptron ran in: 0.0019724369049072266 sec\n",
            "multilayer_perceptron ran in: 0.002035379409790039 sec\n",
            "multilayer_perceptron ran in: 0.0017671585083007812 sec\n",
            "multilayer_perceptron ran in: 0.0018773078918457031 sec\n",
            "multilayer_perceptron ran in: 0.0019061565399169922 sec\n",
            "multilayer_perceptron ran in: 0.0019173622131347656 sec\n",
            "multilayer_perceptron ran in: 0.0017840862274169922 sec\n",
            "multilayer_perceptron ran in: 0.0017457008361816406 sec\n",
            "multilayer_perceptron ran in: 0.0018167495727539062 sec\n",
            "multilayer_perceptron ran in: 0.0019817352294921875 sec\n",
            "multilayer_perceptron ran in: 0.0019011497497558594 sec\n",
            "multilayer_perceptron ran in: 0.0018439292907714844 sec\n",
            "multilayer_perceptron ran in: 0.0018606185913085938 sec\n",
            "multilayer_perceptron ran in: 0.0035142898559570312 sec\n",
            "multilayer_perceptron ran in: 0.0018727779388427734 sec\n",
            "multilayer_perceptron ran in: 0.0019459724426269531 sec\n",
            "multilayer_perceptron ran in: 0.0020096302032470703 sec\n",
            "multilayer_perceptron ran in: 0.0028290748596191406 sec\n",
            "multilayer_perceptron ran in: 0.0028057098388671875 sec\n",
            "multilayer_perceptron ran in: 0.0020051002502441406 sec\n",
            "multilayer_perceptron ran in: 0.001967906951904297 sec\n",
            "multilayer_perceptron ran in: 0.0018467903137207031 sec\n",
            "multilayer_perceptron ran in: 0.0017728805541992188 sec\n",
            "multilayer_perceptron ran in: 0.0023505687713623047 sec\n",
            "multilayer_perceptron ran in: 0.001935720443725586 sec\n",
            "multilayer_perceptron ran in: 0.0018317699432373047 sec\n",
            "multilayer_perceptron ran in: 0.002908945083618164 sec\n",
            "multilayer_perceptron ran in: 0.0018324851989746094 sec\n",
            "multilayer_perceptron ran in: 0.0019719600677490234 sec\n",
            "multilayer_perceptron ran in: 0.0019137859344482422 sec\n",
            "multilayer_perceptron ran in: 0.0018463134765625 sec\n",
            "multilayer_perceptron ran in: 0.0018610954284667969 sec\n",
            "multilayer_perceptron ran in: 0.0018625259399414062 sec\n",
            "multilayer_perceptron ran in: 0.006549835205078125 sec\n",
            "multilayer_perceptron ran in: 0.002887725830078125 sec\n",
            "multilayer_perceptron ran in: 0.0025148391723632812 sec\n",
            "multilayer_perceptron ran in: 0.001863718032836914 sec\n",
            "multilayer_perceptron ran in: 0.0018148422241210938 sec\n",
            "multilayer_perceptron ran in: 0.0018379688262939453 sec\n",
            "multilayer_perceptron ran in: 0.0017676353454589844 sec\n",
            "multilayer_perceptron ran in: 0.0018336772918701172 sec\n",
            "multilayer_perceptron ran in: 0.002412557601928711 sec\n",
            "multilayer_perceptron ran in: 0.0018553733825683594 sec\n",
            "multilayer_perceptron ran in: 0.0021233558654785156 sec\n",
            "multilayer_perceptron ran in: 0.0017931461334228516 sec\n",
            "multilayer_perceptron ran in: 0.002256631851196289 sec\n",
            "multilayer_perceptron ran in: 0.0018186569213867188 sec\n",
            "multilayer_perceptron ran in: 0.0027968883514404297 sec\n",
            "multilayer_perceptron ran in: 0.0017387866973876953 sec\n",
            "multilayer_perceptron ran in: 0.0017681121826171875 sec\n",
            "multilayer_perceptron ran in: 0.0017666816711425781 sec\n",
            "multilayer_perceptron ran in: 0.0017838478088378906 sec\n",
            "multilayer_perceptron ran in: 0.001650094985961914 sec\n",
            "multilayer_perceptron ran in: 0.0025243759155273438 sec\n",
            "multilayer_perceptron ran in: 0.0017447471618652344 sec\n",
            "multilayer_perceptron ran in: 0.0017354488372802734 sec\n",
            "multilayer_perceptron ran in: 0.0017952919006347656 sec\n",
            "multilayer_perceptron ran in: 0.0018241405487060547 sec\n",
            "multilayer_perceptron ran in: 0.0023839473724365234 sec\n",
            "multilayer_perceptron ran in: 0.0016727447509765625 sec\n",
            "multilayer_perceptron ran in: 0.0017726421356201172 sec\n",
            "multilayer_perceptron ran in: 0.0022661685943603516 sec\n",
            "multilayer_perceptron ran in: 0.002000093460083008 sec\n",
            "multilayer_perceptron ran in: 0.0019965171813964844 sec\n",
            "multilayer_perceptron ran in: 0.001791238784790039 sec\n",
            "multilayer_perceptron ran in: 0.004393577575683594 sec\n",
            "multilayer_perceptron ran in: 0.0034995079040527344 sec\n",
            "multilayer_perceptron ran in: 0.0018110275268554688 sec\n",
            "multilayer_perceptron ran in: 0.0022954940795898438 sec\n",
            "multilayer_perceptron ran in: 0.0018839836120605469 sec\n",
            "multilayer_perceptron ran in: 0.002835988998413086 sec\n",
            "multilayer_perceptron ran in: 0.0017499923706054688 sec\n",
            "multilayer_perceptron ran in: 0.0018744468688964844 sec\n",
            "multilayer_perceptron ran in: 0.0023708343505859375 sec\n",
            "multilayer_perceptron ran in: 0.001985311508178711 sec\n",
            "multilayer_perceptron ran in: 0.0017566680908203125 sec\n",
            "multilayer_perceptron ran in: 0.0021843910217285156 sec\n",
            "multilayer_perceptron ran in: 0.001857757568359375 sec\n",
            "multilayer_perceptron ran in: 0.0017654895782470703 sec\n",
            "multilayer_perceptron ran in: 0.0018796920776367188 sec\n",
            "multilayer_perceptron ran in: 0.002353668212890625 sec\n",
            "multilayer_perceptron ran in: 0.0019156932830810547 sec\n",
            "multilayer_perceptron ran in: 0.001783132553100586 sec\n",
            "multilayer_perceptron ran in: 0.0017268657684326172 sec\n",
            "multilayer_perceptron ran in: 0.0018830299377441406 sec\n",
            "multilayer_perceptron ran in: 0.0031654834747314453 sec\n",
            "multilayer_perceptron ran in: 0.0030739307403564453 sec\n",
            "multilayer_perceptron ran in: 0.0024166107177734375 sec\n",
            "multilayer_perceptron ran in: 0.002862215042114258 sec\n",
            "multilayer_perceptron ran in: 0.0033130645751953125 sec\n",
            "multilayer_perceptron ran in: 0.0030896663665771484 sec\n",
            "multilayer_perceptron ran in: 0.002526998519897461 sec\n",
            "multilayer_perceptron ran in: 0.0026242733001708984 sec\n",
            "multilayer_perceptron ran in: 0.0022988319396972656 sec\n",
            "multilayer_perceptron ran in: 0.002095460891723633 sec\n",
            "multilayer_perceptron ran in: 0.002046823501586914 sec\n",
            "multilayer_perceptron ran in: 0.001949310302734375 sec\n",
            "multilayer_perceptron ran in: 0.0023686885833740234 sec\n",
            "multilayer_perceptron ran in: 0.002034425735473633 sec\n",
            "multilayer_perceptron ran in: 0.002172231674194336 sec\n",
            "multilayer_perceptron ran in: 0.0019075870513916016 sec\n",
            "multilayer_perceptron ran in: 0.002493619918823242 sec\n",
            "multilayer_perceptron ran in: 0.002424478530883789 sec\n",
            "multilayer_perceptron ran in: 0.0025911331176757812 sec\n",
            "multilayer_perceptron ran in: 0.002529144287109375 sec\n",
            "multilayer_perceptron ran in: 0.0020771026611328125 sec\n",
            "multilayer_perceptron ran in: 0.0020782947540283203 sec\n",
            "multilayer_perceptron ran in: 0.0027141571044921875 sec\n",
            "multilayer_perceptron ran in: 0.002224445343017578 sec\n",
            "multilayer_perceptron ran in: 0.0019953250885009766 sec\n",
            "multilayer_perceptron ran in: 0.003077983856201172 sec\n",
            "multilayer_perceptron ran in: 0.0024771690368652344 sec\n",
            "multilayer_perceptron ran in: 0.0027098655700683594 sec\n",
            "multilayer_perceptron ran in: 0.0027458667755126953 sec\n",
            "multilayer_perceptron ran in: 0.004876136779785156 sec\n",
            "multilayer_perceptron ran in: 0.002309560775756836 sec\n",
            "multilayer_perceptron ran in: 0.003026247024536133 sec\n",
            "multilayer_perceptron ran in: 0.0024056434631347656 sec\n",
            "multilayer_perceptron ran in: 0.0026869773864746094 sec\n",
            "multilayer_perceptron ran in: 0.0027396678924560547 sec\n",
            "multilayer_perceptron ran in: 0.002363443374633789 sec\n",
            "multilayer_perceptron ran in: 0.007944345474243164 sec\n",
            "multilayer_perceptron ran in: 0.002262115478515625 sec\n",
            "multilayer_perceptron ran in: 0.0025305747985839844 sec\n",
            "multilayer_perceptron ran in: 0.002576112747192383 sec\n",
            "multilayer_perceptron ran in: 0.0022995471954345703 sec\n",
            "multilayer_perceptron ran in: 0.0032644271850585938 sec\n",
            "multilayer_perceptron ran in: 0.0030150413513183594 sec\n",
            "multilayer_perceptron ran in: 0.002665996551513672 sec\n",
            "multilayer_perceptron ran in: 0.002408742904663086 sec\n",
            "multilayer_perceptron ran in: 0.0025482177734375 sec\n",
            "multilayer_perceptron ran in: 0.002660512924194336 sec\n",
            "multilayer_perceptron ran in: 0.001922607421875 sec\n",
            "multilayer_perceptron ran in: 0.0018792152404785156 sec\n",
            "multilayer_perceptron ran in: 0.001912832260131836 sec\n",
            "multilayer_perceptron ran in: 0.0018811225891113281 sec\n",
            "multilayer_perceptron ran in: 0.0019447803497314453 sec\n",
            "multilayer_perceptron ran in: 0.003875255584716797 sec\n",
            "multilayer_perceptron ran in: 0.0018582344055175781 sec\n",
            "multilayer_perceptron ran in: 0.0018155574798583984 sec\n",
            "multilayer_perceptron ran in: 0.0017223358154296875 sec\n",
            "multilayer_perceptron ran in: 0.0019707679748535156 sec\n",
            "multilayer_perceptron ran in: 0.0018205642700195312 sec\n",
            "multilayer_perceptron ran in: 0.001926422119140625 sec\n",
            "multilayer_perceptron ran in: 0.0024843215942382812 sec\n",
            "multilayer_perceptron ran in: 0.0022716522216796875 sec\n",
            "multilayer_perceptron ran in: 0.0017447471618652344 sec\n",
            "multilayer_perceptron ran in: 0.002153635025024414 sec\n",
            "multilayer_perceptron ran in: 0.0018584728240966797 sec\n",
            "multilayer_perceptron ran in: 0.0022068023681640625 sec\n",
            "multilayer_perceptron ran in: 0.001790761947631836 sec\n",
            "multilayer_perceptron ran in: 0.001994609832763672 sec\n",
            "multilayer_perceptron ran in: 0.0019114017486572266 sec\n",
            "multilayer_perceptron ran in: 0.0019664764404296875 sec\n",
            "multilayer_perceptron ran in: 0.001737833023071289 sec\n",
            "multilayer_perceptron ran in: 0.001729726791381836 sec\n",
            "multilayer_perceptron ran in: 0.0018100738525390625 sec\n",
            "multilayer_perceptron ran in: 0.0021750926971435547 sec\n",
            "multilayer_perceptron ran in: 0.0017979145050048828 sec\n",
            "multilayer_perceptron ran in: 0.003023386001586914 sec\n",
            "multilayer_perceptron ran in: 0.001996755599975586 sec\n",
            "multilayer_perceptron ran in: 0.0018687248229980469 sec\n",
            "multilayer_perceptron ran in: 0.00521540641784668 sec\n",
            "multilayer_perceptron ran in: 0.0018222332000732422 sec\n",
            "multilayer_perceptron ran in: 0.002262115478515625 sec\n",
            "multilayer_perceptron ran in: 0.00179290771484375 sec\n",
            "multilayer_perceptron ran in: 0.001924276351928711 sec\n",
            "multilayer_perceptron ran in: 0.0035288333892822266 sec\n",
            "multilayer_perceptron ran in: 0.0017242431640625 sec\n",
            "multilayer_perceptron ran in: 0.0017981529235839844 sec\n",
            "multilayer_perceptron ran in: 0.002076864242553711 sec\n",
            "multilayer_perceptron ran in: 0.0017573833465576172 sec\n",
            "multilayer_perceptron ran in: 0.0018537044525146484 sec\n",
            "multilayer_perceptron ran in: 0.0019185543060302734 sec\n",
            "multilayer_perceptron ran in: 0.0017609596252441406 sec\n",
            "multilayer_perceptron ran in: 0.001890420913696289 sec\n",
            "multilayer_perceptron ran in: 0.003164052963256836 sec\n",
            "multilayer_perceptron ran in: 0.0035715103149414062 sec\n",
            "multilayer_perceptron ran in: 0.0022003650665283203 sec\n",
            "multilayer_perceptron ran in: 0.0017771720886230469 sec\n",
            "multilayer_perceptron ran in: 0.0026543140411376953 sec\n",
            "multilayer_perceptron ran in: 0.0026717185974121094 sec\n",
            "multilayer_perceptron ran in: 0.002094268798828125 sec\n",
            "multilayer_perceptron ran in: 0.0018002986907958984 sec\n",
            "multilayer_perceptron ran in: 0.0017826557159423828 sec\n",
            "multilayer_perceptron ran in: 0.0019352436065673828 sec\n",
            "multilayer_perceptron ran in: 0.0018932819366455078 sec\n",
            "multilayer_perceptron ran in: 0.0033185482025146484 sec\n",
            "multilayer_perceptron ran in: 0.0017969608306884766 sec\n",
            "multilayer_perceptron ran in: 0.0020034313201904297 sec\n",
            "multilayer_perceptron ran in: 0.0029268264770507812 sec\n",
            "multilayer_perceptron ran in: 0.00177764892578125 sec\n",
            "multilayer_perceptron ran in: 0.002223491668701172 sec\n",
            "multilayer_perceptron ran in: 0.0018384456634521484 sec\n",
            "multilayer_perceptron ran in: 0.0024077892303466797 sec\n",
            "multilayer_perceptron ran in: 0.001844644546508789 sec\n",
            "multilayer_perceptron ran in: 0.001984119415283203 sec\n",
            "multilayer_perceptron ran in: 0.0027375221252441406 sec\n",
            "multilayer_perceptron ran in: 0.0019927024841308594 sec\n",
            "multilayer_perceptron ran in: 0.0019559860229492188 sec\n",
            "multilayer_perceptron ran in: 0.0017290115356445312 sec\n",
            "multilayer_perceptron ran in: 0.002882242202758789 sec\n",
            "multilayer_perceptron ran in: 0.006152629852294922 sec\n",
            "multilayer_perceptron ran in: 0.0018477439880371094 sec\n",
            "multilayer_perceptron ran in: 0.0018351078033447266 sec\n",
            "multilayer_perceptron ran in: 0.001814126968383789 sec\n",
            "multilayer_perceptron ran in: 0.001768350601196289 sec\n",
            "multilayer_perceptron ran in: 0.0018672943115234375 sec\n",
            "multilayer_perceptron ran in: 0.002755403518676758 sec\n",
            "multilayer_perceptron ran in: 0.0017702579498291016 sec\n",
            "multilayer_perceptron ran in: 0.0019271373748779297 sec\n",
            "multilayer_perceptron ran in: 0.0017685890197753906 sec\n",
            "multilayer_perceptron ran in: 0.001749277114868164 sec\n",
            "multilayer_perceptron ran in: 0.001985311508178711 sec\n",
            "multilayer_perceptron ran in: 0.0019021034240722656 sec\n",
            "multilayer_perceptron ran in: 0.0017881393432617188 sec\n",
            "multilayer_perceptron ran in: 0.0020716190338134766 sec\n",
            "multilayer_perceptron ran in: 0.0019683837890625 sec\n",
            "multilayer_perceptron ran in: 0.0018243789672851562 sec\n",
            "multilayer_perceptron ran in: 0.0017480850219726562 sec\n",
            "multilayer_perceptron ran in: 0.002000093460083008 sec\n",
            "multilayer_perceptron ran in: 0.003302335739135742 sec\n",
            "Epoch: 13 Cost=69795.6953\n",
            "multilayer_perceptron ran in: 0.0018126964569091797 sec\n",
            "multilayer_perceptron ran in: 0.0018486976623535156 sec\n",
            "multilayer_perceptron ran in: 0.0016696453094482422 sec\n",
            "multilayer_perceptron ran in: 0.0019085407257080078 sec\n",
            "multilayer_perceptron ran in: 0.0019145011901855469 sec\n",
            "multilayer_perceptron ran in: 0.0019135475158691406 sec\n",
            "multilayer_perceptron ran in: 0.0019383430480957031 sec\n",
            "multilayer_perceptron ran in: 0.002488851547241211 sec\n",
            "multilayer_perceptron ran in: 0.0018074512481689453 sec\n",
            "multilayer_perceptron ran in: 0.0019779205322265625 sec\n",
            "multilayer_perceptron ran in: 0.0021257400512695312 sec\n",
            "multilayer_perceptron ran in: 0.0018553733825683594 sec\n",
            "multilayer_perceptron ran in: 0.0019614696502685547 sec\n",
            "multilayer_perceptron ran in: 0.0019521713256835938 sec\n",
            "multilayer_perceptron ran in: 0.0018396377563476562 sec\n",
            "multilayer_perceptron ran in: 0.0024633407592773438 sec\n",
            "multilayer_perceptron ran in: 0.0021500587463378906 sec\n",
            "multilayer_perceptron ran in: 0.001928091049194336 sec\n",
            "multilayer_perceptron ran in: 0.0018880367279052734 sec\n",
            "multilayer_perceptron ran in: 0.0019202232360839844 sec\n",
            "multilayer_perceptron ran in: 0.0017600059509277344 sec\n",
            "multilayer_perceptron ran in: 0.0018723011016845703 sec\n",
            "multilayer_perceptron ran in: 0.0018601417541503906 sec\n",
            "multilayer_perceptron ran in: 0.002069711685180664 sec\n",
            "multilayer_perceptron ran in: 0.0018393993377685547 sec\n",
            "multilayer_perceptron ran in: 0.003723621368408203 sec\n",
            "multilayer_perceptron ran in: 0.0024738311767578125 sec\n",
            "multilayer_perceptron ran in: 0.001954317092895508 sec\n",
            "multilayer_perceptron ran in: 0.002105712890625 sec\n",
            "multilayer_perceptron ran in: 0.0021860599517822266 sec\n",
            "multilayer_perceptron ran in: 0.0020737648010253906 sec\n",
            "multilayer_perceptron ran in: 0.0021796226501464844 sec\n",
            "multilayer_perceptron ran in: 0.0021440982818603516 sec\n",
            "multilayer_perceptron ran in: 0.002064943313598633 sec\n",
            "multilayer_perceptron ran in: 0.0019321441650390625 sec\n",
            "multilayer_perceptron ran in: 0.0018401145935058594 sec\n",
            "multilayer_perceptron ran in: 0.0018258094787597656 sec\n",
            "multilayer_perceptron ran in: 0.0018634796142578125 sec\n",
            "multilayer_perceptron ran in: 0.0023670196533203125 sec\n",
            "multilayer_perceptron ran in: 0.0018115043640136719 sec\n",
            "multilayer_perceptron ran in: 0.0018362998962402344 sec\n",
            "multilayer_perceptron ran in: 0.0017995834350585938 sec\n",
            "multilayer_perceptron ran in: 0.0019428730010986328 sec\n",
            "multilayer_perceptron ran in: 0.0018312931060791016 sec\n",
            "multilayer_perceptron ran in: 0.002099275588989258 sec\n",
            "multilayer_perceptron ran in: 0.0040264129638671875 sec\n",
            "multilayer_perceptron ran in: 0.00431370735168457 sec\n",
            "multilayer_perceptron ran in: 0.0032243728637695312 sec\n",
            "multilayer_perceptron ran in: 0.0019450187683105469 sec\n",
            "multilayer_perceptron ran in: 0.0019605159759521484 sec\n",
            "multilayer_perceptron ran in: 0.002016305923461914 sec\n",
            "multilayer_perceptron ran in: 0.0018362998962402344 sec\n",
            "multilayer_perceptron ran in: 0.001964092254638672 sec\n",
            "multilayer_perceptron ran in: 0.0023889541625976562 sec\n",
            "multilayer_perceptron ran in: 0.0021505355834960938 sec\n",
            "multilayer_perceptron ran in: 0.0019762516021728516 sec\n",
            "multilayer_perceptron ran in: 0.0020627975463867188 sec\n",
            "multilayer_perceptron ran in: 0.0027666091918945312 sec\n",
            "multilayer_perceptron ran in: 0.002796649932861328 sec\n",
            "multilayer_perceptron ran in: 0.0017940998077392578 sec\n",
            "multilayer_perceptron ran in: 0.0037565231323242188 sec\n",
            "multilayer_perceptron ran in: 0.0020933151245117188 sec\n",
            "multilayer_perceptron ran in: 0.001888275146484375 sec\n",
            "multilayer_perceptron ran in: 0.0018634796142578125 sec\n",
            "multilayer_perceptron ran in: 0.0017583370208740234 sec\n",
            "multilayer_perceptron ran in: 0.0017366409301757812 sec\n",
            "multilayer_perceptron ran in: 0.0017213821411132812 sec\n",
            "multilayer_perceptron ran in: 0.0017409324645996094 sec\n",
            "multilayer_perceptron ran in: 0.001767873764038086 sec\n",
            "multilayer_perceptron ran in: 0.0017998218536376953 sec\n",
            "multilayer_perceptron ran in: 0.0018639564514160156 sec\n",
            "multilayer_perceptron ran in: 0.0018193721771240234 sec\n",
            "multilayer_perceptron ran in: 0.002065896987915039 sec\n",
            "multilayer_perceptron ran in: 0.0018172264099121094 sec\n",
            "multilayer_perceptron ran in: 0.0019783973693847656 sec\n",
            "multilayer_perceptron ran in: 0.001873016357421875 sec\n",
            "multilayer_perceptron ran in: 0.0018413066864013672 sec\n",
            "multilayer_perceptron ran in: 0.0017223358154296875 sec\n",
            "multilayer_perceptron ran in: 0.0019199848175048828 sec\n",
            "multilayer_perceptron ran in: 0.0017461776733398438 sec\n",
            "multilayer_perceptron ran in: 0.0018663406372070312 sec\n",
            "multilayer_perceptron ran in: 0.001878976821899414 sec\n",
            "multilayer_perceptron ran in: 0.001794576644897461 sec\n",
            "multilayer_perceptron ran in: 0.0023298263549804688 sec\n",
            "multilayer_perceptron ran in: 0.0017704963684082031 sec\n",
            "multilayer_perceptron ran in: 0.0017535686492919922 sec\n",
            "multilayer_perceptron ran in: 0.001832723617553711 sec\n",
            "multilayer_perceptron ran in: 0.0018002986907958984 sec\n",
            "multilayer_perceptron ran in: 0.0019104480743408203 sec\n",
            "multilayer_perceptron ran in: 0.0018687248229980469 sec\n",
            "multilayer_perceptron ran in: 0.004302263259887695 sec\n",
            "multilayer_perceptron ran in: 0.0018191337585449219 sec\n",
            "multilayer_perceptron ran in: 0.0018422603607177734 sec\n",
            "multilayer_perceptron ran in: 0.002084016799926758 sec\n",
            "multilayer_perceptron ran in: 0.002962827682495117 sec\n",
            "multilayer_perceptron ran in: 0.0018138885498046875 sec\n",
            "multilayer_perceptron ran in: 0.002025127410888672 sec\n",
            "multilayer_perceptron ran in: 0.0018374919891357422 sec\n",
            "multilayer_perceptron ran in: 0.0018606185913085938 sec\n",
            "multilayer_perceptron ran in: 0.003243684768676758 sec\n",
            "multilayer_perceptron ran in: 0.0018684864044189453 sec\n",
            "multilayer_perceptron ran in: 0.002476930618286133 sec\n",
            "multilayer_perceptron ran in: 0.001955747604370117 sec\n",
            "multilayer_perceptron ran in: 0.0018453598022460938 sec\n",
            "multilayer_perceptron ran in: 0.00180816650390625 sec\n",
            "multilayer_perceptron ran in: 0.0017554759979248047 sec\n",
            "multilayer_perceptron ran in: 0.004032611846923828 sec\n",
            "multilayer_perceptron ran in: 0.001768350601196289 sec\n",
            "multilayer_perceptron ran in: 0.0019826889038085938 sec\n",
            "multilayer_perceptron ran in: 0.0019507408142089844 sec\n",
            "multilayer_perceptron ran in: 0.0020051002502441406 sec\n",
            "multilayer_perceptron ran in: 0.0018601417541503906 sec\n",
            "multilayer_perceptron ran in: 0.0018277168273925781 sec\n",
            "multilayer_perceptron ran in: 0.0019407272338867188 sec\n",
            "multilayer_perceptron ran in: 0.0019571781158447266 sec\n",
            "multilayer_perceptron ran in: 0.0018718242645263672 sec\n",
            "multilayer_perceptron ran in: 0.001707315444946289 sec\n",
            "multilayer_perceptron ran in: 0.0017278194427490234 sec\n",
            "multilayer_perceptron ran in: 0.0017476081848144531 sec\n",
            "multilayer_perceptron ran in: 0.0017547607421875 sec\n",
            "multilayer_perceptron ran in: 0.0017337799072265625 sec\n",
            "multilayer_perceptron ran in: 0.002869844436645508 sec\n",
            "multilayer_perceptron ran in: 0.0018646717071533203 sec\n",
            "multilayer_perceptron ran in: 0.0018298625946044922 sec\n",
            "multilayer_perceptron ran in: 0.0018897056579589844 sec\n",
            "multilayer_perceptron ran in: 0.0019338130950927734 sec\n",
            "multilayer_perceptron ran in: 0.0019769668579101562 sec\n",
            "multilayer_perceptron ran in: 0.0017397403717041016 sec\n",
            "multilayer_perceptron ran in: 0.0017802715301513672 sec\n",
            "multilayer_perceptron ran in: 0.0027298927307128906 sec\n",
            "multilayer_perceptron ran in: 0.0018045902252197266 sec\n",
            "multilayer_perceptron ran in: 0.005795717239379883 sec\n",
            "multilayer_perceptron ran in: 0.001811981201171875 sec\n",
            "multilayer_perceptron ran in: 0.0017864704132080078 sec\n",
            "multilayer_perceptron ran in: 0.0017337799072265625 sec\n",
            "multilayer_perceptron ran in: 0.0018267631530761719 sec\n",
            "multilayer_perceptron ran in: 0.002535581588745117 sec\n",
            "multilayer_perceptron ran in: 0.002470731735229492 sec\n",
            "multilayer_perceptron ran in: 0.002361774444580078 sec\n",
            "multilayer_perceptron ran in: 0.002294778823852539 sec\n",
            "multilayer_perceptron ran in: 0.002571582794189453 sec\n",
            "multilayer_perceptron ran in: 0.005273580551147461 sec\n",
            "multilayer_perceptron ran in: 0.0025093555450439453 sec\n",
            "multilayer_perceptron ran in: 0.0021219253540039062 sec\n",
            "multilayer_perceptron ran in: 0.0020678043365478516 sec\n",
            "multilayer_perceptron ran in: 0.0020935535430908203 sec\n",
            "multilayer_perceptron ran in: 0.00217437744140625 sec\n",
            "multilayer_perceptron ran in: 0.004198312759399414 sec\n",
            "multilayer_perceptron ran in: 0.004126310348510742 sec\n",
            "multilayer_perceptron ran in: 0.006956815719604492 sec\n",
            "multilayer_perceptron ran in: 0.0021157264709472656 sec\n",
            "multilayer_perceptron ran in: 0.0019991397857666016 sec\n",
            "multilayer_perceptron ran in: 0.002132892608642578 sec\n",
            "multilayer_perceptron ran in: 0.0020265579223632812 sec\n",
            "multilayer_perceptron ran in: 0.00201416015625 sec\n",
            "multilayer_perceptron ran in: 0.002352476119995117 sec\n",
            "multilayer_perceptron ran in: 0.0025157928466796875 sec\n",
            "multilayer_perceptron ran in: 0.00240325927734375 sec\n",
            "multilayer_perceptron ran in: 0.0020759105682373047 sec\n",
            "multilayer_perceptron ran in: 0.0020737648010253906 sec\n",
            "multilayer_perceptron ran in: 0.002399444580078125 sec\n",
            "multilayer_perceptron ran in: 0.0020780563354492188 sec\n",
            "multilayer_perceptron ran in: 0.0019373893737792969 sec\n",
            "multilayer_perceptron ran in: 0.002691030502319336 sec\n",
            "multilayer_perceptron ran in: 0.004126310348510742 sec\n",
            "multilayer_perceptron ran in: 0.002389669418334961 sec\n",
            "multilayer_perceptron ran in: 0.002641439437866211 sec\n",
            "multilayer_perceptron ran in: 0.0026264190673828125 sec\n",
            "multilayer_perceptron ran in: 0.0027484893798828125 sec\n",
            "multilayer_perceptron ran in: 0.0024378299713134766 sec\n",
            "multilayer_perceptron ran in: 0.0023550987243652344 sec\n",
            "multilayer_perceptron ran in: 0.0025205612182617188 sec\n",
            "multilayer_perceptron ran in: 0.0025522708892822266 sec\n",
            "multilayer_perceptron ran in: 0.0024492740631103516 sec\n",
            "multilayer_perceptron ran in: 0.0027008056640625 sec\n",
            "multilayer_perceptron ran in: 0.00702977180480957 sec\n",
            "multilayer_perceptron ran in: 0.002519369125366211 sec\n",
            "multilayer_perceptron ran in: 0.0024242401123046875 sec\n",
            "multilayer_perceptron ran in: 0.008559465408325195 sec\n",
            "multilayer_perceptron ran in: 0.0028600692749023438 sec\n",
            "multilayer_perceptron ran in: 0.002187967300415039 sec\n",
            "multilayer_perceptron ran in: 0.002330780029296875 sec\n",
            "multilayer_perceptron ran in: 0.0024700164794921875 sec\n",
            "multilayer_perceptron ran in: 0.003237009048461914 sec\n",
            "multilayer_perceptron ran in: 0.003355741500854492 sec\n",
            "multilayer_perceptron ran in: 0.0029375553131103516 sec\n",
            "multilayer_perceptron ran in: 0.0026769638061523438 sec\n",
            "multilayer_perceptron ran in: 0.0031566619873046875 sec\n",
            "multilayer_perceptron ran in: 0.0031235218048095703 sec\n",
            "multilayer_perceptron ran in: 0.001772165298461914 sec\n",
            "multilayer_perceptron ran in: 0.0017783641815185547 sec\n",
            "multilayer_perceptron ran in: 0.001680135726928711 sec\n",
            "multilayer_perceptron ran in: 0.0017826557159423828 sec\n",
            "multilayer_perceptron ran in: 0.0018603801727294922 sec\n",
            "multilayer_perceptron ran in: 0.001844167709350586 sec\n",
            "multilayer_perceptron ran in: 0.001825094223022461 sec\n",
            "multilayer_perceptron ran in: 0.001772165298461914 sec\n",
            "multilayer_perceptron ran in: 0.0018227100372314453 sec\n",
            "multilayer_perceptron ran in: 0.0017518997192382812 sec\n",
            "multilayer_perceptron ran in: 0.0019130706787109375 sec\n",
            "multilayer_perceptron ran in: 0.0017709732055664062 sec\n",
            "multilayer_perceptron ran in: 0.003265857696533203 sec\n",
            "multilayer_perceptron ran in: 0.0019044876098632812 sec\n",
            "multilayer_perceptron ran in: 0.0016949176788330078 sec\n",
            "multilayer_perceptron ran in: 0.001903533935546875 sec\n",
            "multilayer_perceptron ran in: 0.0019943714141845703 sec\n",
            "multilayer_perceptron ran in: 0.0017218589782714844 sec\n",
            "multilayer_perceptron ran in: 0.0018868446350097656 sec\n",
            "multilayer_perceptron ran in: 0.0020029544830322266 sec\n",
            "multilayer_perceptron ran in: 0.0017957687377929688 sec\n",
            "multilayer_perceptron ran in: 0.0018415451049804688 sec\n",
            "multilayer_perceptron ran in: 0.001959562301635742 sec\n",
            "multilayer_perceptron ran in: 0.002820730209350586 sec\n",
            "multilayer_perceptron ran in: 0.001955747604370117 sec\n",
            "multilayer_perceptron ran in: 0.0019078254699707031 sec\n",
            "multilayer_perceptron ran in: 0.0019898414611816406 sec\n",
            "multilayer_perceptron ran in: 0.0018982887268066406 sec\n",
            "multilayer_perceptron ran in: 0.0019180774688720703 sec\n",
            "multilayer_perceptron ran in: 0.0017998218536376953 sec\n",
            "multilayer_perceptron ran in: 0.0017821788787841797 sec\n",
            "multilayer_perceptron ran in: 0.0019197463989257812 sec\n",
            "multilayer_perceptron ran in: 0.0018153190612792969 sec\n",
            "multilayer_perceptron ran in: 0.0020825862884521484 sec\n",
            "multilayer_perceptron ran in: 0.0018830299377441406 sec\n",
            "multilayer_perceptron ran in: 0.007043123245239258 sec\n",
            "multilayer_perceptron ran in: 0.006468772888183594 sec\n",
            "multilayer_perceptron ran in: 0.0019817352294921875 sec\n",
            "multilayer_perceptron ran in: 0.0018565654754638672 sec\n",
            "multilayer_perceptron ran in: 0.0027506351470947266 sec\n",
            "multilayer_perceptron ran in: 0.003130197525024414 sec\n",
            "multilayer_perceptron ran in: 0.002141237258911133 sec\n",
            "multilayer_perceptron ran in: 0.0018587112426757812 sec\n",
            "multilayer_perceptron ran in: 0.0017580986022949219 sec\n",
            "multilayer_perceptron ran in: 0.0018033981323242188 sec\n",
            "multilayer_perceptron ran in: 0.002529621124267578 sec\n",
            "multilayer_perceptron ran in: 0.0018362998962402344 sec\n",
            "multilayer_perceptron ran in: 0.002142190933227539 sec\n",
            "multilayer_perceptron ran in: 0.0018162727355957031 sec\n",
            "multilayer_perceptron ran in: 0.001756906509399414 sec\n",
            "multilayer_perceptron ran in: 0.0018541812896728516 sec\n",
            "Epoch: 14 Cost=66400.4453\n",
            "multilayer_perceptron ran in: 0.0018777847290039062 sec\n",
            "multilayer_perceptron ran in: 0.00229644775390625 sec\n",
            "multilayer_perceptron ran in: 0.0018718242645263672 sec\n",
            "multilayer_perceptron ran in: 0.0018286705017089844 sec\n",
            "multilayer_perceptron ran in: 0.0018808841705322266 sec\n",
            "multilayer_perceptron ran in: 0.002093791961669922 sec\n",
            "multilayer_perceptron ran in: 0.0018603801727294922 sec\n",
            "multilayer_perceptron ran in: 0.001804351806640625 sec\n",
            "multilayer_perceptron ran in: 0.0019283294677734375 sec\n",
            "multilayer_perceptron ran in: 0.0018248558044433594 sec\n",
            "multilayer_perceptron ran in: 0.0018153190612792969 sec\n",
            "multilayer_perceptron ran in: 0.0017468929290771484 sec\n",
            "multilayer_perceptron ran in: 0.001842498779296875 sec\n",
            "multilayer_perceptron ran in: 0.0019121170043945312 sec\n",
            "multilayer_perceptron ran in: 0.0019888877868652344 sec\n",
            "multilayer_perceptron ran in: 0.0023272037506103516 sec\n",
            "multilayer_perceptron ran in: 0.003118753433227539 sec\n",
            "multilayer_perceptron ran in: 0.0018308162689208984 sec\n",
            "multilayer_perceptron ran in: 0.0018138885498046875 sec\n",
            "multilayer_perceptron ran in: 0.002181529998779297 sec\n",
            "multilayer_perceptron ran in: 0.0019185543060302734 sec\n",
            "multilayer_perceptron ran in: 0.0018758773803710938 sec\n",
            "multilayer_perceptron ran in: 0.0018470287322998047 sec\n",
            "multilayer_perceptron ran in: 0.0022084712982177734 sec\n",
            "multilayer_perceptron ran in: 0.0017230510711669922 sec\n",
            "multilayer_perceptron ran in: 0.0018322467803955078 sec\n",
            "multilayer_perceptron ran in: 0.0019266605377197266 sec\n",
            "multilayer_perceptron ran in: 0.0019674301147460938 sec\n",
            "multilayer_perceptron ran in: 0.0018393993377685547 sec\n",
            "multilayer_perceptron ran in: 0.0037834644317626953 sec\n",
            "multilayer_perceptron ran in: 0.0028879642486572266 sec\n",
            "multilayer_perceptron ran in: 0.0026237964630126953 sec\n",
            "multilayer_perceptron ran in: 0.0021507740020751953 sec\n",
            "multilayer_perceptron ran in: 0.0018935203552246094 sec\n",
            "multilayer_perceptron ran in: 0.0017926692962646484 sec\n",
            "multilayer_perceptron ran in: 0.0020856857299804688 sec\n",
            "multilayer_perceptron ran in: 0.0019545555114746094 sec\n",
            "multilayer_perceptron ran in: 0.001821279525756836 sec\n",
            "multilayer_perceptron ran in: 0.002520322799682617 sec\n",
            "multilayer_perceptron ran in: 0.0017330646514892578 sec\n",
            "multilayer_perceptron ran in: 0.001897573471069336 sec\n",
            "multilayer_perceptron ran in: 0.0018568038940429688 sec\n",
            "multilayer_perceptron ran in: 0.0018122196197509766 sec\n",
            "multilayer_perceptron ran in: 0.001875162124633789 sec\n",
            "multilayer_perceptron ran in: 0.001878976821899414 sec\n",
            "multilayer_perceptron ran in: 0.0022804737091064453 sec\n",
            "multilayer_perceptron ran in: 0.0017199516296386719 sec\n",
            "multilayer_perceptron ran in: 0.0021255016326904297 sec\n",
            "multilayer_perceptron ran in: 0.0017914772033691406 sec\n",
            "multilayer_perceptron ran in: 0.002336263656616211 sec\n",
            "multilayer_perceptron ran in: 0.0019843578338623047 sec\n",
            "multilayer_perceptron ran in: 0.0017232894897460938 sec\n",
            "multilayer_perceptron ran in: 0.0017137527465820312 sec\n",
            "multilayer_perceptron ran in: 0.0017998218536376953 sec\n",
            "multilayer_perceptron ran in: 0.002478361129760742 sec\n",
            "multilayer_perceptron ran in: 0.0018374919891357422 sec\n",
            "multilayer_perceptron ran in: 0.0016853809356689453 sec\n",
            "multilayer_perceptron ran in: 0.0018281936645507812 sec\n",
            "multilayer_perceptron ran in: 0.001983642578125 sec\n",
            "multilayer_perceptron ran in: 0.001909494400024414 sec\n",
            "multilayer_perceptron ran in: 0.0019378662109375 sec\n",
            "multilayer_perceptron ran in: 0.0017189979553222656 sec\n",
            "multilayer_perceptron ran in: 0.0018017292022705078 sec\n",
            "multilayer_perceptron ran in: 0.0017135143280029297 sec\n",
            "multilayer_perceptron ran in: 0.0018706321716308594 sec\n",
            "multilayer_perceptron ran in: 0.003996133804321289 sec\n",
            "multilayer_perceptron ran in: 0.0017287731170654297 sec\n",
            "multilayer_perceptron ran in: 0.0018908977508544922 sec\n",
            "multilayer_perceptron ran in: 0.0018494129180908203 sec\n",
            "multilayer_perceptron ran in: 0.001783132553100586 sec\n",
            "multilayer_perceptron ran in: 0.0018415451049804688 sec\n",
            "multilayer_perceptron ran in: 0.0017402172088623047 sec\n",
            "multilayer_perceptron ran in: 0.0018939971923828125 sec\n",
            "multilayer_perceptron ran in: 0.002041339874267578 sec\n",
            "multilayer_perceptron ran in: 0.0018613338470458984 sec\n",
            "multilayer_perceptron ran in: 0.006349325180053711 sec\n",
            "multilayer_perceptron ran in: 0.0017938613891601562 sec\n",
            "multilayer_perceptron ran in: 0.0019078254699707031 sec\n",
            "multilayer_perceptron ran in: 0.0021212100982666016 sec\n",
            "multilayer_perceptron ran in: 0.0018703937530517578 sec\n",
            "multilayer_perceptron ran in: 0.0018494129180908203 sec\n",
            "multilayer_perceptron ran in: 0.0018568038940429688 sec\n",
            "multilayer_perceptron ran in: 0.001993894577026367 sec\n",
            "multilayer_perceptron ran in: 0.002511739730834961 sec\n",
            "multilayer_perceptron ran in: 0.002048492431640625 sec\n",
            "multilayer_perceptron ran in: 0.0019495487213134766 sec\n",
            "multilayer_perceptron ran in: 0.00183868408203125 sec\n",
            "multilayer_perceptron ran in: 0.0017735958099365234 sec\n",
            "multilayer_perceptron ran in: 0.0016586780548095703 sec\n",
            "multilayer_perceptron ran in: 0.0016562938690185547 sec\n",
            "multilayer_perceptron ran in: 0.0038907527923583984 sec\n",
            "multilayer_perceptron ran in: 0.001855611801147461 sec\n",
            "multilayer_perceptron ran in: 0.0019233226776123047 sec\n",
            "multilayer_perceptron ran in: 0.0017609596252441406 sec\n",
            "multilayer_perceptron ran in: 0.003065824508666992 sec\n",
            "multilayer_perceptron ran in: 0.0017809867858886719 sec\n",
            "multilayer_perceptron ran in: 0.0016887187957763672 sec\n",
            "multilayer_perceptron ran in: 0.001718759536743164 sec\n",
            "multilayer_perceptron ran in: 0.003159046173095703 sec\n",
            "multilayer_perceptron ran in: 0.0016853809356689453 sec\n",
            "multilayer_perceptron ran in: 0.0017812252044677734 sec\n",
            "multilayer_perceptron ran in: 0.0018024444580078125 sec\n",
            "multilayer_perceptron ran in: 0.002406597137451172 sec\n",
            "multilayer_perceptron ran in: 0.0018188953399658203 sec\n",
            "multilayer_perceptron ran in: 0.0017650127410888672 sec\n",
            "multilayer_perceptron ran in: 0.0021262168884277344 sec\n",
            "multilayer_perceptron ran in: 0.0016903877258300781 sec\n",
            "multilayer_perceptron ran in: 0.002524137496948242 sec\n",
            "multilayer_perceptron ran in: 0.0018768310546875 sec\n",
            "multilayer_perceptron ran in: 0.0019576549530029297 sec\n",
            "multilayer_perceptron ran in: 0.0018534660339355469 sec\n",
            "multilayer_perceptron ran in: 0.008711814880371094 sec\n",
            "multilayer_perceptron ran in: 0.0019350051879882812 sec\n",
            "multilayer_perceptron ran in: 0.00249481201171875 sec\n",
            "multilayer_perceptron ran in: 0.0019788742065429688 sec\n",
            "multilayer_perceptron ran in: 0.0018160343170166016 sec\n",
            "multilayer_perceptron ran in: 0.0017774105072021484 sec\n",
            "multilayer_perceptron ran in: 0.0019080638885498047 sec\n",
            "multilayer_perceptron ran in: 0.0017764568328857422 sec\n",
            "multilayer_perceptron ran in: 0.0028047561645507812 sec\n",
            "multilayer_perceptron ran in: 0.0018301010131835938 sec\n",
            "multilayer_perceptron ran in: 0.004637956619262695 sec\n",
            "multilayer_perceptron ran in: 0.0017900466918945312 sec\n",
            "multilayer_perceptron ran in: 0.0019800662994384766 sec\n",
            "multilayer_perceptron ran in: 0.0021092891693115234 sec\n",
            "multilayer_perceptron ran in: 0.0016460418701171875 sec\n",
            "multilayer_perceptron ran in: 0.0018444061279296875 sec\n",
            "multilayer_perceptron ran in: 0.0017628669738769531 sec\n",
            "multilayer_perceptron ran in: 0.001832723617553711 sec\n",
            "multilayer_perceptron ran in: 0.0017337799072265625 sec\n",
            "multilayer_perceptron ran in: 0.002103567123413086 sec\n",
            "multilayer_perceptron ran in: 0.002132415771484375 sec\n",
            "multilayer_perceptron ran in: 0.0018482208251953125 sec\n",
            "multilayer_perceptron ran in: 0.001924753189086914 sec\n",
            "multilayer_perceptron ran in: 0.001989603042602539 sec\n",
            "multilayer_perceptron ran in: 0.001893758773803711 sec\n",
            "multilayer_perceptron ran in: 0.0018324851989746094 sec\n",
            "multilayer_perceptron ran in: 0.0024023056030273438 sec\n",
            "multilayer_perceptron ran in: 0.0019366741180419922 sec\n",
            "multilayer_perceptron ran in: 0.0017726421356201172 sec\n",
            "multilayer_perceptron ran in: 0.0017511844635009766 sec\n",
            "multilayer_perceptron ran in: 0.0018095970153808594 sec\n",
            "multilayer_perceptron ran in: 0.0017659664154052734 sec\n",
            "multilayer_perceptron ran in: 0.0017824172973632812 sec\n",
            "multilayer_perceptron ran in: 0.0018296241760253906 sec\n",
            "multilayer_perceptron ran in: 0.0016751289367675781 sec\n",
            "multilayer_perceptron ran in: 0.0016851425170898438 sec\n",
            "multilayer_perceptron ran in: 0.0044329166412353516 sec\n",
            "multilayer_perceptron ran in: 0.0019538402557373047 sec\n",
            "multilayer_perceptron ran in: 0.001739501953125 sec\n",
            "multilayer_perceptron ran in: 0.0018241405487060547 sec\n",
            "multilayer_perceptron ran in: 0.0017342567443847656 sec\n",
            "multilayer_perceptron ran in: 0.001932382583618164 sec\n",
            "multilayer_perceptron ran in: 0.0032532215118408203 sec\n",
            "multilayer_perceptron ran in: 0.0020303726196289062 sec\n",
            "multilayer_perceptron ran in: 0.0018362998962402344 sec\n",
            "multilayer_perceptron ran in: 0.0018153190612792969 sec\n",
            "multilayer_perceptron ran in: 0.003154277801513672 sec\n",
            "multilayer_perceptron ran in: 0.0017807483673095703 sec\n",
            "multilayer_perceptron ran in: 0.0017173290252685547 sec\n",
            "multilayer_perceptron ran in: 0.0019006729125976562 sec\n",
            "multilayer_perceptron ran in: 0.0018105506896972656 sec\n",
            "multilayer_perceptron ran in: 0.0018608570098876953 sec\n",
            "multilayer_perceptron ran in: 0.0017740726470947266 sec\n",
            "multilayer_perceptron ran in: 0.0018393993377685547 sec\n",
            "multilayer_perceptron ran in: 0.0018112659454345703 sec\n",
            "multilayer_perceptron ran in: 0.0017666816711425781 sec\n",
            "multilayer_perceptron ran in: 0.0017733573913574219 sec\n",
            "multilayer_perceptron ran in: 0.0022656917572021484 sec\n",
            "multilayer_perceptron ran in: 0.0018208026885986328 sec\n",
            "multilayer_perceptron ran in: 0.0017571449279785156 sec\n",
            "multilayer_perceptron ran in: 0.0018606185913085938 sec\n",
            "multilayer_perceptron ran in: 0.0018246173858642578 sec\n",
            "multilayer_perceptron ran in: 0.0018918514251708984 sec\n",
            "multilayer_perceptron ran in: 0.0017719268798828125 sec\n",
            "multilayer_perceptron ran in: 0.001859903335571289 sec\n",
            "multilayer_perceptron ran in: 0.0018901824951171875 sec\n",
            "multilayer_perceptron ran in: 0.006109714508056641 sec\n",
            "multilayer_perceptron ran in: 0.0024421215057373047 sec\n",
            "multilayer_perceptron ran in: 0.0025086402893066406 sec\n",
            "multilayer_perceptron ran in: 0.0016887187957763672 sec\n",
            "multilayer_perceptron ran in: 0.0022690296173095703 sec\n",
            "multilayer_perceptron ran in: 0.0021126270294189453 sec\n",
            "multilayer_perceptron ran in: 0.0023834705352783203 sec\n",
            "multilayer_perceptron ran in: 0.0021238327026367188 sec\n",
            "multilayer_perceptron ran in: 0.0022361278533935547 sec\n",
            "multilayer_perceptron ran in: 0.002254486083984375 sec\n",
            "multilayer_perceptron ran in: 0.0021402835845947266 sec\n",
            "multilayer_perceptron ran in: 0.0027997493743896484 sec\n",
            "multilayer_perceptron ran in: 0.002292156219482422 sec\n",
            "multilayer_perceptron ran in: 0.002248048782348633 sec\n",
            "multilayer_perceptron ran in: 0.002104043960571289 sec\n",
            "multilayer_perceptron ran in: 0.002199411392211914 sec\n",
            "multilayer_perceptron ran in: 0.002068758010864258 sec\n",
            "multilayer_perceptron ran in: 0.002051830291748047 sec\n",
            "multilayer_perceptron ran in: 0.0021941661834716797 sec\n",
            "multilayer_perceptron ran in: 0.0020134449005126953 sec\n",
            "multilayer_perceptron ran in: 0.002644062042236328 sec\n",
            "multilayer_perceptron ran in: 0.004876852035522461 sec\n",
            "multilayer_perceptron ran in: 0.0017354488372802734 sec\n",
            "multilayer_perceptron ran in: 0.002131938934326172 sec\n",
            "multilayer_perceptron ran in: 0.003098726272583008 sec\n",
            "multilayer_perceptron ran in: 0.002218008041381836 sec\n",
            "multilayer_perceptron ran in: 0.0024242401123046875 sec\n",
            "multilayer_perceptron ran in: 0.003290891647338867 sec\n",
            "multilayer_perceptron ran in: 0.0021266937255859375 sec\n",
            "multilayer_perceptron ran in: 0.002243518829345703 sec\n",
            "multilayer_perceptron ran in: 0.002518177032470703 sec\n",
            "multilayer_perceptron ran in: 0.0042209625244140625 sec\n",
            "multilayer_perceptron ran in: 0.0023708343505859375 sec\n",
            "multilayer_perceptron ran in: 0.002196073532104492 sec\n",
            "multilayer_perceptron ran in: 0.002526521682739258 sec\n",
            "multilayer_perceptron ran in: 0.0024085044860839844 sec\n",
            "multilayer_perceptron ran in: 0.002718687057495117 sec\n",
            "multilayer_perceptron ran in: 0.002396106719970703 sec\n",
            "multilayer_perceptron ran in: 0.008962631225585938 sec\n",
            "multilayer_perceptron ran in: 0.004122257232666016 sec\n",
            "multilayer_perceptron ran in: 0.002949237823486328 sec\n",
            "multilayer_perceptron ran in: 0.005907535552978516 sec\n",
            "multilayer_perceptron ran in: 0.0026116371154785156 sec\n",
            "multilayer_perceptron ran in: 0.0027070045471191406 sec\n",
            "multilayer_perceptron ran in: 0.0021352767944335938 sec\n",
            "multilayer_perceptron ran in: 0.0018584728240966797 sec\n",
            "multilayer_perceptron ran in: 0.0018415451049804688 sec\n",
            "multilayer_perceptron ran in: 0.001837015151977539 sec\n",
            "multilayer_perceptron ran in: 0.00177764892578125 sec\n",
            "multilayer_perceptron ran in: 0.0018515586853027344 sec\n",
            "multilayer_perceptron ran in: 0.001729726791381836 sec\n",
            "multilayer_perceptron ran in: 0.0019731521606445312 sec\n",
            "multilayer_perceptron ran in: 0.0020461082458496094 sec\n",
            "multilayer_perceptron ran in: 0.0017828941345214844 sec\n",
            "multilayer_perceptron ran in: 0.0018687248229980469 sec\n",
            "multilayer_perceptron ran in: 0.00209808349609375 sec\n",
            "multilayer_perceptron ran in: 0.0018796920776367188 sec\n",
            "multilayer_perceptron ran in: 0.0018885135650634766 sec\n",
            "multilayer_perceptron ran in: 0.0018470287322998047 sec\n",
            "multilayer_perceptron ran in: 0.0027408599853515625 sec\n",
            "multilayer_perceptron ran in: 0.0017573833465576172 sec\n",
            "multilayer_perceptron ran in: 0.0022170543670654297 sec\n",
            "multilayer_perceptron ran in: 0.002081155776977539 sec\n",
            "Epoch: 15 Cost=68911.0469\n",
            "Modellierung ist beendet: 15 Epochs of Training\n"
          ]
        }
      ],
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "n_samples_to_process = int(n_samples * (0.5 / 100)) # Nur 0.5% der Daten werden herangezogen\n",
        "\n",
        "# Training Epochs\n",
        "for epoch in range(training_epochs):\n",
        "\n",
        "    # Start mit cost = 0.0\n",
        "    avg_cost = 0.0\n",
        "\n",
        "    # Konvertiere die Anzahl an Batches in eine Integer\n",
        "    total_batch = int(n_samples_to_process / batch_size)\n",
        "\n",
        "    # Schleife für alle Batches\n",
        "    for i in range(total_batch):\n",
        "\n",
        "        # Den nächsten Batch an Trainingsdaten und -labels nehmen\n",
        "        batch_x = tf.cast(x_train[i * batch_size: (i + 1) * batch_size], tf.float32)\n",
        "        batch_y = tf.cast(y_train[i * batch_size: (i + 1) * batch_size], tf.float32)\n",
        "\n",
        "        # Gradienten berechnen\n",
        "        with tf.GradientTape() as tape:\n",
        "\n",
        "            pred = multilayer_perceptron(batch_x, weights, biases)\n",
        "            loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=batch_y, logits=pred))\n",
        "\n",
        "        gradients = tape.gradient(loss, list(weights.values()) + list(biases.values()))\n",
        "        optimizer.apply_gradients(zip(gradients, list(weights.values()) + list(biases.values())))\n",
        "\n",
        "        # Durchschnittliche Kosten berechnen\n",
        "        avg_cost += loss / total_batch\n",
        "\n",
        "    print(\"Epoch: {} Cost={:.4f}\".format(epoch + 1, avg_cost))\n",
        "\n",
        "print(\"Modellierung ist beendet: {} Epochs of Training\".format(training_epochs))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDIBmW6KO3Yi"
      },
      "source": [
        "## Modell Auswertung\n",
        "\n",
        "Tensorflow bietet einige eingebaute Funktionen, die uns bei der Auswertung helfen. Dazu gehören `tf.equal` und `tf.reduce_mean`.\n",
        "\n",
        "\n",
        "### tf.equal\n",
        "\n",
        "Dies ist im Grunde genommen nur eine Kontrolle, ob die Vorhersagen mit den Labels übereinstimmen. Da wir in unserem Fall wissen, dass die Labels eine 1 in einem Array von Nullen sind, können wir `argmax()` verwenden, um die Position zu vergleichen. Denke daran, dass y immer noch der Platzhalter ist, den wir anfangs erstellt haben. Wir werden eine Reihe an Operationen durchführen, um einen Tensor zu erhalten, in den wir die Testdaten einlesen können, um es auszuwerten."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qG13PBvcO3Yj"
      },
      "outputs": [],
      "source": [
        "# Teste das Modell\n",
        "correct_predictions = tf.math.reduce_all(tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XH30q6ctO3Yj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a47f539-4693-40aa-ed08-32e2444f6724"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KerasTensor(type_spec=TensorSpec(shape=(), dtype=tf.bool, name=None), name='tf.math.reduce_all_1/All:0', description=\"created by layer 'tf.math.reduce_all_1'\")\n"
          ]
        }
      ],
      "source": [
        "print(correct_predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iq137wh4O3Yj"
      },
      "source": [
        "Um numerische Werte für unsere Vorhersagen zu erhalten müssen wir `tf.cast` verwenden, um den Tensor mit Booleans zurückzuführen in einen Tensor mit Floats. Dann können wir den Durchschnitt nehmen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nBqw9lRPO3Yj"
      },
      "outputs": [],
      "source": [
        "correct_predictions = tf.cast(correct_predictions, \"float\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rZvZL3V8O3Yj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85a29c16-7e1f-4baa-d40c-9d29a291c078"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KerasTensor(type_spec=TensorSpec(shape=(), dtype=tf.float32, name=None), name='tf.cast_1/Cast:0', description=\"created by layer 'tf.cast_1'\")\n"
          ]
        }
      ],
      "source": [
        "print(correct_predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZs96X5HO3Yj"
      },
      "source": [
        "Jetzt können wir `tf.reduce_mean` verwenden, um den Durchschnitt der Elemente im Tensor zu erhalten:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "El6DFbWvO3Yj"
      },
      "outputs": [],
      "source": [
        "accuracy = tf.reduce_mean(correct_predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7jSG2BNTO3Yj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        },
        "outputId": "540ad49c-d1d1-48c8-ac42-240482e205d2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "keras.src.engine.keras_tensor.KerasTensor"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>keras.src.engine.keras_tensor.KerasTensor</b><br/>def __init__(type_spec, inferred_value=None, name=None)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/keras/src/engine/keras_tensor.py</a>A representation of a Keras in/output during Functional API construction.\n",
              "\n",
              "`KerasTensor`s are tensor-like objects that represent the symbolic inputs\n",
              "and outputs of Keras layers during Functional model construction. They are\n",
              "comprised of the `tf.TypeSpec` of the (Composite)Tensor that will be\n",
              "consumed/produced in the corresponding location of the Functional model.\n",
              "\n",
              "KerasTensors are intended as a private API, so users should never need to\n",
              "directly instantiate `KerasTensor`s.\n",
              "\n",
              "**Building Functional Models with KerasTensors**\n",
              "`tf.keras.Input` produces `KerasTensor`s that represent the symbolic inputs\n",
              "to your model.\n",
              "\n",
              "Passing a `KerasTensor` to a `tf.keras.Layer` `__call__` lets the layer know\n",
              "that you are building a Functional model. The layer __call__ will\n",
              "infer the output signature and return `KerasTensor`s with `tf.TypeSpec`s\n",
              "corresponding to the symbolic outputs of that layer call. These output\n",
              "`KerasTensor`s will have all of the internal KerasHistory metadata attached\n",
              "to them that Keras needs to construct a Functional Model.\n",
              "\n",
              "Currently, layers infer the output signature by:\n",
              "  * creating a scratch `FuncGraph`\n",
              "  * making placeholders in the scratch graph that match the input typespecs\n",
              "  * Calling `layer.call` on these placeholders\n",
              "  * extracting the signatures of the outputs before clearing the scratch\n",
              "    graph\n",
              "\n",
              "(Note: names assigned to KerasTensors by this process are not guaranteed to\n",
              "be unique, and are subject to implementation details).\n",
              "\n",
              "`tf.nest` methods are used to insure all of the inputs/output data\n",
              "structures get maintained, with elements swapped between KerasTensors and\n",
              "placeholders.\n",
              "\n",
              "In rare cases (such as when directly manipulating shapes using Keras\n",
              "layers), the layer may be able to partially infer the value of the output in\n",
              "addition to just inferring the signature.\n",
              "When this happens, the returned KerasTensor will also contain the inferred\n",
              "value information. Follow-on layers can use this information.\n",
              "during their own output signature inference.\n",
              "E.g. if one layer produces a symbolic `KerasTensor` that the next layer uses\n",
              "as the shape of its outputs, partially knowing the value helps infer the\n",
              "output shape.\n",
              "\n",
              "**Automatically converting TF APIs to layers**:\n",
              "If you passing a `KerasTensor` to a TF API that supports dispatching,\n",
              "Keras will automatically turn that API call into a lambda\n",
              "layer in the Functional model, and return KerasTensors representing the\n",
              "symbolic outputs.\n",
              "\n",
              "Most TF APIs that take only tensors as input and produce output tensors\n",
              "will support dispatching.\n",
              "\n",
              "Calling a `tf.function` does not support dispatching, so you cannot pass\n",
              "`KerasTensor`s as inputs to a `tf.function`.\n",
              "\n",
              "Higher-order APIs that take methods which produce tensors (e.g. `tf.while`,\n",
              "`tf.map_fn`, `tf.cond`) also do not currently support dispatching. So, you\n",
              "cannot directly pass KerasTensors as inputs to these APIs either. If you\n",
              "want to use these APIs inside of a Functional model, you must put them\n",
              "inside of a custom layer.\n",
              "\n",
              "Args:\n",
              "  type_spec: The `tf.TypeSpec` for the symbolic input created by\n",
              "    `tf.keras.Input`, or symbolically inferred for the output\n",
              "    during a symbolic layer `__call__`.\n",
              "  inferred_value: (Optional) a non-symbolic static value, possibly partially\n",
              "    specified, that could be symbolically inferred for the outputs during\n",
              "    a symbolic layer `__call__`. This will generally only happen when\n",
              "    grabbing and manipulating `tf.int32` shapes directly as tensors.\n",
              "    Statically inferring values in this way and storing them in the\n",
              "    KerasTensor allows follow-on layers to infer output signatures\n",
              "    more effectively. (e.g. when using a symbolic shape tensor to later\n",
              "    construct a tensor with that shape).\n",
              "  name: (optional) string name for this KerasTensor. Names automatically\n",
              "    generated by symbolic layer `__call__`s are not guaranteed to be unique,\n",
              "    and are subject to implementation details.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 33);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ],
      "source": [
        "type(accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ym7rcHhiO3Yk"
      },
      "source": [
        "# Neuronales Netzwerk-Modell"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "# Erstellung\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(n_input,)),\n",
        "    tf.keras.layers.Dense(n_hidden_1, activation=tf.nn.relu),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dense(n_hidden_2, activation=tf.nn.relu),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dense(n_classes, activation=None)])\n",
        "\n",
        "# Kompilieren\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
        "\n",
        "# Callbacks\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
        "model_checkpoint = ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True)\n",
        "\n",
        "# Trainieren des Modells\n",
        "x_train_flattened = x_train.reshape(-1, n_input)\n",
        "batch_size = 128\n",
        "model.fit(x_train_flattened, y_train, batch_size=batch_size, epochs=training_epochs,\n",
        "          validation_split=0.2, callbacks=[early_stopping, model_checkpoint])\n",
        "\n",
        "# Evaluierung\n",
        "x_test_flattened = x_test.reshape(-1, n_input)\n",
        "test_loss, test_accuracy = model.evaluate(x_test_flattened, y_test)\n",
        "\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_accuracy)\n"
      ],
      "metadata": {
        "id": "Ihy_XpMofZw5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d568e20e-d84f-4aa4-ba5e-0ceac9f14b3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "300/300 [==============================] - 5s 12ms/step - loss: 0.2381 - sparse_categorical_accuracy: 0.9273 - val_loss: 0.1474 - val_sparse_categorical_accuracy: 0.9621\n",
            "Epoch 2/15\n",
            " 13/300 [>.............................] - ETA: 2s - loss: 0.0906 - sparse_categorical_accuracy: 0.9712"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "300/300 [==============================] - 3s 11ms/step - loss: 0.0853 - sparse_categorical_accuracy: 0.9733 - val_loss: 0.1068 - val_sparse_categorical_accuracy: 0.9658\n",
            "Epoch 3/15\n",
            "300/300 [==============================] - 5s 16ms/step - loss: 0.0530 - sparse_categorical_accuracy: 0.9831 - val_loss: 0.0984 - val_sparse_categorical_accuracy: 0.9693\n",
            "Epoch 4/15\n",
            "300/300 [==============================] - 3s 11ms/step - loss: 0.0374 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.1066 - val_sparse_categorical_accuracy: 0.9688\n",
            "Epoch 5/15\n",
            "300/300 [==============================] - 3s 11ms/step - loss: 0.0308 - sparse_categorical_accuracy: 0.9903 - val_loss: 0.1268 - val_sparse_categorical_accuracy: 0.9640\n",
            "Epoch 6/15\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.0241 - sparse_categorical_accuracy: 0.9922 - val_loss: 0.0966 - val_sparse_categorical_accuracy: 0.9746\n",
            "Epoch 7/15\n",
            "300/300 [==============================] - 4s 14ms/step - loss: 0.0174 - sparse_categorical_accuracy: 0.9947 - val_loss: 0.1077 - val_sparse_categorical_accuracy: 0.9698\n",
            "Epoch 8/15\n",
            "300/300 [==============================] - 3s 11ms/step - loss: 0.0196 - sparse_categorical_accuracy: 0.9935 - val_loss: 0.1100 - val_sparse_categorical_accuracy: 0.9695\n",
            "Epoch 9/15\n",
            "300/300 [==============================] - 3s 11ms/step - loss: 0.0164 - sparse_categorical_accuracy: 0.9946 - val_loss: 0.1035 - val_sparse_categorical_accuracy: 0.9733\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1185 - sparse_categorical_accuracy: 0.9746\n",
            "Test Loss: 0.11849615722894669\n",
            "Test Accuracy: 0.9745833277702332\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prüfungsaufgeben 1 & 2"
      ],
      "metadata": {
        "id": "R0gSdIIzhuzD"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAiIXuXNO3Yk"
      },
      "source": [
        "## Initialisierung Unittest\n",
        "\n",
        "Auf Basis des Code-Snippet der [Website]( https://towardsdatascience.com/unit-testing-and-logging-for-data-science-d7fb8fd5d217) aus der Aufgabenstellung."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O9_tXo32O3Yk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa800f6b-7c0e-49fa-f79d-7a8295d5359d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MNIST: (48000, 784) (48000,)\n",
            "__init__ ran in: 1.52587890625e-05 sec\n",
            "fit ran in: 16.252377033233643 sec\n",
            "Train Accuracy: 72.53645833333333\n",
            "Classification Report for the classifier:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.93      0.81       963\n",
            "           1       0.75      0.95      0.84      1099\n",
            "           2       0.77      0.61      0.68       923\n",
            "           3       0.67      0.76      0.71      1022\n",
            "           4       0.72      0.78      0.75       961\n",
            "           5       0.62      0.44      0.51       844\n",
            "           6       0.73      0.85      0.79       948\n",
            "           7       0.75      0.79      0.77       978\n",
            "           8       0.80      0.54      0.65       922\n",
            "           9       0.77      0.59      0.67       940\n",
            "\n",
            "    accuracy                           0.73      9600\n",
            "   macro avg       0.73      0.72      0.72      9600\n",
            "weighted avg       0.73      0.73      0.72      9600\n",
            "\n",
            "\n",
            "predict ran in: 0.2470109462738037 sec\n",
            "Test Accuracy: 73.19791666666666\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    X = x_train\n",
        "    y = y_train\n",
        "    print('MNIST:', X.shape, y.shape)\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1 - splitRatio, random_state=42)\n",
        "    np.random.seed(31337)\n",
        "    ta = TheAlgorithm(X_train, y_train, X_test, y_test)\n",
        "\n",
        "    train_accuracy = ta.fit()\n",
        "    print('Train Accuracy:', train_accuracy)\n",
        "\n",
        "    test_accuracy = ta.predict()\n",
        "    print('Test Accuracy:', test_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "od5JnWqnO3Yl"
      },
      "source": [
        "# Durchführung der Unittests ausgeführt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZTxlJiNO3Yl"
      },
      "source": [
        "\n",
        "Auf Basis des Code-Snippet der [Website]( https://towardsdatascience.com/unit-testing-and-logging-for-data-science-d7fb8fd5d217) aus der Aufgabenstellung."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TestInput(unittest.TestCase):\n",
        "    @classmethod\n",
        "    def setUpClass(cls):\n",
        "        pass\n",
        "\n",
        "    @classmethod\n",
        "    def tearDownClass(cls):\n",
        "        pass\n",
        "\n",
        "    def setUp(self):\n",
        "        print('setUp')\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1 - splitRatio, random_state=42)\n",
        "        self.X_train = X_train\n",
        "        self.y_train = y_train\n",
        "        self.X_test = X_test\n",
        "        self.y_test = y_test\n",
        "        self.train_accuracy = train_accuracy\n",
        "        self.test_accuracy = test_accuracy\n",
        "        self.train_confusion_matrix = ta.train_confusion_matrix\n",
        "        self.test_confusion_matrix = ta.test_confusion_matrix\n",
        "\n",
        "    def tearDown(self):\n",
        "        pass\n",
        "\n",
        "    def test_fit(self):\n",
        "        np.random.seed(31337)\n",
        "        self.ta = TheAlgorithm(self.X_train, self.y_train, self.X_test, self.y_test)\n",
        "        self.assertEqual(self.ta.fit(), self.train_accuracy)\n",
        "        self.assertTrue(np.array_equal(self.ta.train_confusion_matrix, self.train_confusion_matrix))\n",
        "\n",
        "    def test_predict(self):\n",
        "        np.random.seed(31337)\n",
        "        self.ta = TheAlgorithm(self.X_train, self.y_train, self.X_test, self.y_test)\n",
        "        self.ta.fit()\n",
        "        self.assertEqual(self.ta.predict(), self.test_accuracy)\n",
        "        self.assertTrue(np.array_equal(self.ta.test_confusion_matrix, self.test_confusion_matrix))\n",
        "\n",
        "    def test_duration(self):\n",
        "        np.random.seed(31337)\n",
        "        self.ta = TheAlgorithm(self.X_train, self.y_train, self.X_test, self.y_test)\n",
        "        start_time = time.time()\n",
        "        self.ta.fit()\n",
        "        end_time = time.time()\n",
        "        elapsed_time = end_time - start_time\n",
        "        representative_runtime = 14 #Repräsentativer Durchschnittswert basierend auf früheren Läufen --> definiert auf 14 Sekunden\n",
        "        max_allowed_runtime = 1.2 * representative_runtime #Grenzwert 120%\n",
        "        self.assertLessEqual(elapsed_time, max_allowed_runtime)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    unittest.main(argv=['first-arg-is-ignored'], exit=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GdPMpTj9k8tT",
        "outputId": "32958b65-0f40-4f15-a6ca-5dcaed51c75e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "setUp\n",
            "__init__ ran in: 5.245208740234375e-06 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "."
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fit ran in: 14.972764015197754 sec\n",
            "setUp\n",
            "__init__ ran in: 3.814697265625e-06 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "."
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fit ran in: 13.540144205093384 sec\n",
            "setUp\n",
            "__init__ ran in: 1.33514404296875e-05 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ".\n",
            "----------------------------------------------------------------------\n",
            "Ran 3 tests in 42.762s\n",
            "\n",
            "OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fit ran in: 13.498198986053467 sec\n",
            "Classification Report for the classifier:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.93      0.81       963\n",
            "           1       0.75      0.95      0.84      1099\n",
            "           2       0.77      0.61      0.68       923\n",
            "           3       0.67      0.76      0.71      1022\n",
            "           4       0.72      0.78      0.75       961\n",
            "           5       0.62      0.44      0.51       844\n",
            "           6       0.73      0.85      0.79       948\n",
            "           7       0.75      0.79      0.77       978\n",
            "           8       0.80      0.54      0.65       922\n",
            "           9       0.77      0.59      0.67       940\n",
            "\n",
            "    accuracy                           0.73      9600\n",
            "   macro avg       0.73      0.72      0.72      9600\n",
            "weighted avg       0.73      0.73      0.72      9600\n",
            "\n",
            "\n",
            "predict ran in: 0.06834959983825684 sec\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbqc_ostO3Yl"
      },
      "source": [
        "\n",
        "# Gut gemacht!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
